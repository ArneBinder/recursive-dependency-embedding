
@inproceedings{niwa_co-occurrence_1994,
	title = {Co-occurrence vectors from corpora vs. distance vectors from dictionaries},
	booktitle = {Proceedings of the 15th conference on {Computational} linguistics-{Volume} 1},
	publisher = {Association for Computational Linguistics},
	author = {Niwa, Yoshiki and Nitta, Yoshihiko},
	year = {1994},
	keywords = {PMI, PPMI, SVM},
	pages = {304--309}
}

@article{turney_frequency_2010,
	title = {From {Frequency} to {Meaning}: {Vector} {Space} {Models} of {Semantics}},
	shorttitle = {From {Frequency} to {Meaning}},
	url = {http://arxiv.org/abs/1003.1141},
	doi = {10.1613/jair.2934},
	abstract = {Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.},
	urldate = {2017-12-02TZ},
	journal = {arXiv:1003.1141 [cs]},
	author = {Turney, Peter D. and Pantel, Patrick},
	month = mar,
	year = {2010},
	note = {arXiv: 1003.1141},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Learning, PPMI, SVM}
}

@article{church_word_1990,
	title = {Word association norms, mutual information, and lexicography},
	volume = {16},
	number = {1},
	journal = {Computational linguistics},
	author = {Church, Kenneth Ward and Hanks, Patrick},
	year = {1990},
	keywords = {PMI},
	pages = {22--29}
}

@article{nickel_holographic_2015,
	title = {Holographic {Embeddings} of {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/1510.04935},
	abstract = {Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. In extensive experiments we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction in knowledge graphs and relational learning benchmark datasets.},
	urldate = {2017-11-29TZ},
	journal = {arXiv:1510.04935 [cs, stat]},
	author = {Nickel, Maximilian and Rosasco, Lorenzo and Poggio, Tomaso},
	month = oct,
	year = {2015},
	note = {arXiv: 1510.04935},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning, I.2.4, I.2.6, Statistics - Machine Learning}
}

@book{mohri_foundations_2012,
	address = {Cambridge, Mass. London},
	series = {Adaptive computation and machine learning},
	title = {Foundations of machine learning},
	isbn = {978-0-262-01825-8},
	language = {eng},
	publisher = {The MIT Press},
	author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
	year = {2012},
	note = {OCLC: 812407408}
}

@book{rumelhart_parallel_1986,
	address = {Cambridge, Mass},
	series = {Computational models of cognition and perception},
	title = {Parallel distributed processing: explorations in the microstructure of cognition},
	isbn = {978-0-262-18120-4 978-0-262-13218-3},
	shorttitle = {Parallel distributed processing},
	url = {https://academiaanalitica.files.wordpress.com/2016/11/david-e-rumelhart-james-l-mcclelland-pdp-research-group-parallel-distributed-processing_-explorations-in-the-microstructure-of-cognition_-foundations-vol-11986.pdf},
	publisher = {MIT Press},
	author = {Rumelhart, David E. and McClelland, James L.},
	collaborator = {University of California, San Diego},
	year = {1986},
	keywords = {Cognition, Human information processing}
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {08936080},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	language = {en},
	number = {5},
	urldate = {2017-11-27TZ},
	journal = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	month = jan,
	year = {1989},
	pages = {359--366}
}

@incollection{sandberg_feedforward_2001,
	address = {New York, NY},
	title = {Feedforward {Neural} {Networks}: {An} {Introduction}},
	isbn = {978-0-471-34911-2},
	url = {http://media.wiley.com/product_data/excerpt/19/04713491/0471349119.pdf},
	language = {eng},
	booktitle = {Nonlinear dynamical systems: feedforward neural network perspectives},
	publisher = {Wiley},
	author = {Haykin, Simon},
	editor = {Sandberg, Irwin W.},
	year = {2001},
	note = {OCLC: 247412991}
}

@book{sandberg_nonlinear_2001,
	address = {New York},
	series = {Adaptive and learning systems for signal processing, communications, and control},
	title = {Nonlinear dynamical systems: feedforward neural network perspectives},
	isbn = {978-0-471-34911-2},
	shorttitle = {Nonlinear dynamical systems},
	publisher = {Wiley},
	editor = {Sandberg, I. W.},
	year = {2001},
	keywords = {Dynamics, Neural networks (Computer science)}
}

@incollection{hosseini_persian_2013,
	title = {Persian vowel recognition using the combination of haar wavelet and neural network},
	booktitle = {Innovations in {Intelligent} {Machines}-3},
	publisher = {Springer},
	author = {Hosseini, Mohammad Mehdi and Gharahbagh, Abdorreza Alavi},
	year = {2013},
	pages = {53--68}
}

@article{rosenblatt_perceptron:_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain.},
	volume = {65},
	issn = {1939-1471, 0033-295X},
	shorttitle = {The perceptron},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
	doi = {10.1037/h0042519},
	language = {en},
	number = {6},
	urldate = {2017-11-27TZ},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	pages = {386--408}
}

@inproceedings{socher_recursive_2013,
	title = {Recursive deep models for semantic compositionality over a sentiment treebank},
	url = {http://www.aclweb.org/anthology/D13-1170},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings of the 2013 conference on empirical methods in natural language processing},
	author = {Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher},
	year = {2013},
	pages = {1631--1642}
}

@article{budanitsky_evaluating_2006,
	title = {Evaluating wordnet-based measures of lexical semantic relatedness},
	volume = {32},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/coli.2006.32.1.13},
	number = {1},
	urldate = {2017-08-24TZ},
	journal = {Computational Linguistics},
	author = {Budanitsky, Alexander and Hirst, Graeme},
	year = {2006},
	pages = {13--47}
}

@article{zeiler_adadelta:_2012,
	title = {{ADADELTA}: {An} {Adaptive} {Learning} {Rate} {Method}},
	shorttitle = {{ADADELTA}},
	url = {http://arxiv.org/abs/1212.5701},
	abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
	urldate = {2017-09-12TZ},
	journal = {arXiv:1212.5701 [cs]},
	author = {Zeiler, Matthew D.},
	month = dec,
	year = {2012},
	note = {arXiv: 1212.5701},
	keywords = {Computer Science - Learning}
}

@article{pagliardini_unsupervised_2017,
	title = {Unsupervised {Learning} of {Sentence} {Embeddings} using {Compositional} n-{Gram} {Features}},
	url = {http://arxiv.org/abs/1703.02507},
	abstract = {The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.},
	urldate = {2017-08-14TZ},
	journal = {arXiv:1703.02507 [cs]},
	author = {Pagliardini, Matteo and Gupta, Prakhar and Jaggi, Martin},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.02507},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval, I.2.7}
}

@inproceedings{le_distributed_2014,
	title = {Distributed representations of sentences and documents},
	url = {http://www.jmlr.org/proceedings/papers/v32/le14.pdf},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Machine} {Learning} ({ICML}-14)},
	author = {Le, Quoc and Mikolov, Tomas},
	year = {2014},
	pages = {1188--1196}
}

@inproceedings{agirre_semeval-2012_2012,
	title = {Semeval-2012 task 6: {A} pilot on semantic textual similarity},
	shorttitle = {Semeval-2012 task 6},
	booktitle = {Proceedings of the {First} {Joint} {Conference} on {Lexical} and {Computational} {Semantics}-{Volume} 1: {Proceedings} of the main conference and the shared task, and {Volume} 2: {Proceedings} of the {Sixth} {International} {Workshop} on {Semantic} {Evaluation}},
	publisher = {Association for Computational Linguistics},
	author = {Agirre, Eneko and Diab, Mona and Cer, Daniel and Gonzalez-Agirre, Aitor},
	year = {2012},
	pages = {385--393}
}

@article{cho_properties_2014,
	title = {On the properties of neural machine translation: {Encoder}-decoder approaches},
	shorttitle = {On the properties of neural machine translation},
	url = {https://arxiv.org/abs/1409.1259},
	urldate = {2017-10-02TZ},
	journal = {arXiv preprint arXiv:1409.1259},
	author = {Cho, Kyunghyun and Van Merriënboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
	year = {2014},
	keywords = {gru}
}

@inproceedings{mikolov_distributed_2013,
	title = {Distributed representations of words and phrases and their compositionality},
	url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality},
	urldate = {2017-10-02TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S. and Dean, Jeff},
	year = {2013},
	keywords = {word2vec},
	pages = {3111--3119}
}

@book{sternefeld_syntax::_2015,
	address = {Tübingen},
	edition = {4., überarbeitete Auflage},
	series = {Stauffenburg-{Linguistik}},
	title = {Syntax:: eine morphologisch motivierte generative {Beschreibung} des {Deutschen}. {Band} 1: [...]},
	isbn = {978-3-86057-176-7},
	shorttitle = {Syntax},
	language = {ger},
	number = {Band 31,1},
	publisher = {Stauffenburg Verlag},
	author = {Sternefeld, Wolfgang},
	year = {2015},
	note = {OCLC: 945727954},
	keywords = {German language, Morphology, Syntax}
}

@article{kim_convolutional_2014,
	title = {Convolutional neural networks for sentence classification},
	url = {https://arxiv.org/abs/1408.5882},
	urldate = {2017-10-04TZ},
	journal = {arXiv preprint arXiv:1408.5882},
	author = {Kim, Yoon},
	year = {2014}
}

@article{kingma_adam:_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2017-11-21TZ},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Learning}
}

@article{zhang_feedforward_2015,
	title = {Feedforward {Sequential} {Memory} {Networks}: {A} {New} {Structure} to {Learn} {Long}-term {Dependency}},
	shorttitle = {Feedforward {Sequential} {Memory} {Networks}},
	url = {http://arxiv.org/abs/1512.08301},
	abstract = {In this paper, we propose a novel neural network structure, namely {\textbackslash}emph\{feedforward sequential memory networks (FSMN)\}, to model long-term dependency in time series without using recurrent feedback. The proposed FSMN is a standard fully-connected feedforward neural network equipped with some learnable memory blocks in its hidden layers. The memory blocks use a tapped-delay line structure to encode the long context information into a fixed-size representation as short-term memory mechanism. We have evaluated the proposed FSMNs in several standard benchmark tasks, including speech recognition and language modelling. Experimental results have shown FSMNs significantly outperform the conventional recurrent neural networks (RNN), including LSTMs, in modeling sequential signals like speech or language. Moreover, FSMNs can be learned much more reliably and faster than RNNs or LSTMs due to the inherent non-recurrent model structure.},
	urldate = {2017-11-27TZ},
	journal = {arXiv:1512.08301 [cs]},
	author = {Zhang, Shiliang and Liu, Cong and Jiang, Hui and Wei, Si and Dai, Lirong and Hu, Yu},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.08301},
	keywords = {Computer Science - Neural and Evolutionary Computing}
}

@article{hopfield_neural_1982,
	title = {Neural networks and physical systems with emergent collective computational abilities.},
	volume = {79},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.79.8.2554},
	doi = {10.1073/pnas.79.8.2554},
	language = {en},
	number = {8},
	urldate = {2017-11-27TZ},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Hopfield, J. J.},
	month = apr,
	year = {1982},
	pages = {2554--2558}
}

@misc{noauthor_survey_nodate,
	title = {A survey on tag recommendation methods - {Belém} - 2016 - {Journal} of the {Association} for {Information} {Science} and {Technology} - {Wiley} {Online} {Library}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/asi.23736/abstract?systemMessage=Wiley+Online+Library+usage+report+download+page+will+be+unavailable+on+Friday+24th+November+2017+at+21%3A00+EST+%2F+02.00+GMT+%2F+10%3A00+SGT+%28Saturday+25th+Nov+for+SGT+},
	urldate = {2017-11-27TZ}
}

@article{spearman_proof_1904,
	title = {The {Proof} and {Measurement} of {Association} between {Two} {Things}},
	volume = {15},
	issn = {00029556},
	url = {http://www.jstor.org/stable/1412159},
	doi = {10.2307/1412159},
	number = {1},
	journal = {The American Journal of Psychology},
	author = {Spearman, C.},
	year = {1904},
	pages = {72--101}
}

@article{pearson_note_1895,
	title = {Note on {Regression} and {Inheritance} in the {Case} of {Two} {Parents}},
	volume = {58},
	issn = {0370-1662},
	url = {http://rspl.royalsocietypublishing.org/cgi/doi/10.1098/rspl.1895.0041},
	doi = {10.1098/rspl.1895.0041},
	number = {-1},
	urldate = {2017-11-27TZ},
	journal = {Proceedings of the Royal Society of London (1854-1905)},
	author = {Pearson, Karl},
	month = jan,
	year = {1895},
	pages = {240--242}
}

@incollection{britain_notes_1895,
	title = {Notes on {Regression} and {Inheritance} in the {Case} of {Two} {Parents}},
	number = {Bd. 58},
	booktitle = {Proceedings of the {Royal} {Society} of {London}},
	publisher = {Taylor \& Francis},
	author = {Britain), Royal Society (Great},
	year = {1895},
	lccn = {93660113},
	pages = {240--242}
}

@inproceedings{pham_sentence_2013,
	title = {Sentence paraphrase detection: {When} determiners and word order make the difference},
	shorttitle = {Sentence paraphrase detection},
	url = {http://clic.cimec.unitn.it/marco/publications/pham-etal-tfds2013.pdf},
	booktitle = {Proceedings of the {Towards} a {Formal} {Distributional} {Semantics} {Workshop} at {IWCS} 2013},
	author = {Pham, Nghia and Bernardi, Raffaella and Zhang, Yao Zhong and Baroni, Marco},
	year = {2013},
	pages = {21--29}
}

@inproceedings{gracia_web-based_2008,
	title = {Web-{Based} {Measure} of {Semantic} {Relatedness}.},
	url = {http://oa.upm.es/6549/1/Web-based_Measure.pdf},
	booktitle = {{WISE}},
	publisher = {Springer},
	author = {Gracia, Jorge and Mena, Eduardo},
	year = {2008},
	pages = {136--150}
}

@article{resnik_semantic_1999,
	title = {Semantic similarity in a taxonomy: {An} information-based measure and its application to problems of ambiguity in natural language},
	volume = {11},
	shorttitle = {Semantic similarity in a taxonomy},
	url = {https://www.jair.org/media/514/live-514-1722-jair.pdf},
	journal = {J. Artif. Intell. Res.(JAIR)},
	author = {Resnik, Philip},
	year = {1999},
	pages = {95--130}
}

@article{hodosh_framing_2013,
	title = {Framing image description as a ranking task: {Data}, models and evaluation metrics},
	volume = {47},
	shorttitle = {Framing image description as a ranking task},
	journal = {Journal of Artificial Intelligence Research},
	author = {Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
	year = {2013},
	pages = {853--899}
}

@article{bowman_large_2015,
	title = {A large annotated corpus for learning natural language inference},
	url = {http://arxiv.org/abs/1508.05326},
	abstract = {Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.},
	urldate = {2017-11-23TZ},
	journal = {arXiv:1508.05326 [cs]},
	author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher and Manning, Christopher D.},
	month = aug,
	year = {2015},
	note = {arXiv: 1508.05326},
	keywords = {Computer Science - Computation and Language}
}

@inproceedings{pavlick_ppdb_2015,
	address = {Beijing, China},
	title = {{PPDB} 2.0: {Better} paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification},
	url = {http://www.aclweb.org/anthology/P15-2070},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Pavlick, Ellie and Rastogi, Pushpendre and Ganitkevitch, Juri and Van Durme, Benjamin and Callison-Burch, Chris},
	month = jul,
	year = {2015},
	pages = {425--430}
}

@article{robins_catastrophic_1995,
	title = {Catastrophic forgetting, rehearsal and pseudorehearsal},
	volume = {7},
	number = {2},
	journal = {Connection Science},
	author = {Robins, Anthony},
	year = {1995},
	pages = {123--146}
}

@inproceedings{choi_it_2015,
	title = {It {Depends}: {Dependency} {Parser} {Comparison} {Using} {A} {Web}-based {Evaluation} {Tool}.},
	shorttitle = {It {Depends}},
	booktitle = {{ACL} (1)},
	author = {Choi, Jinho D. and Tetreault, Joel R. and Stent, Amanda},
	year = {2015},
	pages = {387--396}
}

@article{abadi_tensorflow:_2016,
	title = {{TensorFlow}: {A} system for large-scale machine learning},
	shorttitle = {{TensorFlow}},
	url = {http://arxiv.org/abs/1605.08695},
	abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
	urldate = {2017-11-21TZ},
	journal = {arXiv:1605.08695 [cs]},
	author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	month = may,
	year = {2016},
	note = {arXiv: 1605.08695},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing}
}

@inproceedings{bergstra_algorithms_2011,
	title = {Algorithms for hyper-parameter optimization},
	url = {https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bergstra, James S. and Bardenet, Rémi and Bengio, Yoshua and Kégl, Balázs},
	year = {2011},
	pages = {2546--2554}
}

@article{arora_simple_2016,
	title = {A simple but tough-to-beat baseline for sentence embeddings},
	url = {https://openreview.net/pdf?id=SyK00v5xx},
	author = {Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu},
	year = {2016}
}

@article{conneau_supervised_2017,
	title = {Supervised {Learning} of {Universal} {Sentence} {Representations} from {Natural} {Language} {Inference} {Data}},
	url = {http://arxiv.org/abs/1705.02364},
	abstract = {Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.},
	urldate = {2017-11-19TZ},
	journal = {arXiv:1705.02364 [cs]},
	author = {Conneau, Alexis and Kiela, Douwe and Schwenk, Holger and Barrault, Loic and Bordes, Antoine},
	month = may,
	year = {2017},
	note = {arXiv: 1705.02364},
	keywords = {Computer Science - Computation and Language}
}

@inproceedings{lu_deep_2015,
	title = {Deep {Multilingual} {Correlation} for {Improved} {Word} {Embeddings}.},
	url = {http://ttic.uchicago.edu/~kgimpel/papers/lu+etal.naacl15.pdf},
	urldate = {2017-10-10TZ},
	booktitle = {{HLT}-{NAACL}},
	author = {Lu, Ang and Wang, Weiran and Bansal, Mohit and Gimpel, Kevin and Livescu, Karen},
	year = {2015},
	pages = {250--256}
}

@article{bordes_open_2014,
	title = {Open {Question} {Answering} with {Weakly} {Supervised} {Embedding} {Models}},
	url = {http://arxiv.org/abs/1404.4326},
	abstract = {Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data.},
	urldate = {2017-10-10TZ},
	journal = {arXiv:1404.4326 [cs]},
	author = {Bordes, Antoine and Weston, Jason and Usunier, Nicolas},
	month = apr,
	year = {2014},
	note = {arXiv: 1404.4326},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning}
}

@inproceedings{faruqui_improving_2014,
	title = {Improving vector space word representations using multilingual correlation},
	url = {http://anthology.aclweb.org/E/E14/E14-1049.pdf},
	urldate = {2017-10-10TZ},
	publisher = {Association for Computational Linguistics},
	author = {Faruqui, Manaal and Dyer, Chris},
	year = {2014}
}

@article{hermann_multilingual_2014,
	title = {Multilingual {Models} for {Compositional} {Distributed} {Semantics}},
	url = {https://arxiv.org/pdf/1404.4641.pdf},
	abstract = {We present a novel technique for learning semantic representations, which extends the distributional hypothesis to multilingual data and joint-space embeddings. Our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences, while maintaining sufficient distance between those of dissimilar sentences. The models do not rely on word alignments or any syntactic information and are successfully applied to a number of diverse languages. We extend our approach to learn semantic representations at the document level, too. We evaluate these models on two cross-lingual document classification tasks, outperforming the prior state of the art. Through qualitative analysis and the study of pivoting effects we demonstrate that our representations are semantically plausible and can capture semantic relationships across languages without parallel data.},
	urldate = {2017-10-10TZ},
	journal = {arXiv:1404.4641 [cs]},
	author = {Hermann, Karl Moritz and Blunsom, Phil},
	month = apr,
	year = {2014},
	note = {arXiv: 1404.4641},
	keywords = {Computer Science - Computation and Language}
}

@article{firth_synopsis_1957,
	title = {A synopsis of linguistic theory, 1930-1955},
	url = {http://annabellelukin.edublogs.org/files/2013/08/Firth-JR-1962-A-Synopsis-of-Linguistic-Theory-wfihi5.pdf},
	journal = {Studies in linguistic analysis},
	author = {Firth, John R},
	year = {1957}
}

@inproceedings{huang_learning_2013,
	title = {Learning deep structured semantic models for web search using clickthrough data},
	url = {https://pdfs.semanticscholar.org/5b95/34442f91a87022427b74bca9fd95dd045383.pdf},
	urldate = {2017-10-10TZ},
	booktitle = {Proceedings of the 22nd {ACM} international conference on {Conference} on information \& knowledge management},
	publisher = {ACM},
	author = {Huang, Po-Sen and He, Xiaodong and Gao, Jianfeng and Deng, Li and Acero, Alex and Heck, Larry},
	year = {2013},
	pages = {2333--2338}
}

@inproceedings{yih_learning_2011,
	title = {Learning discriminative projections for text similarity measures},
	url = {http://anthology.aclweb.org/W/W11/W11-03.pdf#page=261},
	booktitle = {Proceedings of the {Fifteenth} {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author = {Yih, Wen-tau and Toutanova, Kristina and Platt, John C and Meek, Christopher},
	year = {2011},
	pages = {247--256}
}

@article{li_hierarchical_2015,
	title = {A {Hierarchical} {Neural} {Autoencoder} for {Paragraphs} and {Documents}},
	url = {http://arxiv.org/abs/1506.01057},
	abstract = {Natural language generation of coherent long texts like paragraphs or longer documents is a challenging problem for recurrent networks models. In this paper, we explore an important step toward this generation task: training an LSTM (Long-short term memory) auto-encoder to preserve and reconstruct multi-sentence paragraphs. We introduce an LSTM model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words, then decodes this embedding to reconstruct the original paragraph. We evaluate the reconstructed paragraph using standard metrics like ROUGE and Entity Grid, showing that neural models are able to encode texts in a way that preserve syntactic, semantic, and discourse coherence. While only a first step toward generating coherent text units from neural models, our work has the potential to significantly impact natural language generation and summarization .},
	urldate = {2017-10-04TZ},
	journal = {arXiv:1506.01057 [cs]},
	author = {Li, Jiwei and Luong, Minh-Thang and Jurafsky, Dan},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.01057},
	keywords = {Computer Science - Computation and Language}
}

@article{wieting_towards_2015,
	title = {Towards {Universal} {Paraphrastic} {Sentence} {Embeddings}},
	url = {https://arxiv.org/pdf/1511.08198.pdf},
	abstract = {We consider the problem of learning general-purpose, paraphrastic sentence embeddings based on supervision from the Paraphrase Database (Ganitkevitch et al., 2013). We compare six compositional architectures, evaluating them on annotated textual similarity datasets drawn both from the same distribution as the training data and from a wide range of other domains. We find that the most complex architectures, such as long short-term memory (LSTM) recurrent neural networks, perform best on the in-domain data. However, in out-of-domain scenarios, simple architectures such as word averaging vastly outperform LSTMs. Our simplest averaging model is even competitive with systems tuned for the particular tasks while also being extremely efficient and easy to use. In order to better understand how these architectures compare, we conduct further experiments on three supervised NLP tasks: sentence similarity, entailment, and sentiment classification. We again find that the word averaging models perform well for sentence similarity and entailment, outperforming LSTMs. However, on sentiment classification, we find that the LSTM performs very strongly-even recording new state-of-the-art performance on the Stanford Sentiment Treebank. We then demonstrate how to combine our pretrained sentence embeddings with these supervised tasks, using them both as a prior and as a black box feature extractor. This leads to performance rivaling the state of the art on the SICK similarity and entailment tasks. We release all of our resources to the research community with the hope that they can serve as the new baseline for further work on universal sentence embeddings.},
	urldate = {2017-10-02TZ},
	journal = {arXiv:1511.08198 [cs]},
	author = {Wieting, John and Bansal, Mohit and Gimpel, Kevin and Livescu, Karen},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.08198},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning}
}

@inproceedings{liu_multi-timescale_2015,
	title = {Multi-{Timescale} {Long} {Short}-{Term} {Memory} {Neural} {Network} for {Modelling} {Sentences} and {Documents}.},
	url = {https://www.aclweb.org/anthology/D/D15/D15-1280.pdf},
	urldate = {2017-10-04TZ},
	booktitle = {{EMNLP}},
	author = {Liu, Pengfei and Qiu, Xipeng and Chen, Xinchi and Wu, Shiyu and Huang, Xuanjing},
	year = {2015},
	pages = {2326--2335}
}

@article{ling_finding_2015,
	title = {Finding function in form: {Compositional} character models for open vocabulary word representation},
	shorttitle = {Finding function in form},
	url = {https://arxiv.org/abs/1508.02096},
	urldate = {2017-10-04TZ},
	journal = {arXiv preprint arXiv:1508.02096},
	author = {Ling, Wang and Luís, Tiago and Marujo, Luís and Astudillo, Ramón Fernandez and Amir, Silvio and Dyer, Chris and Black, Alan W. and Trancoso, Isabel},
	year = {2015}
}

@inproceedings{he_multi-perspective_2015,
	title = {Multi-{Perspective} {Sentence} {Similarity} {Modeling} with {Convolutional} {Neural} {Networks}.},
	url = {https://pdfs.semanticscholar.org/0f69/24633c56832b91836b69aedfd024681e427c.pdf},
	urldate = {2017-10-04TZ},
	booktitle = {{EMNLP}},
	author = {He, Hua and Gimpel, Kevin and Lin, Jimmy J.},
	year = {2015},
	pages = {1576--1586}
}

@inproceedings{yin_convolutional_2015,
	title = {Convolutional neural network for paraphrase identification},
	url = {https://aclanthology.info/pdf/N/N15/N15-1091.pdf},
	urldate = {2017-10-04TZ},
	booktitle = {Proceedings of the 2015 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	author = {Yin, Wenpeng and Schütze, Hinrich},
	year = {2015},
	pages = {901--911}
}

@inproceedings{hu_convolutional_2014,
	title = {Convolutional neural network architectures for matching natural language sentences},
	url = {http://papers.nips.cc/paper/5550-convolutional-neural-network-architectures-for-matching-natural-language-sentences},
	urldate = {2017-10-04TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Hu, Baotian and Lu, Zhengdong and Li, Hang and Chen, Qingcai},
	year = {2014},
	pages = {2042--2050}
}

@inproceedings{chen_sentence_2015,
	title = {Sentence {Modeling} with {Gated} {Recursive} {Neural} {Network}.},
	url = {https://www.aclweb.org/anthology/D/D15/D15-1092.pdf},
	urldate = {2017-10-04TZ},
	booktitle = {{EMNLP}},
	author = {Chen, Xinchi and Qiu, Xipeng and Zhu, Chenxi and Wu, Shiyu and Huang, Xuanjing},
	year = {2015},
	pages = {793--798}
}

@article{zhao_self-adaptive_2015,
	title = {Self-{Adaptive} {Hierarchical} {Sentence} {Model}},
	url = {http://arxiv.org/abs/1504.05070},
	abstract = {The ability to accurately model a sentence at varying stages (e.g., word-phrase-sentence) plays a central role in natural language processing. As an effort towards this goal we propose a self-adaptive hierarchical sentence model (AdaSent). AdaSent effectively forms a hierarchy of representations from words to phrases and then to sentences through recursive gated local composition of adjacent segments. We design a competitive mechanism (through gating networks) to allow the representations of the same sentence to be engaged in a particular learning task (e.g., classification), therefore effectively mitigating the gradient vanishing problem persistent in other recursive models. Both qualitative and quantitative analysis shows that AdaSent can automatically form and select the representations suitable for the task at hand during training, yielding superior classification performance over competitor models on 5 benchmark data sets.},
	urldate = {2017-10-04TZ},
	journal = {arXiv:1504.05070 [cs]},
	author = {Zhao, Han and Lu, Zhengdong and Poupart, Pascal},
	month = apr,
	year = {2015},
	note = {arXiv: 1504.05070},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing}
}

@inproceedings{irsoy_deep_2014,
	title = {Deep recursive neural networks for compositionality in language},
	url = {http://papers.nips.cc/paper/5551-deep-recursive-neural-networks-for-compositionality-in-language},
	urldate = {2017-10-04TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Irsoy, Ozan and Cardie, Claire},
	year = {2014},
	pages = {2096--2104}
}

@inproceedings{socher_semantic_2012,
	title = {Semantic compositionality through recursive matrix-vector spaces},
	url = {http://dl.acm.org/citation.cfm?id=2391084},
	urldate = {2017-10-04TZ},
	booktitle = {Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning},
	publisher = {Association for Computational Linguistics},
	author = {Socher, Richard and Huval, Brody and Manning, Christopher D. and Ng, Andrew Y.},
	year = {2012},
	pages = {1201--1211}
}

@inproceedings{socher_dynamic_2011,
	title = {Dynamic pooling and unfolding recursive autoencoders for paraphrase detection},
	url = {http://papers.nips.cc/paper/4204-dynamic-pooling-and-unfolding-recursive-autoencoders-for-paraphrase-detection.pdf},
	urldate = {2017-10-04TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Socher, Richard and Huang, Eric H. and Pennin, Jeffrey and Manning, Christopher D. and Ng, Andrew Y.},
	year = {2011},
	pages = {801--809}
}

@inproceedings{polajnar_exploration_2015,
	title = {An exploration of discourse-based sentence spaces for compositional distributional semantics},
	url = {http://www.anthology.aclweb.org/W/W15/W15-27.pdf#page=13},
	urldate = {2017-10-04TZ},
	booktitle = {Workshop on {Linking} {Models} of {Lexical}, {Sentential} and {Discourse}-level {Semantics} ({LSDSem})},
	author = {Polajnar, Tamara and Rimell, Laura and Clark, Stephen},
	year = {2015},
	pages = {1}
}

@inproceedings{paperno_practical_2014,
	title = {A practical and linguistically-motivated approach to compositional distributional semantics},
	volume = {1},
	url = {https://aclanthology.info/pdf/P/P14/P14-1009.pdf},
	urldate = {2017-10-04TZ},
	booktitle = {Proceedings of the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	author = {Paperno, Denis and Baroni, Marco and {others}},
	year = {2014},
	pages = {90--99}
}

@article{baroni_frege_2014,
	title = {Frege in {Space}: {A} {Program} of {Compositional} {Distributional} {Semantics}},
	volume = {9},
	copyright = {Copyright (c)},
	issn = {1945-3604},
	shorttitle = {Frege in {Space}},
	url = {http://csli-lilt.stanford.edu/ojs/index.php/LiLT/article/download/6/5},
	language = {en},
	number = {0},
	urldate = {2017-10-04TZ},
	journal = {LiLT (Linguistic Issues in Language Technology)},
	author = {Baroni, Marco and Bernardi, Raffaela and Zamparelli, Roberto},
	year = {2014},
	keywords = {compositional semantics, distributional semantics}
}

@inproceedings{blacoe_comparison_2012,
	title = {A comparison of vector-based representations for semantic composition},
	url = {http://dl.acm.org/citation.cfm?id=2391011},
	urldate = {2017-10-04TZ},
	booktitle = {Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning},
	publisher = {Association for Computational Linguistics},
	author = {Blacoe, William and Lapata, Mirella},
	year = {2012},
	pages = {546--556}
}

@inproceedings{iyyer_deep_2015,
	title = {Deep unordered composition rivals syntactic methods for text classification},
	volume = {1},
	url = {http://www.aclweb.org/anthology/P15-1162},
	urldate = {2017-10-04TZ},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	author = {Iyyer, Mohit and Manjunatha, Varun and Boyd-Graber, Jordan and Daumé III, Hal},
	year = {2015},
	pages = {1681--1691}
}

@inproceedings{turian_word_2010,
	title = {Word representations: a simple and general method for semi-supervised learning},
	shorttitle = {Word representations},
	url = {http://dl.acm.org/citation.cfm?id=1858721},
	urldate = {2017-10-04TZ},
	booktitle = {Proceedings of the 48th annual meeting of the association for computational linguistics},
	publisher = {Association for Computational Linguistics},
	author = {Turian, Joseph and Ratinov, Lev and Bengio, Yoshua},
	year = {2010},
	pages = {384--394}
}

@inproceedings{mcadams_ontology_nodate,
	title = {An {Ontology} for {Smart} {Contracts}},
	url = {https://files.zotero.net/19470512428/Darryl%20McAdams%20-%20An%20Ontology%20for%20Smart%20Contracts.pdf},
	author = {McAdams, Darryl}
}

@inproceedings{garay_bitcoin_2015,
	title = {The {Bitcoin} {Backbone} {Protocol}: {Analysis} and {Applications}.},
	url = {https://eprint.iacr.org/2014/765.pdf},
	booktitle = {{EUROCRYPT} (2)},
	author = {Garay, Juan A and Kiayias, Aggelos and Leonardos, Nikos},
	year = {2015},
	pages = {281--310}
}

@article{lau_empirical_2016,
	title = {An {Empirical} {Evaluation} of doc2vec with {Practical} {Insights} into {Document} {Embedding} {Generation}},
	url = {http://arxiv.org/abs/1607.05368},
	abstract = {Recently, Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al., 2013a) to learn document-level embeddings. Despite promising results in the original paper, others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models.},
	urldate = {2017-10-02TZ},
	journal = {arXiv:1607.05368 [cs]},
	author = {Lau, Jey Han and Baldwin, Timothy},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.05368},
	keywords = {Computer Science - Computation and Language}
}

@article{srivastava_modeling_2013,
	title = {Modeling documents with deep boltzmann machines},
	url = {https://arxiv.org/abs/1309.6865},
	urldate = {2017-10-02TZ},
	journal = {arXiv preprint arXiv:1309.6865},
	author = {Srivastava, Nitish and Salakhutdinov, Ruslan R. and Hinton, Geoffrey E.},
	year = {2013}
}

@inproceedings{larochelle_neural_2012,
	title = {A neural autoregressive topic model},
	url = {http://papers.nips.cc/paper/4613-a-neural-autoregressive-topic-model},
	urldate = {2017-10-02TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Larochelle, Hugo and Lauly, Stanislas},
	year = {2012},
	pages = {2708--2716}
}

@inproceedings{maas_learning_2011,
	title = {Learning word vectors for sentiment analysis},
	url = {http://dl.acm.org/citation.cfm?id=2002491},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings of the 49th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}-{Volume} 1},
	publisher = {Association for Computational Linguistics},
	author = {Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher},
	year = {2011},
	pages = {142--150}
}

@inproceedings{zanzotto_estimating_2010,
	title = {Estimating linear models for compositional distributional semantics},
	url = {http://dl.acm.org/citation.cfm?id=1873923},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Zanzotto, Fabio Massimo and Korkontzelos, Ioannis and Fallucchi, Francesca and Manandhar, Suresh},
	year = {2010},
	pages = {1263--1271}
}

@article{liu_automatic_2017,
	title = {Automatic {Argumentative}-{Zoning} {Using} {Word}2vec},
	url = {http://arxiv.org/abs/1703.10152},
	abstract = {In comparison with document summarization on the articles from social media and newswire, argumentative zoning (AZ) is an important task in scientific paper analysis. Traditional methodology to carry on this task relies on feature engineering from different levels. In this paper, three models of generating sentence vectors for the task of sentence classification were explored and compared. The proposed approach builds sentence representations using learned embeddings based on neural network. The learned word embeddings formed a feature space, to which the examined sentence is mapped to. Those features are input into the classifiers for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on the Argumentative-Zoning (AZ) annotated articles. The results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance. In comparison with the hand-crafted features, the word2vec method won for most of the categories. However, the hand-crafted features showed their strength on classifying some of the categories.},
	urldate = {2017-10-02TZ},
	journal = {arXiv:1703.10152 [cs]},
	author = {Liu, Haixia},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.10152},
	keywords = {Computer Science - Computation and Language}
}
@article{cohan_scientific_2017,
	title = {Scientific document summarization via citation contextualization and scientific discourse},
	issn = {1432-5012, 1432-1300},
	url = {http://arxiv.org/abs/1706.03449},
	doi = {10.1007/s00799-017-0216-8},
	abstract = {The rapid growth of scientific literature has made it difficult for the researchers to quickly learn about the developments in their respective fields. Scientific document summarization addresses this challenge by providing summaries of the important contributions of scientific papers. We present a framework for scientific summarization which takes advantage of the citations and the scientific discourse structure. Citation texts often lack the evidence and context to support the content of the cited paper and are even sometimes inaccurate. We first address the problem of inaccuracy of the citation texts by finding the relevant context from the cited paper. We propose three approaches for contextualizing citations which are based on query reformulation, word embeddings, and supervised learning. We then train a model to identify the discourse facets for each citation. We finally propose a method for summarizing scientific papers by leveraging the faceted citations and their corresponding contexts. We evaluate our proposed method on two scientific summarization datasets in the biomedical and computational linguistics domains. Extensive evaluation results show that our methods can improve over the state of the art by large margins.},
	urldate = {2017-10-02TZ},
	journal = {International Journal on Digital Libraries},
	author = {Cohan, Arman and Goharian, Nazli},
	month = may,
	year = {2017},
	note = {arXiv: 1706.03449},
	keywords = {Computer Science - Computation and Language, Computer Science - Digital Libraries}
}

@inproceedings{ai_analysis_2016,
	title = {Analysis of the {Paragraph} {Vector} {Model} for {Information} {Retrieval}},
	isbn = {978-1-4503-4497-5},
	url = {http://dl.acm.org/citation.cfm?doid=2970398.2970409},
	doi = {10.1145/2970398.2970409},
	language = {en},
	urldate = {2017-10-02TZ},
	publisher = {ACM Press},
	author = {Ai, Qingyao and Yang, Liu and Guo, Jiafeng and Croft, W. Bruce},
	year = {2016},
	pages = {133--142}
}

@inproceedings{baroni_dont_2014,
	title = {Don't count, predict! {A} systematic comparison of context-counting vs. context-predicting semantic vectors.},
	url = {http://anthology.aclweb.org/P/P14/P14-1023.pdf},
	urldate = {2017-10-02TZ},
	booktitle = {{ACL} (1)},
	author = {Baroni, Marco and Dinu, Georgiana and Kruszewski, Germán},
	year = {2014},
	pages = {238--247}
}

@inproceedings{dai_semi-supervised_2015,
	title = {Semi-supervised sequence learning},
	url = {http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning},
	urldate = {2017-10-02TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dai, Andrew M. and Le, Quoc V.},
	year = {2015},
	pages = {3079--3087}
}

@article{socher_grounded_2014,
	title = {Grounded compositional semantics for finding and describing images with sentences},
	volume = {2},
	url = {https://www.transacl.org/ojs/index.php/tacl/article/view/325},
	urldate = {2017-10-02TZ},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Socher, Richard and Karpathy, Andrej and Le, Quoc V. and Manning, Christopher D. and Ng, Andrew Y.},
	year = {2014},
	pages = {207--218}
}

@article{wager_dropout_2013,
	title = {Dropout {Training} as {Adaptive} {Regularization}},
	url = {http://arxiv.org/abs/1307.1493},
	abstract = {Dropout and other feature noising schemes control overfitting by artificially corrupting the training data. For generalized linear models, dropout performs a form of adaptive regularization. Using this viewpoint, we show that the dropout regularizer is first-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix. We also establish a connection to AdaGrad, an online learning algorithm, and find that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems. By casting dropout as regularization, we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer. We apply this idea to document classification tasks, and show that it consistently boosts the performance of dropout training, improving on state-of-the-art results on the IMDB reviews dataset.},
	urldate = {2017-10-02TZ},
	journal = {arXiv:1307.1493 [cs, stat]},
	author = {Wager, Stefan and Wang, Sida and Liang, Percy},
	month = jul,
	year = {2013},
	note = {arXiv: 1307.1493},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Statistics - Methodology}
}

@inproceedings{vincent_extracting_2008,
	title = {Extracting and composing robust features with denoising autoencoders},
	url = {http://dl.acm.org/citation.cfm?id=1390294},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning},
	publisher = {ACM},
	author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
	year = {2008},
	pages = {1096--1103}
}

@article{mitchell_composition_2010,
	title = {Composition in distributional models of semantics},
	volume = {34},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1551-6709.2010.01106.x/full},
	number = {8},
	urldate = {2017-10-02TZ},
	journal = {Cognitive science},
	author = {Mitchell, Jeff and Lapata, Mirella},
	year = {2010},
	pages = {1388--1429}
}

@inproceedings{guevara_regression_2010,
	title = {A regression model of adjective-noun compositionality in distributional semantics},
	url = {http://dl.acm.org/citation.cfm?id=1870521},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings of the 2010 {Workshop} on {GEometrical} {Models} of {Natural} {Language} {Semantics}},
	publisher = {Association for Computational Linguistics},
	author = {Guevara, Emiliano},
	year = {2010},
	pages = {33--37}
}

@inproceedings{baroni_nouns_2010,
	title = {Nouns are vectors, adjectives are matrices: {Representing} adjective-noun constructions in semantic space},
	shorttitle = {Nouns are vectors, adjectives are matrices},
	url = {http://dl.acm.org/citation.cfm?id=1870773},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings of the 2010 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Baroni, Marco and Zamparelli, Roberto},
	year = {2010},
	pages = {1183--1193}
}

@misc{noauthor_d10-1115.pdf_nodate,
	title = {D10-1115.pdf},
	url = {http://www.aclweb.org/anthology/D10-1115},
	urldate = {2017-10-02TZ}
}

@inproceedings{medic_does_2017,
	title = {Does {Free} {Word} {Order} {Hurt}? {Assessing} the {Practical} {Lexical} {Function} {Model} for {Croatian}},
	url = {http://www.aclweb.org/anthology/S17-1014},
	booktitle = {*{SEM}},
	author = {Medic, Zoran and Snajder, Jan and Padó, Sebastian},
	year = {2017}
}

@article{grefenstette_multi-step_2013,
	title = {Multi-step regression learning for compositional distributional semantics},
	url = {https://arxiv.org/abs/1301.6939},
	urldate = {2017-10-02TZ},
	journal = {arXiv preprint arXiv:1301.6939},
	author = {Grefenstette, Edward and Dinu, Georgiana and Zhang, Yao-Zhong and Sadrzadeh, Mehrnoosh and Baroni, Marco},
	year = {2013}
}

@inproceedings{zhao_self-adaptive_2015,
	title = {Self-{Adaptive} {Hierarchical} {Sentence} {Model}.},
	url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/download/10828/11307},
	urldate = {2017-10-02TZ},
	booktitle = {{IJCAI}},
	author = {Zhao, Han and Lu, Zhengdong and Poupart, Pascal},
	year = {2015},
	pages = {4069--4076}
}

@article{kalchbrenner_convolutional_2014,
	title = {A convolutional neural network for modelling sentences},
	url = {https://arxiv.org/abs/1404.2188},
	urldate = {2017-10-02TZ},
	journal = {arXiv preprint arXiv:1404.2188},
	author = {Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil},
	year = {2014}
}

@article{kiros_skip-thought_2015,
	title = {Skip-{Thought} {Vectors}},
	url = {https://arxiv.org/pdf/1506.06726.pdf},
	abstract = {We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.},
	urldate = {2017-09-28TZ},
	journal = {arXiv:1506.06726 [cs]},
	author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan and Zemel, Richard S. and Torralba, Antonio and Urtasun, Raquel and Fidler, Sanja},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.06726},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning}
}

@article{tan_scalable_2012,
	title = {A scalable distributed syntactic, semantic, and lexical language model},
	volume = {38},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/COLI_a_00107},
	number = {3},
	urldate = {2017-10-02TZ},
	journal = {Computational Linguistics},
	author = {Tan, Ming and Zhou, Wenli and Zheng, Lei and Wang, Shaojun},
	year = {2012},
	pages = {631--671}
}

@inproceedings{shazeer_sparse_2015,
	title = {Sparse non-negative matrix language modeling for skip-grams},
	url = {https://lirias.kuleuven.be/bitstream/123456789/511499/1/3976_postprint.pdf},
	urldate = {2017-10-02TZ},
	booktitle = {Proceedings {Interspeech} 2015},
	author = {Shazeer, Noam and Pelemans, Joris and Chelba, Ciprian},
	year = {2015},
	pages = {1428--1432}
}

@inproceedings{prechelt_early_1998,
	address = {London, UK, UK},
	title = {Early {Stopping}-{But} {When}?},
	isbn = {3-540-65311-2},
	url = {http://dl.acm.org/citation.cfm?id=645754.668392},
	booktitle = {Neural {Networks}: {Tricks} of the {Trade}, {This} {Book} is an {Outgrowth} of a 1996 {NIPS} {Workshop}},
	publisher = {Springer-Verlag},
	author = {Prechelt, Lutz},
	year = {1998},
	pages = {55--69}
}

@article{cer_semeval-2017_2017,
	title = {{SemEval}-2017 {Task} 1: {Semantic} {Textual} {Similarity}-{Multilingual} and {Cross}-lingual {Focused} {Evaluation}},
	shorttitle = {{SemEval}-2017 {Task} 1},
	url = {https://arxiv.org/abs/1708.00055},
	urldate = {2017-09-26TZ},
	journal = {arXiv preprint arXiv:1708.00055},
	author = {Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
	year = {2017}
}

@article{lund_producing_1996,
	title = {Producing high-dimensional semantic spaces from lexical co-occurrence},
	volume = {28},
	url = {http://link.springer.com/article/10.3758/BF03204766},
	number = {2},
	urldate = {2017-09-25TZ},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Lund, Kevin and Burgess, Curt},
	year = {1996},
	keywords = {HAL},
	pages = {203--208}
}

@book{lund_semantic_1995,
	title = {Semantic and associative priming in high-dimensional semantic space},
	author = {Lund, Kevin and Burgess, Curt and Atchley, Ruth},
	month = jan,
	year = {1995},
	keywords = {HAL}
}

@inproceedings{glorot_domain_2011,
	title = {Domain adaptation for large-scale sentiment classification: {A} deep learning approach},
	shorttitle = {Domain adaptation for large-scale sentiment classification},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Glorot_342.pdf},
	urldate = {2017-09-25TZ},
	booktitle = {Proceedings of the 28th international conference on machine learning ({ICML}-11)},
	author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	year = {2011},
	pages = {513--520}
}

@article{chen_marginalized_2012,
	title = {Marginalized {Denoising} {Autoencoders} for {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/1206.4683},
	abstract = {Stacked denoising autoencoders (SDAs) have been successfully used to learn new representations for domain adaptation. Recently, they have attained record accuracy on standard benchmark tasks of sentiment analysis across different text domains. SDAs learn robust data representations by reconstruction, recovering original features from data that are artificially corrupted with noise. In this paper, we propose marginalized SDA (mSDA) that addresses two crucial limitations of SDAs: high computational cost and lack of scalability to high-dimensional features. In contrast to SDAs, our approach of mSDA marginalizes noise and thus does not require stochastic gradient descent or other optimization algorithms to learn parameters ? in fact, they are computed in closed-form. Consequently, mSDA, which can be implemented in only 20 lines of MATLAB{\textasciicircum}\{TM\}, significantly speeds up SDAs by two orders of magnitude. Furthermore, the representations learnt by mSDA are as effective as the traditional SDAs, attaining almost identical accuracies in benchmark tasks.},
	urldate = {2017-09-25TZ},
	journal = {arXiv:1206.4683 [cs]},
	author = {Chen, Minmin and Xu, Zhixiang and Weinberger, Kilian and Sha, Fei},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.4683},
	keywords = {Computer Science - Learning}
}

@inproceedings{bengio_deep_2012,
	address = {Bellevue, Washington, USA},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Deep {Learning} of {Representations} for {Unsupervised} and {Transfer} {Learning}},
	volume = {27},
	url = {http://proceedings.mlr.press/v27/bengio12a/bengio12a.pdf},
	abstract = {Deep learning algorithms seek to exploit the unknown structure in the input distribution in order to discover good representations, often at multiple levels, with higher-level learned features defined in terms of lower-level features. The objective is to make these higher-level representations more abstract, with their individual features more invariant to most of the variations that are typically present in the training distribution, while collectively preserving as much as possible of the information in the input. Ideally, we would like these representations to disentangle the unknown factors of variation that underlie the training distribution. Such unsupervised learning of representations can be exploited usefully under the hypothesis that the input distribution \$P(x)\$ is structurally related to some task of interest, say predicting \$P(y{\textbar}x)\$. This paper focuses on the context of the Unsupervised and Transfer Learning Challenge, on why unsupervised pre-training of representations can be useful, and how it can be exploited in the transfer learning scenario, where we care about predictions on examples that are not from the same distribution as the training distribution.},
	booktitle = {Proceedings of {ICML} {Workshop} on {Unsupervised} and {Transfer} {Learning}},
	publisher = {PMLR},
	author = {Bengio, Yoshua},
	editor = {Guyon, Isabelle and Dror, Gideon and Lemaire, Vincent and Taylor, Graham and Silver, Daniel},
	month = jul,
	year = {2012},
	pages = {17--36}
}

@article{pan_survey_2010,
	title = {A {Survey} on {Transfer} {Learning}},
	volume = {22},
	issn = {1041-4347},
	url = {https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf},
	doi = {10.1109/TKDE.2009.191},
	abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
	number = {10},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Pan, S. J. and Yang, Q.},
	month = oct,
	year = {2010},
	keywords = {Data mining, Knowledge engineering, Knowledge transfer, Labeling, Learning systems, Machine learning, Machine learning algorithms, Space technology, Testing, Training data, Transfer learning, data mining, data mining., inductive transfer learning, knowledge engineering, knowledge transfer, learning by example, machine learning, optimisation, survey, transductive transfer learning, unsupervised learning, unsupervised transfer learning},
	pages = {1345--1359}
}

@article{ganin_unsupervised_2014,
	title = {Unsupervised {Domain} {Adaptation} by {Backpropagation}},
	url = {http://arxiv.org/abs/1409.7495},
	abstract = {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of "deep" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation. Overall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.},
	urldate = {2017-09-22TZ},
	journal = {arXiv:1409.7495 [cs, stat]},
	author = {Ganin, Yaroslav and Lempitsky, Victor},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.7495},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{tzeng_adversarial_2017,
	title = {Adversarial {Discriminative} {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/1702.05464},
	abstract = {Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They also can improve recognition despite the presence of domain shift or dataset bias: several adversarial approaches to unsupervised domain adaptation have recently been introduced, which reduce the difference between the training and test domain distributions and thus improve generalization performance. Prior generative approaches show compelling visualizations, but are not optimal on discriminative tasks and can be limited to smaller shifts. Prior discriminative approaches could handle larger domain shifts, but imposed tied weights on the model and did not exploit a GAN-based loss. We first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and we use this generalized view to better relate the prior approaches. We propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard cross-domain digit classification tasks and a new more difficult cross-modality object classification task.},
	urldate = {2017-09-21TZ},
	journal = {arXiv:1702.05464 [cs]},
	author = {Tzeng, Eric and Hoffman, Judy and Saenko, Kate and Darrell, Trevor},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.05464},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{jozefowicz_exploring_2016,
	title = {Exploring the {Limits} of {Language} {Modeling}},
	url = {http://arxiv.org/abs/1602.02410},
	abstract = {In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.},
	urldate = {2017-09-21TZ},
	journal = {arXiv:1602.02410 [cs]},
	author = {Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.02410},
	keywords = {Computer Science - Computation and Language}
}

@article{radford_unsupervised_2015,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2017-09-21TZ},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.06434},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning}
}

@article{rumelhart_learning_1988,
	title = {Learning representations by back-propagating errors},
	volume = {5},
	number = {3},
	journal = {Cognitive modeling},
	author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and {others}},
	year = {1988},
	pages = {1}
}

@article{polyak_methods_1964,
	title = {Some methods of speeding up the convergence of iteration methods},
	volume = {4},
	issn = {0041-5553},
	url = {http://www.sciencedirect.com/science/article/pii/0041555364901375},
	doi = {10.1016/0041-5553(64)90137-5},
	abstract = {For the solution of the functional equation P (x) = 0 (1) (where P is an operator, usually linear, from B into B, and B is a Banach space) iteration methods are generally used. These consist of the construction of a series x0, …, xn, …, which converges to the solution (see, for example [1]). Continuous analogues of these methods are also known, in which a trajectory x(t), 0 ⩽ t ⩽ ∞ is constructed, which satisfies the ordinary differential equation in B and is such that x(t) approaches the solution of (1) as t → ∞ (see [2]). We shall call the method a k-step method if for the construction of each successive iteration xn+1 we use k previous iterations xn, …, xn−k+1. The same term will also be used for continuous methods if x(t) satisfies a differential equation of the k-th order or k-th degree. Iteration methods which are more widely used are one-step (e.g. methods of successive approximations). They are generally simple from the calculation point of view but often converge very slowly. This is confirmed both by the evaluation of the speed of convergence and by calculation in practice (for more details see below). Therefore the question of the rate of convergence is most important. Some multistep methods, which we shall consider further, which are only slightly more complicated than the corresponding one-step methods, make it possible to speed up the convergence substantially. Note that all the methods mentioned below are applicable also to the problem of minimizing the differentiable functional (x) in Hilbert space, so long as this problem reduces to the solution of the equation grad (x) = 0.},
	number = {5},
	urldate = {2017-09-12TZ},
	journal = {USSR Computational Mathematics and Mathematical Physics},
	author = {Polyak, B. T.},
	month = jan,
	year = {1964},
	pages = {1--17}
}

@article{epelbaum_deep_2017,
	title = {Deep learning: {Technical} introduction},
	shorttitle = {Deep learning},
	url = {http://arxiv.org/abs/1709.01412},
	abstract = {This note presents in a technical though hopefully pedagogical way the three most common forms of neural network architectures: Feedforward, Convolutional and Recurrent. For each network, their fundamental building blocks are detailed. The forward pass and the update rules for the backpropagation algorithm are then derived in full.},
	urldate = {2017-09-10TZ},
	journal = {arXiv:1709.01412 [cs, stat]},
	author = {Epelbaum, Thomas},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.01412},
	keywords = {Computer Science - Learning, Statistics - Machine Learning}
}

@book{jurafsky_speech_2014,
	title = {Speech and language processing},
	volume = {3},
	url = {http://www.cs.colorado.edu/~martin/SLP/Updates/1.pdf},
	urldate = {2017-09-09TZ},
	publisher = {Pearson London},
	author = {Jurafsky, Dan and Martin, James H.},
	year = {2014}
}

@article{lee_generalizing_2015,
	title = {Generalizing {Pooling} {Functions} in {Convolutional} {Neural} {Networks}: {Mixed}, {Gated}, and {Tree}},
	shorttitle = {Generalizing {Pooling} {Functions} in {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1509.08985},
	abstract = {We seek to improve deep neural networks by generalizing the pooling operations that play a central role in current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets; they are also easy to implement, and can be applied within various deep neural network architectures. These benefits come with only a light increase in computational overhead during training and a very modest increase in the number of model parameters.},
	urldate = {2017-09-08TZ},
	journal = {arXiv:1509.08985 [cs, stat]},
	author = {Lee, Chen-Yu and Gallagher, Patrick W. and Tu, Zhuowen},
	month = sep,
	year = {2015},
	note = {arXiv: 1509.08985},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@book{index_global_2013,
	title = {Global mobile data traffic forecast update, 2012-2017},
	author = {Index, Cisco Visual Networking},
	year = {2013}
}

@incollection{jurafsky_vector_nodate,
	title = {Vector {Semantics}},
	url = {https://web.stanford.edu/~jurafsky/slp3/15.pdf},
	booktitle = {Speech and {Language} {Processing}},
	author = {Jurafsky, Daniel and Martin, James H.}
}

@article{deerwester_indexing_1990,
	title = {Indexing by latent semantic analysis},
	volume = {41},
	url = {http://search.proquest.com/openview/a1907164bd88dfc38a4875b73a3f7b3d/1?pq-origsite=gscholar&cbl=1818555},
	number = {6},
	urldate = {2017-09-06TZ},
	journal = {Journal of the American society for information science},
	author = {Deerwester, Scott and Dumais, Susan T. and Furnas, George W. and Landauer, Thomas K. and Harshman, Richard},
	year = {1990},
	pages = {391}
}

@inproceedings{levy_neural_2014,
	title = {Neural word embedding as implicit matrix factorization},
	url = {http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization},
	urldate = {2017-09-05TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Levy, Omer and Goldberg, Yoav},
	year = {2014},
	pages = {2177--2185}
}

@article{harris_distributional_1954,
	title = {Distributional {Structure}},
	volume = {10},
	issn = {0043-7956, 2373-5112},
	url = {http://www.tandfonline.com/doi/full/10.1080/00437956.1954.11659520},
	doi = {10.1080/00437956.1954.11659520},
	language = {en},
	number = {2-3},
	urldate = {2017-09-05TZ},
	journal = {\textit{WORD}},
	author = {Harris, Zellig S.},
	month = aug,
	year = {1954},
	pages = {146--162}
}

@inproceedings{das_gaussian_2015,
	title = {Gaussian {LDA} for {Topic} {Models} with {Word} {Embeddings}.},
	url = {http://www.aclweb.org/old_anthology/P/P15/P15-1077.pdf},
	urldate = {2017-09-05TZ},
	booktitle = {{ACL} (1)},
	author = {Das, Rajarshi and Zaheer, Manzil and Dyer, Chris},
	year = {2015},
	pages = {795--804}
}

@article{sparck_jones_statistical_1972,
	title = {A statistical interpretation of term specificity and its application in retrieval},
	volume = {28},
	url = {http://www.emeraldinsight.com/doi/abs/10.1108/eb026526},
	number = {1},
	urldate = {2017-09-04TZ},
	journal = {Journal of documentation},
	author = {Sparck Jones, Karen},
	year = {1972},
	pages = {11--21}
}

@article{sahlgren_distributional_2008,
	title = {The distributional hypothesis},
	volume = {20},
	url = {http://www.diva-portal.org/smash/get/diva2:1035870/FULLTEXT01.pdf},
	urldate = {2017-08-24TZ},
	journal = {Italian Journal of Disability Studies},
	author = {Sahlgren, Magnus},
	year = {2008},
	pages = {33--53}
}

@misc{noauthor_coi32103.dvi_nodate,
	title = {coi32103.dvi - coli.2006.32.1.13.pdf},
	url = {http://delivery.acm.org/10.1145/1170000/1168108/coli.2006.32.1.13.pdf?ip=134.96.191.252&id=1168108&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&CFID=976201936&CFTOKEN=49675072&__acm__=1503579624_f65c7d77466d3489c90247a4b42b811c},
	urldate = {2017-08-24TZ}
}

@incollection{dagan_pascal_2006,
	title = {The {PASCAL} recognising textual entailment challenge},
	url = {ftp://nozdr.ru/biblio/kolxo3/Cs/CsLn/Machine%20Learning%20Challenges,%201%20conf.,%20MLCW%202005(LNCS3944,%20Springer,%202006)(ISBN%203540334270)(473s).pdf#page=188},
	booktitle = {Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment},
	publisher = {Springer},
	author = {Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
	year = {2006},
	pages = {177--190}
}

@article{bentivogli_sick_2016,
	title = {{SICK} through the {SemEval} glasses. {Lesson} learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment},
	volume = {50},
	issn = {1574-020X, 1574-0218},
	url = {http://link.springer.com/10.1007/s10579-015-9332-5},
	doi = {10.1007/s10579-015-9332-5},
	language = {en},
	number = {1},
	urldate = {2017-08-23TZ},
	journal = {Language Resources and Evaluation},
	author = {Bentivogli, Luisa and Bernardi, Raffaella and Marelli, Marco and Menini, Stefano and Baroni, Marco and Zamparelli, Roberto},
	month = mar,
	year = {2016},
	pages = {95--124}
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2017-08-17TZ},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning}
}

@inproceedings{marelli_semeval-2014_2014,
	title = {{SemEval}-2014 {Task} 1: {Evaluation} of {Compositional} {Distributional} {Semantic} {Models} on {Full} {Sentences} through {Semantic} {Relatedness} and {Textual} {Entailment}.},
	shorttitle = {{SemEval}-2014 {Task} 1},
	url = {https://www.aclweb.org/anthology/S/S14/S14-2.pdf#page=21},
	urldate = {2017-08-14TZ},
	booktitle = {{SemEval}@ {COLING}},
	author = {Marelli, Marco and Bentivogli, Luisa and Baroni, Marco and Bernardi, Raffaella and Menini, Stefano and Zamparelli, Roberto},
	year = {2014},
	pages = {1--8}
}

@inproceedings{annesi_semantic_2014,
	address = {New York, NY, USA},
	series = {{CIKM} '14},
	title = {Semantic {Compositionality} in {Tree} {Kernels}},
	isbn = {978-1-4503-2598-1},
	url = {http://doi.acm.org/10.1145/2661829.2661955},
	doi = {10.1145/2661829.2661955},
	abstract = {Kernel-based learning has been largely applied to semantic textual inference tasks. In particular, Tree Kernels (TKs) are crucial in the modeling of syntactic similarity between linguistic instances in Question Answering or Information Extraction tasks. At the same time, lexical semantic information has been studied through the adoption of the so-called Distributional Semantics (DS) paradigm, where lexical vectors are acquired automatically from large corpora. Notice how methods to account for compositional linguistic structures (e.g. grammatically typed bi-grams or complex verb or noun phrases) have been proposed recently by defining algebras on lexical vectors. The result is an extended paradigm called Distributional Compositional Semantics (DCS). Although lexical extensions have been already proposed to generalize TKs towards semantic phenomena (e.g. the predicate argument structures as for role labeling), currently studied TKs do not account for compositionality, in general. In this paper, a novel kernel called Compositionally Smoothed Partial Tree Kernel is proposed to integrate DCS operators into the tree kernel evaluation, by acting both over lexical leaves and non-terminal, i.e. complex compositional, nodes. The empirical results obtained on a Question Classification and Paraphrase Identification tasks show that state-of-the-art performances can be achieved, without resorting to manual feature engineering, thus suggesting that a large set of Web and text mining tasks can be handled successfully by the kernel proposed here.},
	urldate = {2017-08-10TZ},
	booktitle = {Proceedings of the 23rd {ACM} {International} {Conference} on {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Annesi, Paolo and Croce, Danilo and Basili, Roberto},
	year = {2014},
	keywords = {compositional distributional semantics, kernel machines, natural language processing, tree kernel},
	pages = {1029--1038}
}

@article{oliva_symss:_2011,
	title = {{SyMSS}: {A} syntax-based measure for short-text semantic similarity},
	volume = {70},
	issn = {0169023X},
	shorttitle = {{SyMSS}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0169023X11000036},
	doi = {10.1016/j.datak.2011.01.002},
	language = {en},
	number = {4},
	urldate = {2017-08-09TZ},
	journal = {Data \& Knowledge Engineering},
	author = {Oliva, Jesús and Serrano, José Ignacio and del Castillo, María Dolores and Iglesias, Ángel},
	month = apr,
	year = {2011},
	pages = {390--405}
}

@article{islam_semantic_2008,
	title = {Semantic text similarity using corpus-based word similarity and string similarity},
	volume = {2},
	url = {http://dl.acm.org/citation.cfm?id=1376819},
	number = {2},
	urldate = {2017-08-09TZ},
	journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
	author = {Islam, Aminul and Inkpen, Diana},
	year = {2008},
	pages = {10}
}

@article{quan_short_2010,
	title = {Short text similarity based on probabilistic topics},
	volume = {25},
	issn = {0219-1377, 0219-3116},
	url = {https://link.springer.com/article/10.1007/s10115-009-0250-y},
	doi = {10.1007/s10115-009-0250-y},
	abstract = {In this paper, we propose a new method for measuring the similarity between two short text snippets by comparing each of them with the probabilistic topics. Specifically, our method starts by firstly finding the distinguishing terms between the two short text snippets and comparing them with a series of probabilistic topics, extracted by Gibbs sampling algorithm. The relationship between the distinguishing terms of the short text snippets can be discovered by examining their probabilities under each topic. The similarity between two short text snippets is calculated based on their common terms and the relationship of their distinguishing terms. Extensive experiments on paraphrasing and question categorization show that the proposed method can calculate the similarity of short text snippets more accurately than other methods including the pure TF-IDF measure.},
	language = {en},
	number = {3},
	urldate = {2017-08-09TZ},
	journal = {Knowledge and Information Systems},
	author = {Quan, Xiaojun and Liu, Gang and Lu, Zhi and Ni, Xingliang and Wenyin, Liu},
	month = dec,
	year = {2010},
	pages = {473--491}
}

@misc{noauthor_web-based_nodate,
	title = {A {Web}-based {Kernel} {Function} for {Measuring} the {Similarity} of {Short} {Text} {Snippets}},
	url = {http://www2006.org/programme/files/xhtml/3069/3069-sahami/3069-sahami-xhtml.html},
	urldate = {2017-08-09TZ}
}

@inproceedings{kenter_short_2015,
	title = {Short {Text} {Similarity} with {Word} {Embeddings}},
	isbn = {978-1-4503-3794-6},
	url = {http://dl.acm.org/citation.cfm?doid=2806416.2806475},
	doi = {10.1145/2806416.2806475},
	language = {en},
	urldate = {2017-08-09TZ},
	publisher = {ACM Press},
	author = {Kenter, Tom and de Rijke, Maarten},
	year = {2015},
	pages = {1411--1420}
}

@article{oshea_comparative_2008,
	title = {A comparative study of two short text semantic similarity measures},
	url = {http://www.springerlink.com/index/V0867641U342PM28.pdf},
	urldate = {2017-08-09TZ},
	journal = {Agent and Multi-Agent Systems: Technologies and Applications},
	author = {O’Shea, James and Bandar, Zuhair and Crockett, Keeley and McLean, David},
	year = {2008},
	pages = {172--181}
}

@article{bojanowski_enriching_2016,
	title = {Enriching {Word} {Vectors} with {Subword} {Information}},
	url = {http://arxiv.org/abs/1607.04606},
	abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character \$n\$-grams. A vector representation is associated to each character \$n\$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
	urldate = {2017-08-04TZ},
	journal = {arXiv:1607.04606 [cs]},
	author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.04606},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning}
}

@article{gomaa_survey_2013,
	title = {A survey of text similarity approaches},
	volume = {68},
	number = {13},
	journal = {International Journal of Computer Applications},
	author = {Gomaa, Wael H and Fahmy, Aly A},
	year = {2013}
}

@misc{noauthor_survey_nodate,
	title = {A {Survey} of {Text} {Similarity} {Approaches} - {A}\_Survey\_of\_Text\_Similarity\_Approaches.pdf},
	url = {http://s3.amazonaws.com/academia.edu.documents/35754965/A_Survey_of_Text_Similarity_Approaches.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1501679464&Signature=a8RMn77ifYkQQ%2BBX8BWfoX%2Fly1c%3D&response-content-disposition=inline%3B%20filename%3DA_Survey_of_Text_Similarity_Approaches.pdf},
	urldate = {2017-08-02TZ}
}

@book{krause_taxicab_1987,
	address = {New York},
	title = {Taxicab {Geometry}: an adventure in non-{Euclidean} geometry},
	isbn = {978-0-486-25202-5},
	shorttitle = {Taxicab {Geometry}},
	abstract = {Develops a simple non-Euclidean geometry and explores some of its practical applications through graphs, research problems, and exercises. Includes selected answers},
	publisher = {Dover Publications},
	author = {Krause, Eugene F.},
	year = {1987},
	keywords = {Geometry, Non-Euclidean, Juvenile literature}
}

@article{agirre_sem_2013,
	title = {{SEM} 2013 shared task: {Semantic} {Textual} {Similarity}},
	url = {http://www.aclweb.org/website/old_anthology/S/S13/S13-1.pdf#page=58},
	urldate = {2017-07-29TZ},
	journal = {Atlanta, Georgia, USA},
	author = {Agirre, Eneko and Cer, Daniel and Diab, Mona and Gonzalez-Agirre, Aitor and Guo, Weiwei},
	year = {2013},
	pages = {32}
}

@article{pascanu_difficulty_2012,
	title = {On the difficulty of training {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1211.5063},
	abstract = {There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
	urldate = {2017-07-28TZ},
	journal = {arXiv:1211.5063 [cs]},
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	month = nov,
	year = {2012},
	note = {arXiv: 1211.5063},
	keywords = {Computer Science - Learning}
}

@inproceedings{mueller_siamese_2016,
	title = {Siamese {Recurrent} {Architectures} for {Learning} {Sentence} {Similarity}.},
	url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12195/12023},
	urldate = {2017-07-26TZ},
	booktitle = {{AAAI}},
	author = {Mueller, Jonas and Thyagarajan, Aditya},
	year = {2016},
	keywords = {Manhatten distance},
	pages = {2786--2792}
}
@article{wang_sentence_2016,
	title = {Sentence {Similarity} {Learning} by {Lexical} {Decomposition} and {Composition}},
	url = {http://arxiv.org/abs/1602.07019},
	abstract = {Most conventional sentence similarity methods only focus on similar parts of two input sentences, and simply ignore the dissimilar parts, which usually give us some clues and semantic meanings about the sentences. In this work, we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences. The model represents each word as a vector, and calculates a semantic matching vector for each word based on all words in the other sentence. Then, each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector. After this, a two-channel CNN model is employed to capture features by composing the similar and dissimilar components. Finally, a similarity score is estimated over the composed feature vectors. Experimental results show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.},
	urldate = {2017-07-26TZ},
	journal = {arXiv:1602.07019 [cs]},
	author = {Wang, Zhiguo and Mi, Haitao and Ittycheriah, Abraham},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.07019},
	keywords = {Computer Science - Computation and Language}
}

@article{huang_paraphrase_2011,
	title = {Paraphrase detection using recursive autoencoder},
	url = {http://www-nlp.stanford.edu/courses/cs224n/2011/reports/ehhuang.pdf},
	urldate = {2017-07-26TZ},
	journal = {Source:[http://nlp. stanford. edu/courses/cs224n/2011/reports/ehhuang. pdf]},
	author = {Huang, Eric},
	year = {2011}
}

@article{eger_neural_2017,
	title = {Neural {End}-to-{End} {Learning} for {Computational} {Argumentation} {Mining}},
	url = {http://arxiv.org/abs/1704.06104},
	abstract = {We investigate neural techniques for end-to-end computational argumentation mining (AM). We frame AM both as a token-based dependency parsing and as a token-based sequence tagging problem, including a multi-task learning setup. Contrary to models that operate on the argument component level, we find that framing AM as dependency parsing leads to subpar performance results. In contrast, less complex (local) tagging models based on BiLSTMs perform robustly across classification scenarios, being able to catch long-range dependencies inherent to the AM problem. Moreover, we find that jointly learning 'natural' subtasks, in a multi-task learning setup, improves performance.},
	urldate = {2017-07-21TZ},
	journal = {arXiv:1704.06104 [cs]},
	author = {Eger, Steffen and Daxenberger, Johannes and Gurevych, Iryna},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.06104},
	keywords = {Computer Science - Computation and Language}
}

@misc{noauthor_dataset-sts:_2017,
	title = {dataset-sts: {Semantic} {Text} {Similarity} {Dataset} {Hub}},
	shorttitle = {dataset-sts},
	url = {https://github.com/brmson/dataset-sts},
	urldate = {2017-07-21TZ},
	publisher = {brmson},
	month = jul,
	year = {2017},
	note = {original-date: 2016-01-21T03:22:10Z}
}

@misc{alvations_stasis:_2017,
	title = {stasis: {Semantic} {Textual} {Similarity} in {Python}},
	shorttitle = {stasis},
	url = {https://github.com/alvations/stasis},
	urldate = {2017-07-21TZ},
	author = {alvations},
	month = jul,
	year = {2017},
	note = {original-date: 2015-01-23T10:03:11Z},
	keywords = {dataset, python, semantic-textual-similarity, semeval}
}

@inproceedings{marelli_sick_2014,
	title = {A {SICK} cure for the evaluation of compositional distributional semantic models.},
	url = {http://clic.cimec.unitn.it/marco/publications/marelli-etal-sick-lrec2014.pdf},
	urldate = {2017-06-12TZ},
	booktitle = {{LREC}},
	author = {Marelli, Marco and Menini, Stefano and Baroni, Marco and Bentivogli, Luisa and Bernardi, Raffaella and Zamparelli, Roberto},
	year = {2014},
	pages = {216--223}
}

@article{kokkinos_structural_2017,
	title = {Structural {Attention} {Neural} {Networks} for improved sentiment analysis},
	url = {http://arxiv.org/abs/1701.01811},
	abstract = {We introduce a tree-structured attention neural network for sentences and small phrases and apply it to the problem of sentiment classification. Our model expands the current recursive models by incorporating structural information around a node of a syntactic tree using both bottom-up and top-down information propagation. Also, the model utilizes structural attention to identify the most salient representations during the construction of the syntactic tree. To our knowledge, the proposed models achieve state of the art performance on the Stanford Sentiment Treebank dataset.},
	urldate = {2017-07-04TZ},
	journal = {arXiv:1701.01811 [cs]},
	author = {Kokkinos, Filippos and Potamianos, Alexandros},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.01811},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing}
}

@article{zhang_characterizing_2017,
	title = {Characterizing {Online} {Discussion} {Using} {Coarse} {Discourse} {Sequences}},
	url = {http://people.csail.mit.edu/axz/papers/discourse.pdf},
	urldate = {2017-07-03TZ},
	author = {Zhang, Amy X. and Culbertson, Bryan and Paritosh, Praveen},
	year = {2017}
}

@article{zayats_conversation_2017,
	title = {Conversation {Modeling} on {Reddit} using a {Graph}-{Structured} {LSTM}},
	url = {http://arxiv.org/abs/1704.02080},
	abstract = {This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM which represents both hierarchical and temporal conversation structure. In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features. Analyses show a benefit to the model over the full course of the discussion, improving detection in both early and late stages. Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments.},
	urldate = {2017-06-26TZ},
	journal = {arXiv:1704.02080 [cs]},
	author = {Zayats, Vicky and Ostendorf, Mari},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.02080},
	keywords = {Computer Science - Computation and Language}
}

@article{amigo_comparison_2009,
	title = {A comparison of extrinsic clustering evaluation metrics based on formal constraints},
	volume = {12},
	url = {http://link.springer.com/article/10.1007/s10791-008-9066-8},
	number = {4},
	urldate = {2017-06-26TZ},
	journal = {Information retrieval},
	author = {Amigó, Enrique and Gonzalo, Julio and Artiles, Javier and Verdejo, Felisa},
	year = {2009},
	pages = {461--486}
}

@article{chung_empirical_2014,
	title = {Empirical {Evaluation} of {Gated} {Recurrent} {Neural} {Networks} on {Sequence} {Modeling}},
	url = {http://arxiv.org/abs/1412.3555},
	abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
	urldate = {2017-06-26TZ},
	journal = {arXiv:1412.3555 [cs]},
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.3555},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing}
}

@article{karpathy_visualizing_2015,
	title = {Visualizing and {Understanding} {Recurrent} {Networks}},
	url = {http://arxiv.org/abs/1506.02078},
	abstract = {Recurrent Neural Networks (RNNs), and specifically a variant with Long Short-Term Memory (LSTM), are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data. However, while LSTMs provide exceptional results in practice, the source of their performance and their limitations remain rather poorly understood. Using character-level language models as an interpretable testbed, we aim to bridge this gap by providing an analysis of their representations, predictions and error types. In particular, our experiments reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets. Moreover, our comparative analysis with finite horizon n-gram models traces the source of the LSTM improvements to long-range structural dependencies. Finally, we provide analysis of the remaining errors and suggests areas for further study.},
	urldate = {2017-06-26TZ},
	journal = {arXiv:1506.02078 [cs]},
	author = {Karpathy, Andrej and Johnson, Justin and Fei-Fei, Li},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.02078},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing}
}

@article{le_quantifying_2016,
	title = {Quantifying the vanishing gradient and long distance dependency problem in recursive neural networks and recursive {LSTMs}},
	url = {http://arxiv.org/abs/1603.00423},
	abstract = {Recursive neural networks (RNN) and their recently proposed extension recursive long short term memory networks (RLSTM) are models that compute representations for sentences, by recursively combining word embeddings according to an externally provided parse tree. Both models thus, unlike recurrent networks, explicitly make use of the hierarchical structure of a sentence. In this paper, we demonstrate that RNNs nevertheless suffer from the vanishing gradient and long distance dependency problem, and that RLSTMs greatly improve over RNN's on these problems. We present an artificial learning task that allows us to quantify the severity of these problems for both models. We further show that a ratio of gradients (at the root node and a focal leaf node) is highly indicative of the success of backpropagation at optimizing the relevant weights low in the tree. This paper thus provides an explanation for existing, superior results of RLSTMs on tasks such as sentiment analysis, and suggests that the benefits of including hierarchical structure and of including LSTM-style gating are complementary.},
	urldate = {2017-06-26TZ},
	journal = {arXiv:1603.00423 [cs]},
	author = {Le, Phong and Zuidema, Willem},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.00423},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing}
}

@inproceedings{dima_reverse-engineering_2015,
	title = {Reverse-engineering {Language}: {A} {Study} on the {Semantic} {Compositionality} of {German} {Compounds}.},
	shorttitle = {Reverse-engineering {Language}},
	url = {http://www.aclweb.org/old_anthology/D/D15/D15-1188.pdf},
	urldate = {2017-06-22TZ},
	booktitle = {{EMNLP}},
	author = {Dima, Corina},
	year = {2015},
	pages = {1637--1642}
}

@article{wieting_paraphrase_2015,
	title = {From {Paraphrase} {Database} to {Compositional} {Paraphrase} {Model} and {Back}},
	url = {http://arxiv.org/abs/1506.03487},
	abstract = {The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive semantic resource, consisting of a list of phrase pairs with (heuristic) confidence estimates. However, it is still unclear how it can best be used, due to the heuristic nature of the confidences and its necessarily incomplete coverage. We propose models to leverage the phrase pairs from the PPDB to build parametric paraphrase models that score paraphrase pairs more accurately than the PPDB's internal scores while simultaneously improving its coverage. They allow for learning phrase embeddings as well as improved word embeddings. Moreover, we introduce two new, manually annotated datasets to evaluate short-phrase paraphrasing models. Using our paraphrase model trained using PPDB, we achieve state-of-the-art results on standard word and bigram similarity tasks and beat strong baselines on our new short phrase paraphrase tasks.},
	urldate = {2017-06-22TZ},
	journal = {arXiv:1506.03487 [cs]},
	author = {Wieting, John and Bansal, Mohit and Gimpel, Kevin and Livescu, Karen and Roth, Dan},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.03487},
	keywords = {Computer Science - Computation and Language}
}

@article{levy_improving_2015,
	title = {Improving distributional similarity with lessons learned from word embeddings},
	volume = {3},
	url = {https://www.transacl.org/ojs/index.php/tacl/article/view/570},
	urldate = {2017-06-22TZ},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
	year = {2015},
	pages = {211--225}
}

@article{tian_mechanism_2017,
	title = {The {Mechanism} of {Additive} {Composition}},
	issn = {0885-6125, 1573-0565},
	url = {http://arxiv.org/abs/1511.08407},
	doi = {10.1007/s10994-017-5634-8},
	abstract = {Additive composition (Foltz et al, 1998; Landauer and Dumais, 1997; Mitchell and Lapata, 2010) is a widely used method for computing meanings of phrases, which takes the average of vector representations of the constituent words. In this article, we prove an upper bound for the bias of additive composition, which is the first theoretical analysis on compositional frameworks from a machine learning point of view. The bound is written in terms of collocation strength; we prove that the more exclusively two successive words tend to occur together, the more accurate one can guarantee their additive composition as an approximation to the natural phrase vector. Our proof relies on properties of natural language data that are empirically verified, and can be theoretically derived from an assumption that the data is generated from a Hierarchical Pitman-Yor Process. The theory endorses additive composition as a reasonable operation for calculating meanings of phrases, and suggests ways to improve additive compositionality, including: transforming entries of distributional word vectors by a function that meets a specific condition, constructing a novel type of vector representations to make additive composition sensitive to word order, and utilizing singular value decomposition to train word vectors.},
	urldate = {2017-06-22TZ},
	journal = {Machine Learning},
	author = {Tian, Ran and Okazaki, Naoaki and Inui, Kentaro},
	month = apr,
	year = {2017},
	note = {arXiv: 1511.08407},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning}
}

@phdthesis{fyshe_corpora_2015,
	title = {Corpora and {Cognition}: {The} {Semantic} {Composition} of {Adjectives} and {Nouns} in the {Human} {Brain}},
	shorttitle = {Corpora and {Cognition}},
	url = {http://www.cs.cmu.edu/~afyshe/thesis/afyshe_thesis.pdf},
	urldate = {2017-06-22TZ},
	school = {Air Force Research Laboratory},
	author = {Fyshe, Alona},
	year = {2015}
}

@article{bowman_fast_2016,
	title = {A {Fast} {Unified} {Model} for {Parsing} and {Sentence} {Understanding}},
	url = {http://arxiv.org/abs/1603.06021},
	abstract = {Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suffer from two key technical problems that make them slow and unwieldy for large-scale NLP tasks: they usually operate on parsed sentences and they do not directly support batched computation. We address these issues by introducing the Stack-augmented Parser-Interpreter Neural Network (SPINN), which combines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shift-reduce parser. Our model supports batched computation for a speedup of up to 25 times over other tree-structured models, and its integrated parser can operate on unparsed data with little loss in accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models.},
	urldate = {2017-06-22TZ},
	journal = {arXiv:1603.06021 [cs]},
	author = {Bowman, Samuel R. and Gauthier, Jon and Rastogi, Abhinav and Gupta, Raghav and Manning, Christopher D. and Potts, Christopher},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.06021},
	keywords = {Computer Science - Computation and Language}
}

@article{wang_comparison_2017,
	title = {Comparison {Study} on {Critical} {Components} in {Composition} {Model} for {Phrase} {Representation}},
	volume = {16},
	issn = {23754699},
	url = {http://dl.acm.org/citation.cfm?doid=3041821.3010088},
	doi = {10.1145/3010088},
	language = {en},
	number = {3},
	urldate = {2017-06-21TZ},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	author = {Wang, Shaonan and Zong, Chengqing},
	month = jan,
	year = {2017},
	keywords = {Phrase representation, composition model, max-margin, mean square error, retrofitting, word paraphrasing},
	pages = {1--25}
}

@inproceedings{habernal_exploiting_2015,
	title = {Exploiting {Debate} {Portals} for {Semi}-{Supervised} {Argumentation} {Mining} in {User}-{Generated} {Web} {Discourse}.},
	url = {http://www.aclweb.org/anthology/D/D15/D15-1255.pdf},
	urldate = {2017-06-21TZ},
	booktitle = {{EMNLP}},
	author = {Habernal, Ivan and Gurevych, Iryna},
	year = {2015},
	pages = {2127--2137}
}

@inproceedings{boltuzic_identifying_2015,
	title = {Identifying prominent arguments in online debates using semantic textual similarity},
	url = {http://www.aclweb.org/anthology/W/W15/W15-05.pdf#page=122},
	urldate = {2017-06-12TZ},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	author = {Boltuzic, Filip and Šnajder, Jan},
	year = {2015},
	pages = {110--115}
}

@misc{noauthor_neuer_nodate,
	title = {Neuer {Tab}},
	url = {about:newtab},
	urldate = {2017-06-21TZ}
}

@article{yu_learning_2015,
	title = {Learning composition models for phrase embeddings},
	volume = {3},
	url = {https://transacl.org/ojs/index.php/tacl/article/view/586},
	urldate = {2017-06-20TZ},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Yu, Mo and Dredze, Mark},
	year = {2015},
	pages = {227--242}
}

@article{egan_summarising_2016,
	title = {Summarising the points made in online political debates},
	url = {http://www.aclweb.org/anthology/W/W16/W16-28.pdf#page=146},
	urldate = {2017-06-20TZ},
	journal = {ACL 2016},
	author = {Egan, Charlie and Siddharthan, Advaith and Wyner, Adam},
	year = {2016},
	pages = {134}
}

@article{petasis_identifying_2016,
	title = {Identifying {Argument} {Components} through {TextRank}},
	url = {http://www.aclweb.org/anthology/W/W16/W16-28.pdf#page=106},
	urldate = {2017-06-20TZ},
	journal = {ACL 2016},
	author = {Petasis, Georgios and Karkaletsis, Vangelis},
	year = {2016},
	pages = {94}
}

@inproceedings{uszkoreit_common_2017,
	address = {Valencia, Spain},
	title = {Common {Round}: {Application} of {Language} {Technologies} to {Large}-{Scale} {Web} {Debates}},
	url = {http://aclweb.org/anthology/E17-3002},
	abstract = {Web debates play an important role in enabling broad participation of constituencies in social, political and economic decision-taking. However, it is challenging to organize, structure, and navigate a vast number of diverse argumentations and comments collected from many participants over a long time period. In this paper we demonstrate Common Round, a next generation platform for large-scale web debates, which provides functions for eliciting the semantic content and structures from the contributions of participants. In particular, Common Round applies language technologies for the extraction of semantic essence from textual input, aggregation of the formulated opinions and arguments. The platform also provides a cross-lingual access to debates using machine translation.},
	booktitle = {Proceedings of the {Software} {Demonstrations} of the 15th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Uszkoreit, Hans and Gabryszak, Aleksandra and Hennig, Leonhard and Steffen, Jörg and Ai, Renlong and Busemann, Stephan and Dehdari, Jon and van Genabith, Josef and Heigold, Georg and Rethmeier, Nils and Rubino, Raphael and Schmeier, Sven and Thomas, Philippe and Wang, He and Xu, Feiyu},
	month = apr,
	year = {2017},
	pages = {5--8}
}

@article{tian_ecnu_2016,
	title = {{ECNU} at {SemEval}-2016 {Task} 1: {Leveraging} word embedding from macro and micro views to boost performance for semantic textual similarity},
	shorttitle = {{ECNU} at {SemEval}-2016 {Task} 1},
	url = {http://www.anthology.aclweb.org/S/S16/S16-1094.pdf},
	urldate = {2017-06-20TZ},
	journal = {Proceedings of SemEval},
	author = {Tian, Junfeng and Lan, Man},
	year = {2016},
	pages = {621--627}
}

@article{agirre_semeval-2016_2016,
	title = {Semeval-2016 task 1: {Semantic} textual similarity, monolingual and cross-lingual evaluation},
	shorttitle = {Semeval-2016 task 1},
	url = {http://www.aclweb.org/anthology/S16-1081},
	urldate = {2017-06-20TZ},
	journal = {Proceedings of SemEval},
	author = {Agirre, Eneko and Banea, Carmen and Cer, Daniel and Diab, Mona and Gonzalez-Agirre, Aitor and Mihalcea, Rada and Rigau, German and Wiebe, Janyce},
	year = {2016},
	pages = {497--511}
}

@article{zhuang_neobility_2017,
	title = {Neobility at {SemEval}-2017 {Task} 1: {An} {Attention}-based {Sentence} {Similarity} {Model}},
	shorttitle = {Neobility at {SemEval}-2017 {Task} 1},
	url = {http://arxiv.org/abs/1703.05465},
	abstract = {This paper describes a neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task. Our system employs an attention-based recurrent neural network model that optimizes the sentence similarity. In this paper, we describe our participation in the multilingual STS task which measures similarity across English, Spanish, and Arabic.},
	urldate = {2017-06-20TZ},
	journal = {arXiv:1703.05465 [cs]},
	author = {Zhuang, Wenli and Chang, Ernie},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.05465},
	keywords = {Computer Science - Computation and Language}
}

@inproceedings{hasan_why_2014,
	title = {Why are {You} {Taking} this {Stance}? {Identifying} and {Classifying} {Reasons} in {Ideological} {Debates}.},
	shorttitle = {Why are {You} {Taking} this {Stance}?},
	url = {http://www.aclweb.org/old_anthology/D/D14/D14-1083.pdf},
	urldate = {2017-06-15TZ},
	booktitle = {{EMNLP}},
	author = {Hasan, Kazi Saidul and Ng, Vincent},
	year = {2014},
	pages = {751--762}
}

@article{srivastava_dropout:_2014,
	title = {Dropout: {A} simple way to prevent neural networks from overfitting},
	volume = {15},
	shorttitle = {Dropout},
	url = {http://www.jmlr.org/papers/volume15/srivastava14a.old/source/srivastava14a.pdf},
	number = {1},
	urldate = {2017-06-14TZ},
	journal = {The Journal of Machine Learning Research},
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	year = {2014},
	pages = {1929--1958}
}

@article{shrivastava_learning_2016,
	title = {Learning from {Simulated} and {Unsupervised} {Images} through {Adversarial} {Training}},
	url = {https://arxiv.org/abs/1612.07828},
	urldate = {2017-06-14TZ},
	journal = {arXiv preprint arXiv:1612.07828},
	author = {Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Josh and Wang, Wenda and Webb, Russ},
	year = {2016}
}

@inproceedings{bengio_curriculum_2009,
	title = {Curriculum learning},
	url = {http://dl.acm.org/citation.cfm?id=1553380},
	urldate = {2017-06-14TZ},
	booktitle = {Proceedings of the 26th annual international conference on machine learning},
	publisher = {ACM},
	author = {Bengio, Yoshua and Louradour, Jérôme and Collobert, Ronan and Weston, Jason},
	year = {2009},
	pages = {41--48}
}

@article{schakel_measuring_2015,
	title = {Measuring {Word} {Significance} using {Distributed} {Representations} of {Words}},
	url = {http://arxiv.org/abs/1508.02297},
	abstract = {Distributed representations of words as real-valued vectors in a relatively low-dimensional space aim at extracting syntactic and semantic features from large text corpora. A recently introduced neural network, named word2vec (Mikolov et al., 2013a; Mikolov et al., 2013b), was shown to encode semantic information in the direction of the word vectors. In this brief report, it is proposed to use the length of the vectors, together with the term frequency, as measure of word significance in a corpus. Experimental evidence using a domain-specific corpus of abstracts is presented to support this proposal. A useful visualization technique for text corpora emerges, where words are mapped onto a two-dimensional plane and automatically ranked by significance.},
	urldate = {2017-06-14TZ},
	journal = {arXiv:1508.02297 [cs]},
	author = {Schakel, Adriaan M. J. and Wilson, Benjamin J.},
	month = aug,
	year = {2015},
	note = {arXiv: 1508.02297},
	keywords = {Computer Science - Computation and Language}
}

@book{pollard_head-driven_1994,
	title = {Head-driven phrase structure grammar},
	publisher = {University of Chicago Press},
	author = {Pollard, Carl and Sag, Ivan A},
	year = {1994}
}

@article{levine_head-driven_2006,
	title = {Head-driven phrase structure grammar},
	volume = {5},
	journal = {Encyclopedia of language and linguistics},
	author = {Levine, Robert D and Meurers, W Detmar},
	year = {2006},
	pages = {237--52}
}

@article{m?ller_unifying_2013,
	title = {Unifying everything: {Some} remarks on simpler syntax, construction grammar, minimalism, and {HPSG}},
	volume = {89},
	issn = {1535-0665},
	shorttitle = {Unifying everything},
	url = {http://muse.jhu.edu/content/crossref/journals/language/v089/89.4.muller.html},
	doi = {10.1353/lan.2013.0061},
	language = {en},
	number = {4},
	urldate = {2017-06-13TZ},
	journal = {Language},
	author = {M?ller, Stefan},
	year = {2013},
	pages = {920--950}
}

@article{muller_unifying_2013,
	title = {Unifying everything: {Some} remarks on simpler syntax, construction grammar, minimalism, and {HPSG}},
	volume = {89},
	shorttitle = {Unifying everything},
	url = {https://muse.jhu.edu/article/532708/summary},
	number = {4},
	urldate = {2017-06-13TZ},
	journal = {Language},
	author = {Müller, Stefan},
	year = {2013},
	pages = {920--950}
}

@book{noauthor_head-driven_nodate,
	title = {Head-{Driven} {Phrase} {Structure} {Grammar}},
	url = {http://www.press.uchicago.edu/ucp/books/book/chicago/H/bo3618318.html},
	abstract = {This book presents the most complete exposition of the theory of head-driven phrase structure grammar (HPSG), introduced in the authors' Information-Based Syntax and Semantics. HPSG provides an integration of key ideas from the various disciplines of cognitive science, drawing on results from diverse approaches to syntactic theory, situation semantics, data type theory, and knowledge representation. The result is a conception of grammar as a set of declarative and order-independent constraints, a conception well suited to modelling human language processing. This self-contained volume demonstrates the applicability of the HPSG approach to a wide range of empirical problems, including a number which have occupied center-stage within syntactic theory for well over twenty years: the control of "understood" subjects, long-distance dependencies conventionally treated in terms of wh-movement, and syntactic constraints on the relationship between various kinds of pronouns and their antecedents. The authors make clear how their approach compares with and improves upon approaches undertaken in other frameworks, including in particular the government-binding theory of Noam Chomsky.},
	urldate = {2017-06-13TZ}
}

@misc{noauthor_1155162.pdf_nodate,
	title = {1155162.{PDF}},
	url = {https://www.uni-salzburg.at/fileadmin/oracle_file_imports/1155162.PDF},
	urldate = {2017-04-01TZ}
}

@article{brezina_selection_1975,
	title = {Selection of chlortetracycline-resistant strain of {Coxiella} burnetii},
	volume = {19},
	issn = {0001-723X},
	language = {eng},
	number = {6},
	journal = {Acta Virologica},
	author = {Brezina, R. and Schramek, S. and Kazár, J.},
	month = nov,
	year = {1975},
	pmid = {1997},
	keywords = {Animals, Chick Embryo, Chlortetracycline, Coxiella, Drug Resistance, Microbial, Female, Vitelline Membrane},
	pages = {496}
}

@article{tai_improved_2015,
	title = {Improved {Semantic} {Representations} {From} {Tree}-{Structured} {Long} {Short}-{Term} {Memory} {Networks}},
	url = {http://arxiv.org/abs/1503.00075},
	abstract = {Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).},
	urldate = {2017-06-12TZ},
	journal = {arXiv:1503.00075 [cs]},
	author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.},
	month = feb,
	year = {2015},
	note = {arXiv: 1503.00075},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Learning, TreeLSTM}
}

@article{neubig_dynet:_2017,
	title = {{DyNet}: {The} {Dynamic} {Neural} {Network} {Toolkit}},
	shorttitle = {{DyNet}},
	url = {http://arxiv.org/abs/1701.03980},
	abstract = {We describe DyNet, a toolkit for implementing neural network models based on dynamic declaration of network structure. In the static declaration strategy that is used in toolkits like Theano, CNTK, and TensorFlow, the user first defines a computation graph (a symbolic representation of the computation), and then examples are fed into an engine that executes this computation and computes its derivatives. In DyNet's dynamic declaration strategy, computation graph construction is mostly transparent, being implicitly constructed by executing procedural code that computes the network outputs, and the user is free to use different network structures for each input. Dynamic declaration thus facilitates the implementation of more complicated network architectures, and DyNet is specifically designed to allow users to implement their models in a way that is idiomatic in their preferred programming language (C++ or Python). One challenge with dynamic declaration is that because the symbolic computation graph is defined anew for every training example, its construction must have low overhead. To achieve this, DyNet has an optimized C++ backend and lightweight graph representation. Experiments show that DyNet's speeds are faster than or comparable with static declaration toolkits, and significantly faster than Chainer, another dynamic declaration toolkit. DyNet is released open-source under the Apache 2.0 license and available at http://github.com/clab/dynet.},
	urldate = {2017-06-12TZ},
	journal = {arXiv:1701.03980 [cs, stat]},
	author = {Neubig, Graham and Dyer, Chris and Goldberg, Yoav and Matthews, Austin and Ammar, Waleed and Anastasopoulos, Antonios and Ballesteros, Miguel and Chiang, David and Clothiaux, Daniel and Cohn, Trevor and Duh, Kevin and Faruqui, Manaal and Gan, Cynthia and Garrette, Dan and Ji, Yangfeng and Kong, Lingpeng and Kuncoro, Adhiguna and Kumar, Gaurav and Malaviya, Chaitanya and Michel, Paul and Oda, Yusuke and Richardson, Matthew and Saphra, Naomi and Swayamdipta, Swabha and Yin, Pengcheng},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.03980},
	keywords = {Computer Science - Computation and Language, Computer Science - Mathematical Software, Statistics - Machine Learning}
}

@article{vila_relational_2015,
	title = {Relational paraphrase acquisition from {Wikipedia}: {The} {WRPA} method and corpus},
	volume = {21},
	issn = {1351-3249, 1469-8110},
	shorttitle = {Relational paraphrase acquisition from {Wikipedia}},
	url = {http://www.journals.cambridge.org/abstract_S1351324913000235},
	doi = {10.1017/S1351324913000235},
	language = {en},
	number = {03},
	urldate = {2017-06-12TZ},
	journal = {Natural Language Engineering},
	author = {Vila, M. and Rodr?Guez, H. and Mart?, M. A.},
	month = may,
	year = {2015},
	pages = {355--389}
}

@inproceedings{dolan_automatically_2005,
	title = {Automatically constructing a corpus of sentential paraphrases},
	url = {https://pdfs.semanticscholar.org/4753/54f10798f110d34792b6d88f31d6d5cb099e.pdf},
	urldate = {2017-06-12TZ},
	booktitle = {Proc. of {IWP}},
	author = {Dolan, William B. and Brockett, Chris},
	year = {2005}
}

@inproceedings{ganitkevitch_ppdb:_2013,
	title = {{PPDB}: {The} {Paraphrase} {Database}.},
	shorttitle = {{PPDB}},
	url = {http://www.aclweb.org/anthology/N13-1#page=796},
	urldate = {2017-06-12TZ},
	booktitle = {{HLT}-{NAACL}},
	author = {Ganitkevitch, Juri and Van Durme, Benjamin and Callison-Burch, Chris},
	year = {2013},
	pages = {758--764}
}

@article{looks_deep_2017,
	title = {Deep {Learning} with {Dynamic} {Computation} {Graphs}},
	url = {http://arxiv.org/abs/1702.02181},
	abstract = {Neural networks that compute over graph structures are a natural fit for problems in a variety of domains, including natural language (parse trees) and cheminformatics (molecular graphs). However, since the computation graph has a different shape and size for every input, such networks do not directly support batched training or inference. They are also difficult to implement in popular deep learning libraries, which are based on static data-flow graphs. We introduce a technique called dynamic batching, which not only batches together operations between different input graphs of dissimilar shape, but also between different nodes within a single input graph. The technique allows us to create static graphs, using popular libraries, that emulate dynamic computation graphs of arbitrary shape and size. We further present a high-level library of compositional blocks that simplifies the creation of dynamic graph models. Using the library, we demonstrate concise and batch-wise parallel implementations for a variety of models from the literature.},
	urldate = {2017-06-12TZ},
	journal = {arXiv:1702.02181 [cs, stat]},
	author = {Looks, Moshe and Herreshoff, Marcello and Hutchins, DeLesley and Norvig, Peter},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.02181},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, Tensorflow Fold}
}
@inproceedings{abadi_tensorflow:_2016,
	title = {{TensorFlow}: {A} system for large-scale machine learning},
	booktitle = {{OSDI}},
	author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek Gordon and Steiner, Benoit and Tucker, Paul A. and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zhang, Xiaoqiang},
	year = {2016},
	keywords = {tensorflow}
}

@book{workshop_on_wireless_traffic_measurements_and_modeling_papers_2005,
	address = {Berkeley, CA},
	title = {Papers presented at the {Workshop} on {Wireless} {Traffic} {Measurements} and {Modeling}: {June} 5, 2005, {Seattle}, {WA}, {USA}},
	isbn = {978-1-931971-33-1},
	shorttitle = {Papers presented at the {Workshop} on {Wireless} {Traffic} {Measurements} and {Modeling}},
	url = {http://portal.acm.org/toc.cfm?id=1072430},
	language = {English},
	urldate = {2017-06-12TZ},
	publisher = {USENIX Association},
	author = {{Workshop on Wireless Traffic Measurements and Modeling} and {USENIX Association} and {ACM SIGMOBILE} and {ACM Special Interest Group in Operating Systems} and {ACM Digital Library}},
	year = {2005},
	note = {OCLC: 83296063}
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9 8},
	journal = {Neural computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	year = {1997},
	keywords = {lstm},
	pages = {1735--80}
}

@inproceedings{pennington_glove:_2014,
	title = {Glove: {Global} {Vectors} for {Word} {Representation}},
	booktitle = {{EMNLP}},
	author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.},
	year = {2014}
}

@inproceedings{misra_measuring_2016,
	title = {Measuring the {Similarity} of {Sentential} {Arguments} in {Dialog}},
	url = {http://www.aclweb.org/anthology/W/W16/W16-36.pdf#page=294},
	urldate = {2017-06-12TZ},
	booktitle = {17th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	author = {Misra, Amita and Ecker, Brian and Walker, Marilyn A.},
	year = {2016},
	pages = {276}
}

@misc{noauthor_spacy_nodate,
	title = {{spaCy}},
	url = {https://spacy.io/index},
	abstract = {spaCy is a free open-source library featuring state-of-the-art speed and accuracy and a powerful Python API.},
	urldate = {2017-06-12TZ}
}

@misc{noauthor_distributed_nodate,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality} - {MikolovSutskeverChenCorradoDean}2013.pdf},
	url = {http://web2.cs.columbia.edu/~blei/seminar/2016_discrete_data/readings/MikolovSutskeverChenCorradoDean2013.pdf},
	urldate = {2017-06-12TZ}
}

@inproceedings{wachsmuth_argumentation_2017,
	address = {Vancouver, Canada},
	title = {Argumentation {Quality} {Assessment}: {Theory} vs. {Practice}},
	volume = {Volume 2: Short Papers},
	abstract = {Argumentation quality is viewed differently in argumentation theory and in practical assessment approaches. This paper studies to what extent the views match empirically. We find that most observations on quality phrased spontaneously are in fact adequately represented by theory. Even more, relative comparisons of arguments in practice correlate with absolute quality ratings based on theory. Our results clarify how the two views can learn from each other.},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({ACL} 2017)},
	publisher = {Association for Computational Linguistics},
	author = {Wachsmuth, Henning and Naderi, Nona and Habernal, Ivan and Hou, Yufang and Hirst, Graeme and Gurevych, Iryna and Stein, Benno},
	month = aug,
	year = {2017},
	pages = {(to appear)}
}

@inproceedings{eger_neural_2017,
	address = {Vancouver, Canada},
	title = {Neural {End}-to-{End} {Learning} for {Computational} {Argumentation} {Mining}},
	volume = {Volume 1: Long Papers},
	abstract = {{\textless}div{\textgreater}We investigate neural techniques for end-to-end computational argumentation mining (AM). We frame AM both as a token-based dependency parsing and as a token-based sequence tagging problem, including a multi-task learning setup. Contrary to models that operate on the argument component level, we find that framing AM as dependency parsing leads to subpar performance results. In contrast, less complex (local) tagging models based on BiLSTMs perform robustly across classification scenarios, being able to catch long-range dependencies inherent to the AM problem. Moreover, we find that jointly learning ‘natural’ subtasks, in a multi-task learning setup, improves performance.{\textless}/div{\textgreater}},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({ACL} 2017)},
	publisher = {Association for Computational Linguistics},
	author = {Eger, Steffen and Daxenberger, Johannes and Gurevych, Iryna},
	month = aug,
	year = {2017},
	pages = {(to appear)}
}

@article{habernal_what_nodate,
	title = {What makes a convincing argument? {Empirical} analysis and detecting attributes of convincingness in {Web} argumentation},
	shorttitle = {What makes a convincing argument?},
	url = {https://www.aclweb.org/anthology/D16-1129},
	urldate = {2017-04-25TZ},
	author = {Habernal, Ivan and Gurevych, Iryna},
	keywords = {Argument}
}

@misc{gurevych_linked_2016,
	type = {other},
	title = {Linked {Lexical} {Knowledge} {Bases}: {Foundations} and {Applications}},
	copyright = {Copyright © 2016 by Morgan \& Claypool},
	shorttitle = {Linked {Lexical} {Knowledge} {Bases}},
	url = {http://www.morganclaypool.com/doi/10.2200/S00717ED1V01Y201605HLT034},
	abstract = {Abstract This book conveys the fundamentals of Linked Lexical Knowledge Bases (LLKB) and sheds light on their different aspects from various perspectives, focusing on their construction and use in natural language processing (NLP). It characterizes a wide range of both expert-based and collaboratively constructed lexical knowledge bases. Only basic familiarity with NLP is required and this book has been written for both students and researchers in NLP and related fields who are interested in knowledge-based approaches to language analysis and their applications. Lexical Knowledge Bases (LKBs) are indispensable in many areas of natural language processing, as they encode human knowledge of language in machine readable form, and as such, they are required as a reference when machines attempt to interpret natural language in accordance with human perception. In recent years, numerous research efforts have led to the insight that to make the best use of available knowledge, the orchestrated exploitation of di...},
	language = {en},
	urldate = {2017-04-25TZ},
	author = {Gurevych, Iryna and Eckle-Kohler, Judith and Matuschek, Michael},
	month = jul,
	year = {2016}
}

@phdthesis{beinborn_predicting_2016,
	title = {Predicting and {Manipulating} the {Difficulty} of {Text}-{Completion} {Exercises} for {Language} {Learning}},
	url = {http://tuprints.ulb.tu-darmstadt.de/5647},
	urldate = {2017-04-25TZ},
	school = {Technische Universität Darmstadt},
	author = {Beinborn, Lisa Marina},
	year = {2016}
}

@misc{noauthor_details:_nodate,
	title = {Details: {UKP}},
	url = {https://www.ukp.tu-darmstadt.de/publications/details/?no_cache=1&tx_dppublications_pi1%5Bpublication%5D=10236&tx_dppublications_pi1%5Baction%5D=show&tx_dppublications_pi1%5Bcontroller%5D=Publication&cHash=2c6877d9b5479e42772e11df225f839d#dp_publications-single},
	urldate = {2017-04-25TZ}
}

@article{fortmann_bewegungsresistente_2007,
	title = {Bewegungsresistente {Verben}},
	volume = {26},
	issn = {0721-9067, 1613-3706},
	url = {http://www.degruyter.com/view/j/zfsw.2007.26.issue-1/zfs.2007.009/zfs.2007.009.xml},
	doi = {10.1515/ZFS.2007.009},
	number = {1},
	urldate = {2017-04-03TZ},
	journal = {Zeitschrift für Sprachwissenschaft},
	author = {Fortmann, Christian},
	month = jan,
	year = {2007},
	pages = {1--40}
}

@article{chomsky_lectures_1981,
	title = {Lectures on {Government} and {Binding}, {Foris}, {Dordrecht}},
	journal = {ChomskyLectures on Government and Binding1981},
	author = {Chomsky, Noam},
	year = {1981}
}

@article{den_besten_ergative_1985,
	title = {The ergative hypothesis and free word order in {Dutch} and {German}},
	volume = {21},
	journal = {Studies in German grammar},
	author = {Den Besten, Hans},
	year = {1985},
	pages = {23--64}
}

@article{pesetsky_morphology_1985,
	title = {Morphology and {Logical} {Form}},
	volume = {16},
	issn = {0024-3892},
	url = {http://www.jstor.org/stable/4178430},
	number = {2},
	urldate = {2017-04-01TZ},
	journal = {Linguistic Inquiry},
	author = {Pesetsky, David},
	year = {1985},
	pages = {193--246}
}

@article{haider_projective_1997,
	title = {Projective economy},
	journal = {German: Syntactic problems–problematic syntax, ed. Werner Abraham},
	author = {Haider, Hubert},
	year = {1997},
	pages = {83--103}
}

@misc{noauthor_notitle_nodate,
	url = {https://scholar.googleusercontent.com/scholar.bib?q=info:u-4SYjm81owJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWOA1kpCZ3dJGqOrQ9woHW4qLwYg9ANCa&scisf=4&ct=citation&cd=-1&hl=de},
	urldate = {2017-04-01TZ}
}

@article{asakura_mechanical_1975,
	title = {Mechanical precipitation of hemoglobin köln},
	volume = {412},
	issn = {0006-3002},
	abstract = {Hb Köln (beta 98 Val leads to Met) was found to precipitate rapidly during mechanical shaking. The rate of precipitation of Hb Köln is 5-6 times faster than that of Hb S. The kinetics of precipitation of the patient's hemolysate, which is a mixture of Hb Köln and Hb A, showed a biphasic curve indicating that Hb Köln precipitates independently from Hb A. The instability of Hb Köln may be attributed to the conformational change in the vicinity of heme. The mechanical shaking may be used as a new method for detection and quantitation of hemoglobin Köln and other unstable hemoglobins.},
	language = {eng},
	number = {2},
	journal = {Biochimica Et Biophysica Acta},
	author = {Asakura, T. and Adachi, K. and Shapiro, M. and Friedman, S. and Schwartz, E.},
	month = dec,
	year = {1975},
	pmid = {83},
	keywords = {Chemical Precipitation, Germany, West, Hemoglobin, Sickle, Hemoglobins, Abnormal, Humans, Hydrogen-Ion Concentration, Methionine, Osmolar Concentration, Temperature, Valine},
	pages = {197--201}
}

@article{kulik_[combined_1975,
	title = {[{Combined} effects of hypoxia and hypercapnia on the functional state of the respiratory center]},
	volume = {79},
	issn = {0365-9615},
	abstract = {Experiments were conducted on cats under nembutal anesthesia; a study was made of pulse activity of bulbar respiratory neurons, electrical activity of the diaphragm and of the intercostal muscles; pO2, pCO2, pH, arterial blood oxygen saturation were determined in combined action of hypoxia and hypercapnia. When hypoxic gaseous mixture was given for respiration the developing hypocapnia disturbed the discharge rhythmic activity of the respiratory neurons, the respiration acquiring a pathological character of the Cheyne--Stokes type. After addition to the hypoxic gaseous mixture of 2\% CO2 the gaseous composition of the arterial blood approached the initial values; this addition prevented the development of hypercapnia and disturbances of rhythmic discharge activity of the respiratory neurons. Addition of 5\% CO2 to the hypoxic gaseous mixture produced a negative effect: at first it intensified and then depressed the pulse activity of the respiratory neurons, caused metabolic and respiratory acidosis, and promoted asphyxia.},
	language = {rus},
	number = {4},
	journal = {Biulleten' Eksperimental'noi Biologii I Meditsiny},
	author = {Kulik, A. M. and Kondrat'eva, L. N.},
	month = apr,
	year = {1975},
	pmid = {103},
	keywords = {Animals, Carbon Dioxide, Cats, Cheyne-Stokes Respiration, Diaphragm, Electrophysiology, Hydrogen-Ion Concentration, Hypercapnia, Hypoxia, Intercostal Muscles, Neurons, Oxygen, Respiratory Center},
	pages = {39--43}
}

@book{sternefeld_syntax:_2009,
	address = {Tübingen},
	edition = {3., überarb. Aufl},
	series = {Stauffenburg-{Linguistik}},
	title = {Syntax: eine morphologisch motivierte generative {Beschreibung} des {Deutschen}. {Bd}. 2},
	isbn = {978-3-86057-177-4},
	shorttitle = {Syntax},
	language = {ger},
	number = {Bd. 31,2},
	publisher = {Stauffenburg},
	author = {Sternefeld, Wolfgang},
	year = {2009},
	note = {OCLC: 426147853}
}

@article{piggott_purification_1976,
	title = {Purification of multiple forms of adenosine deaminase from rabbit intestine},
	volume = {429},
	issn = {0006-3002},
	abstract = {Two forms of adenosine deaminase (adenosine aminohydrolase, EC 3.5.4.4), differing in molecular size, have been purified and obtained in homogeneous form from rabbit intestine. The purification procedures involved extraction with acetate buffer, pH 5.5, precipitation and fractional reextraction with (NH4)2SO4, ion-exchange chromatography on DEAE-cellulose and gel filtration on Sephadex G-75 and Sephadex G-200. Gel filtrations analysis gave molecular weight estimates of 265 000 and 32 000 for the large and small deaminases respectively. The two enzymes forms had similar pH optima and pH stability ranges.},
	language = {eng},
	number = {2},
	journal = {Biochimica Et Biophysica Acta},
	author = {Piggott, C. O. and Brady, T. G.},
	month = apr,
	year = {1976},
	pmid = {4139},
	keywords = {Adenosine Deaminase, Animals, Drug Stability, Hydrogen-Ion Concentration, Intestines, Isoenzymes, Kinetics, Molecular Weight, Nucleoside Deaminases, Rabbits},
	pages = {600--607}
}

@article{skipper_hydrolysis_1976,
	title = {Hydrolysis of a chloro-s-triazine herbicide},
	volume = {24},
	issn = {0021-8561},
	language = {eng},
	number = {1},
	journal = {Journal of Agricultural and Food Chemistry},
	author = {Skipper, H. D. and Volk, V. V. and Frech, R.},
	month = feb,
	year = {1976},
	pmid = {1430},
	keywords = {Atrazine, Chemical Phenomena, Chemistry, Hydrogen-Ion Concentration, Hydrolysis, Pesticide Residues, Spectrophotometry, Infrared},
	pages = {126--129}
}

@book{sternefeld_syntax:_2006,
	address = {Tübingen},
	series = {Stauffenburg {Linguistik}},
	title = {Syntax: eine morphologisch motivierte generative {Beschreibung} des {Deutschen}},
	isbn = {978-3-86057-779-0 978-3-86057-790-5},
	shorttitle = {Syntax},
	number = {Bd. 31},
	publisher = {Stauffenburg},
	author = {Sternefeld, Wolfgang},
	year = {2006},
	keywords = {German language, Morphology, Syntax}
}

@book{sternefeld_syntax::_2009,
	address = {Tübingen},
	edition = {3., überarb. Aufl},
	series = {Stauffenburg-{Linguistik}},
	title = {Syntax:: eine morphologisch motivierte generative {Beschreibung} des {Deutschen}. {Bd}. 2: [...]},
	isbn = {978-3-86057-177-4},
	shorttitle = {Syntax},
	language = {ger},
	number = {Bd. 31,2},
	publisher = {Stauffenburg},
	author = {Sternefeld, Wolfgang},
	year = {2009},
	note = {OCLC: 426147853}
}

@book{noauthor_syntax._2009,
	address = {Tübingen},
	title = {Syntax. 2 2},
	isbn = {978-3-86057-177-4},
	language = {German},
	publisher = {Stauffenburg},
	year = {2009},
	note = {OCLC: 930387783}
}

@book{noauthor_syntax.._2009,
	edition = {3., überarb. Aufl.},
	series = {{BV}013738446 31,2},
	title = {Syntax.. 2},
	isbn = {978-3-86057-177-4},
	abstract = {Verantwortlichkeit: Wolfgang Sternefeld},
	language = {ger},
	year = {2009}
}

@misc{noauthor_syntax.._nodate,
	title = {Syntax.. 2},
	url = {http://hu-berlin.hosted.exlibrisgroup.com/primo_library/libweb/action/dlDisplay.do?vid=hub_ub&afterPDS=true&docId=HUB_UB_ALMA_DS21607931800002882},
	urldate = {2017-04-01TZ}
}

@book{noauthor_syntax.._2009-1,
	edition = {3., überarb. Aufl.},
	series = {{BV}013738446 31,2},
	title = {Syntax.. 2},
	isbn = {978-3-86057-177-4},
	abstract = {Verantwortlichkeit: Wolfgang Sternefeld},
	language = {ger},
	year = {2009}
}

@article{goldberg_word2vec_2014,
	title = {word2vec {Explained}: deriving {Mikolov} et al.'s negative-sampling word-embedding method},
	shorttitle = {word2vec {Explained}},
	url = {http://arxiv.org/abs/1402.3722},
	urldate = {2016-12-12TZ},
	journal = {arXiv preprint arXiv:1402.3722},
	author = {Goldberg, Yoav and Levy, Omer},
	year = {2014}
}

@article{duchi_adaptive_2011,
	title = {Adaptive subgradient methods for online learning and stochastic optimization},
	volume = {12},
	url = {http://www.jmlr.org/papers/v12/duchi11a.html},
	number = {Jul},
	urldate = {2016-12-12TZ},
	journal = {Journal of Machine Learning Research},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	year = {2011},
	pages = {2121--2159}
}

@article{mikolov_efficient_2013,
	title = {Efficient estimation of word representations in vector space},
	url = {http://arxiv.org/abs/1301.3781},
	urldate = {2016-12-12TZ},
	journal = {arXiv preprint arXiv:1301.3781},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	year = {2013}
}

@misc{noauthor_1301.3781v3.pdf_nodate,
	title = {1301.3781v3.pdf},
	url = {https://arxiv.org/pdf/1301.3781v3.pdf},
	urldate = {2016-12-12TZ}
}

@misc{duchi_adaptive_nodate,
	title = {Adaptive {Subgradient} {Methods} for {Online} {Learning} and {Stochastic} {Optimization}},
	url = {http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf},
	urldate = {2016-12-05TZ},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram}
}

@inproceedings{levy_dependency-based_2014,
	title = {Dependency-{Based} {Word} {Embeddings}.},
	url = {http://www.aclweb.org/anthology/P14-2050.pdf},
	urldate = {2016-12-06TZ},
	booktitle = {{ACL} (2)},
	author = {Levy, Omer and Goldberg, Yoav},
	year = {2014},
	pages = {302--308}
}

@article{liebeck_what_2016,
	title = {What to {Do} with an {Airport}? {Mining} {Arguments} in the {German} {Online} {Participation} {Project} {Tempelhofer} {Feld}},
	shorttitle = {What to {Do} with an {Airport}?},
	url = {http://www.aclweb.org/anthology/W/W16/W16-28.pdf#page=156},
	urldate = {2016-12-01TZ},
	journal = {ACL 2016},
	author = {Liebeck, Matthias and Esau, Katharina and Conrad, Stefan},
	year = {2016},
	pages = {144}
}

@inproceedings{rinott_show_2015,
	title = {Show {Me} {Your} {Evidence}–an {Automatic} {Method} for {Context} {Dependent} {Evidence} {Detection}},
	url = {http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP050.pdf},
	urldate = {2016-12-01TZ},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {NLP} ({EMNLP}), {Lisbon}, {Portugal}},
	author = {Rinott, Ruty and Dankin, Lena and Alzate, Carlos and Khapra, Mitesh M. and Aharoni, Ehud and Slonim, Noam},
	year = {2015},
	pages = {17--21}
}

@misc{noauthor_debating_2011,
	type = {{CT}002},
	title = {Debating {Technologies} {Datasets}},
	copyright = {© Copyright IBM Corp. 2011},
	url = {https://www.research.ibm.com/haifa/dept/vst/mlta_data.shtml},
	language = {en-US},
	urldate = {2016-12-01TZ},
	month = may,
	year = {2011}
}

@article{graves_neural_2014,
	title = {Neural turing machines},
	url = {http://arxiv.org/abs/1410.5401},
	urldate = {2016-10-25TZ},
	journal = {arXiv preprint arXiv:1410.5401},
	author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
	year = {2014}
}

@article{kurach_neural_2015,
	title = {Neural random-access machines},
	url = {http://arxiv.org/abs/1511.06392},
	urldate = {2016-10-25TZ},
	journal = {arXiv preprint arXiv:1511.06392},
	author = {Kurach, Karol and Andrychowicz, Marcin and Sutskever, Ilya},
	year = {2015}
}

@article{zaremba_reinforcement_2015,
	title = {Reinforcement learning neural {Turing} machines},
	volume = {362},
	url = {https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf},
	urldate = {2016-10-25TZ},
	journal = {arXiv preprint arXiv:1505.00521},
	author = {Zaremba, Wojciech and Sutskever, Ilya},
	year = {2015}
}

@book{berntson_handbook_2009,
	address = {Hoboken, N.J},
	title = {Handbook of neuroscience for the behavioral sciences},
	isbn = {978-0-470-08355-0 978-0-470-08356-7 978-0-470-08357-4},
	publisher = {Wiley},
	editor = {Berntson, Gary G. and Cacioppo, John T.},
	year = {2009},
	note = {OCLC: ocn259902179},
	keywords = {Behavior, Mental Processes, Neuropsychology, Neurosciences, Psychophysiology, physiology}
}

@article{reed_neural_2015,
	title = {Neural programmer-interpreters},
	url = {http://arxiv.org/abs/1511.06279},
	urldate = {2016-10-25TZ},
	journal = {arXiv preprint arXiv:1511.06279},
	author = {Reed, Scott and de Freitas, Nando},
	year = {2015}
}

@inproceedings{salakhutdinov_learning_2007,
	title = {Learning a {Nonlinear} {Embedding} by {Preserving} {Class} {Neighbourhood} {Structure}.},
	url = {http://www.jmlr.org/proceedings/papers/v2/salakhutdinov07a/salakhutdinov07a.pdf},
	urldate = {2016-10-25TZ},
	booktitle = {{AISTATS}},
	author = {Salakhutdinov, Ruslan and Hinton, Geoffrey E.},
	year = {2007},
	pages = {412--419}
}

@article{kaiser_neural_2015,
	title = {Neural gpus learn algorithms},
	url = {http://arxiv.org/abs/1511.08228},
	urldate = {2016-10-25TZ},
	journal = {arXiv preprint arXiv:1511.08228},
	author = {Kaiser, {\textbackslash}Lukasz and Sutskever, Ilya},
	year = {2015}
}

@inproceedings{al_sallab_self_2011,
	title = {Self learning machines using {Deep} {Networks}},
	isbn = {978-1-4577-1196-1 978-1-4577-1195-4 978-1-4577-1194-7},
	url = {http://ieeexplore.ieee.org/document/6089108/},
	doi = {10.1109/SoCPaR.2011.6089108},
	urldate = {2016-10-25TZ},
	publisher = {IEEE},
	author = {Al Sallab, Ahmad A. and Rashwan, Mohsen A.},
	month = oct,
	year = {2011},
	pages = {21--26}
}

@article{poole_exponential_2016,
	title = {Exponential expressivity in deep neural networks through transient chaos},
	url = {https://arxiv.org/abs/1606.05340},
	urldate = {2016-10-25TZ},
	journal = {arXiv preprint arXiv:1606.05340},
	author = {Poole, Ben and Lahiri, Subhaneil and Raghu, Maithra and Sohl-Dickstein, Jascha and Ganguli, Surya},
	year = {2016}
}

@article{damianou_feature_nodate,
	title = {Feature representation with {Deep} {Gaussian} processes},
	url = {http://ml.dcs.shef.ac.uk/gpss/gpfe14/talks/gpss_deepGPs.pdf},
	urldate = {2016-10-25TZ},
	author = {Damianou, Andreas}
}

@phdthesis{duvenaud_automatic_2014,
	title = {Automatic model construction with {Gaussian} processes},
	url = {https://www.repository.cam.ac.uk/handle/1810/247281},
	urldate = {2016-10-25TZ},
	school = {University of Cambridge},
	author = {Duvenaud, David},
	year = {2014}
}

@inproceedings{eichler_teg-rep:_2016,
	title = {{TEG}-{REP}: {A} corpus of {Textual} {Entailment} {Graphs} based on {Relation} {Extraction} {Patterns}},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Language} {Resources} and {Evaluation}},
	publisher = {European Language Resources Association},
	author = {Eichler, Kathrin and Xu, Feiyu and Uszkoreit, Hans and Hennig, Leonhard and Krause, Sebastian},
	year = {2016}
}

@inproceedings{carstens_towards_2015,
	address = {Denver, CO},
	title = {Towards relation based {Argumentation} {Mining}},
	url = {http://www.aclweb.org/anthology/W15-0504},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Carstens, Lucas and Toni, Francesca},
	month = jun,
	year = {2015},
	pages = {29--34}
}

@inproceedings{kirschner_linking_2015,
	address = {Denver, CO},
	title = {Linking the {Thoughts}: {Analysis} of {Argumentation} {Structures} in {Scientific} {Publications}},
	shorttitle = {Linking the {Thoughts}},
	url = {http://www.aclweb.org/anthology/W15-0501},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Kirschner, Christian and Eckle-Kohler, Judith and Gurevych, Iryna},
	month = jun,
	year = {2015},
	pages = {1--11}
}

@inproceedings{lawrence_combining_2015,
	address = {Denver, CO},
	title = {Combining {Argument} {Mining} {Techniques}},
	url = {http://www.aclweb.org/anthology/W15-0516},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Lawrence, John and Reed, Chris},
	month = jun,
	year = {2015},
	pages = {127--136}
}
@inproceedings{banko_tradeoffs_2008,
	address = {Columbus, Ohio},
	title = {The {Tradeoffs} {Between} {Open} and {Traditional} {Relation} {Extraction}},
	url = {http://www.aclweb.org/anthology/P/P08/P08-1004},
	booktitle = {Proceedings of {ACL}-08: {HLT}},
	publisher = {Association for Computational Linguistics},
	author = {Banko, Michele and Etzioni, Oren},
	month = jun,
	year = {2008},
	keywords = {relation extraction},
	pages = {28--36}
}

@article{walton_using_2012,
	title = {Using {Argumentation} {Schemes} for {Argument} {Extraction}: {A} {Bottom}-{Up} {Method}},
	volume = {6},
	issn = {1557-3958},
	shorttitle = {Using {Argumentation} {Schemes} for {Argument} {Extraction}},
	url = {http://dx.doi.org/10.4018/jcini.2012070103},
	doi = {10.4018/jcini.2012070103},
	abstract = {This paper surveys the state-of-the-art of argumentation schemes used as argument extraction techniques in cognitive informatics and uses examples to show how a series of connected problems needs to be solved to move these techniques forward to computational implementation. Some of the schemes considered are argument from expert opinion, practical reasoning, argument from negative consequences, fear appeal arguments, argument from commitment, argument from inconsistent commitments, and the circumstantial ad hominem argument. The paper shows how schemes need to be formed into clusters of sub-schemes work toward a classification system of schemes from the bottom up, and how identification conditions for each scheme can be helpful for argument extraction.},
	number = {3},
	journal = {Int. J. Cogn. Inform. Nat. Intell.},
	author = {Walton, Douglas},
	month = jul,
	year = {2012},
	keywords = {Carneades Argumentation System, Classifying Types of Arguments, Identifying Arguments in a Natural Language Text, argument mining},
	pages = {33--61}
}

@inproceedings{peldszus_towards_2014,
	address = {Baltimore, Maryland},
	title = {Towards segment-based recognition of argumentation structure in short texts},
	url = {http://www.aclweb.org/anthology/W14-2112},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Peldszus, Andreas},
	month = jun,
	year = {2014},
	pages = {88--97}
}

@article{wells_using_2008,
	title = {Using dialogical argument as an interface to complex debates},
	volume = {27},
	issn = {0278-6648},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4625357},
	doi = {10.1109/MPOT.2008.928452},
	number = {5},
	journal = {IEEE Potentials},
	author = {Wells, Simon and Reed, Chris},
	year = {2008},
	pages = {26--30}
}

@inproceedings{peldszus_towards_2015,
	address = {Denver, CO},
	title = {Towards {Detecting} {Counter}-considerations in {Text}},
	url = {http://www.aclweb.org/anthology/W15-0513},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Peldszus, Andreas and Stede, Manfred},
	month = jun,
	year = {2015},
	pages = {104--109}
}

@inproceedings{mochales_palau_study_2007,
	address = {Amsterdam},
	title = {Study on sentence relations in the automatic detection of argumentation in legal cases},
	url = {https://lirias.kuleuven.be/handle/123456789/197361},
	booktitle = {Proceedings of {JURIX} 2007: the {Twentieth} {Annual} {Conference} on {Legal} {Knowledge} and {Information} {Systems}, {JURIX} 2007: the twentieth annual conference on legal knowledge and information systems, {Leiden}, {The} {Netherlands}, 13-14 {December} 2007},
	publisher = {IOS press},
	author = {Mochales Palau, Raquel and Moens, Marie-Francine},
	year = {2007},
	pages = {89--98}
}

@inproceedings{mochales_palau_study_2008,
	address = {Amsterdam},
	title = {Study on the structure of argumentation in case law},
	url = {https://lirias.kuleuven.be/handle/123456789/203100},
	booktitle = {Proceedings of {JURIX} 2008: the {Twenty}-first {Annual} {Conference} on {Legal} {Knowledge} and {Information} {Systems}, {JURIX} 2008: the twenty-first annual conference on legal knowledge and information systems, {Florence}, {Italy}, 10-13 {December} 2008},
	publisher = {IOS Press Amsterdam},
	author = {Mochales Palau, Raquel and Moens, Marie-Francine},
	year = {2008},
	pages = {11--20}
}

@inproceedings{houy_towards_2013,
	title = {Towards automated identification and analysis of argumentation structures in the decision corpus of the {German} {Federal} {Constitutional} {Court}},
	url = {http://www.dfki.de/lt/publication_show.php?id=6833},
	doi = {10.1109/DEST.2013.6611332},
	abstract = {Argumentation is an essential task in every scientific discipline. The development of strong and convincing argumentation as well as the analysis of existing argumentation structures is important in the field of humanities, and especially in the field of jurisprudence. Judicial argumentation requires sophisticated intellectual effort and the knowledge of as much potentially relevant background information as possible. Considering that the fulfillment of this task is limited by the natural human information processing capacity, the field of digital humanities investigates how such information-intensive and time-consuming tasks can be supported by computers. Against the background of the ever-growing availability of different corpora of jurisdiction in Germany, a software prototype supporting automated identification, analysis and recommendation of argumentation structures in electronically available corpora of jurisdiction is currently developed in the project ARGUMENTUM. In this article, we present the basic concept for the preparation and processing of the decision corpus of the German Federal Constitutional Court which shall provide the basis for the future ARGUMENTUM prototype.},
	booktitle = {2013 7th {IEEE} {International} {Conference} on {Digital} {Ecosystems} and {Technologies} ({DEST})},
	author = {Houy, C. and Niesen, T. and Fettke, P. and Loos, P.},
	month = jul,
	year = {2013},
	keywords = {ARGUMENTUM, Argumentation mining, Cognition, Context, German federal constitutional court, Indexes, Law, NLP, Prototypes, Vectors, argument mining, argumentation structures analysis, automated identification, decision corpus, decision making, digital humanities, eHumanities, humanities, information-intensive tasks, judicial argumentation, jurisprudence, natural human information processing capacity, public administration, software prototype, text mining, time-consuming tasks},
	pages = {72--77}
}

@article{garcia_villalba_m.p_facets_2012,
	title = {Some facets of argument mining for opinion analysis},
	volume = {245},
	issn = {0922-6389},
	language = {English},
	number = {1},
	journal = {Front. Artif. Intell. Appl. Frontiers in Artificial Intelligence and Applications},
	author = {{Garcia Villalba M.P} and {Saint-Dizier P}},
	year = {2012},
	pages = {23--34}
}

@inproceedings{ashley_toward_2013,
	address = {New York, NY, USA},
	series = {{ICAIL} '13},
	title = {Toward {Constructing} {Evidence}-based {Legal} {Arguments} {Using} {Legal} {Decision} {Documents} and {Machine} {Learning}},
	isbn = {978-1-4503-2080-1},
	url = {http://doi.acm.org/10.1145/2514601.2514622},
	doi = {10.1145/2514601.2514622},
	abstract = {This paper explores how to extract argumentation-relevant information automatically from a corpus of legal decision documents, and how to build new arguments using that information. For decision texts, we use the Vaccine/Injury Project (V/IP) Corpus, which contains default-logic annotations of argument structure. We supplement this with presuppositional annotations about entities, events, and relations that play important roles in argumentation, and about the level of confidence that arguments would be successful. We then propose how to integrate these semantic-pragmatic annotations with syntactic and domain-general semantic annotations, such as those generated in the DeepQA architecture, and outline how to apply machine learning and scoring techniques similar to those used in the IBM Watson system for playing the Jeopardy! question-answer game. We replace this game-playing goal, however, with the goal of learning to construct legal arguments.},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Law}},
	publisher = {ACM},
	author = {Ashley, Kevin D. and Walker, Vern R.},
	year = {2013},
	keywords = {DeepQA, IBM Watson, default-logic framework, legal argumentation, presuppositional annotation, text annotation},
	pages = {176--180}
}

@book{green_proceedings_2014,
	address = {Baltimore, Maryland},
	title = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	url = {http://www.aclweb.org/anthology/W14-21},
	publisher = {Association for Computational Linguistics},
	editor = {Green, Nancy and Ashley, Kevin and Litman, Diane and Reed, Chris and Walker, Vern},
	month = jun,
	year = {2014}
}

@inproceedings{graves_titles_2014,
	address = {Baltimore, Maryland},
	title = {Titles {That} {Announce} {Argumentative} {Claims} in {Biomedical} {Research} {Articles}},
	url = {http://www.aclweb.org/anthology/W14-2113},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Graves, Heather and Graves, Roger and Mercer, Robert and Akter, Mahzereen},
	month = jun,
	year = {2014},
	pages = {98--99}
}

@inproceedings{hernandez_a._survey_2014,
	address = {Baltimore, Maryland},
	title = {Survey in sentiment, polarity and function analysis of citation},
	url = {http://www.aclweb.org/anthology/W14-2115},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Hernández A., Myriam and Gómez, José M.},
	month = jun,
	year = {2014},
	pages = {102--103}
}

@inproceedings{green_towards_2014,
	address = {Baltimore, Maryland},
	title = {Towards {Creation} of a {Corpus} for {Argumentation} {Mining} the {Biomedical} {Genetics} {Research} {Literature}},
	url = {http://www.aclweb.org/anthology/W14-2102},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Green, Nancy},
	month = jun,
	year = {2014},
	pages = {11--18}
}

@inproceedings{lawrence_mining_2014,
	address = {Baltimore, Maryland},
	title = {Mining {Arguments} {From} 19th {Century} {Philosophical} {Texts} {Using} {Topic} {Based} {Modelling}},
	url = {http://www.aclweb.org/anthology/W14-2111},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Lawrence, John and Reed, Chris and Allen, Colin and McAlister, Simon and Ravenscroft, Andrew},
	month = jun,
	year = {2014},
	pages = {79--87}
}

@inproceedings{kang_requirement_2014,
	address = {Baltimore, Maryland},
	title = {Requirement {Mining} in {Technical} {Documents}},
	url = {http://www.aclweb.org/anthology/W14-2118},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Kang, Juyeon and Saint-Dizier, Patrick},
	month = jun,
	year = {2014},
	pages = {108--109}
}

@inproceedings{ong_ontology-based_2014,
	address = {Baltimore, Maryland},
	title = {Ontology-{Based} {Argument} {Mining} and {Automatic} {Essay} {Scoring}},
	url = {http://www.aclweb.org/anthology/W14-2104},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Ong, Nathan and Litman, Diane and Brusilovsky, Alexandra},
	month = jun,
	year = {2014},
	pages = {24--28}
}

@phdthesis{white_pattern-based_2010,
	address = {United States – Colorado},
	type = {Ph.{D}.},
	title = {Pattern-based extraction of argumentation from the scientific literature},
	copyright = {Copyright ProQuest, UMI Dissertations Publishing 2010},
	url = {http://search.proquest.com/docview/501674530/abstract/C75577A4FBA14858PQ/1?accountid=11004},
	abstract = {As the number of publications in the biomedical field continues its exponential increase, techniques for automatically summarizing information from this body of literature have become more diverse. In addition, the targets of summarization have become more subtle; initial work focused on extracting the factual assertions from full-text papers, while recent interest has shifted to recovering statements involving certainty, like speculations and agreements or disagreements with other research. Scientific writing is rife with such argumentation, and the premises, evidence, conjectures, objections and rebuttals that writers use to persuade the reader represent a rich vein of expert knowledge for summarization. However, recovering these presents substantial challenges as well: processing natural language leads to ambiguity; arguments are made implicitly instead of explicitly; and arguments are nested into complex structures. Agreement, disagreement, and conjecture are often expressed in highly scripted ways in scientific writing, and this feature makes these arguments recoverable by pattern-based search. Here, I present the PARROT software; it recognizes claims pertaining to scientific methods, cognition, discourse, negation, causation, and modality and uses discourse cues to combine these claims recursively into larger rhetorical structures to recover the shape of the arguments made in a scientific publication, which uses OpenDMAP patterns in combination with a Protégé ontology. PARROT outperforms an SVM classifier in identifying statements of support and conflict at the sentence level. Additionally, PARROT adapts to graphical representation of the arguments it finds, which makes it an valuable tool for summarizing the reasoning behind scientists' conclusions and identifying areas of consensus and contention.},
	language = {English},
	school = {University of Colorado at Boulder},
	author = {White, Elizabeth K.},
	year = {2010},
	keywords = {Applied sciences, Argumentation, Concept, Language, Pattern, Pattern-based extraction, Speculation, literature and linguistics}
}

@article{teufel_summarizing_2002,
	title = {Summarizing {Scientific} {Articles}: {Experiments} with {Relevance} and {Rhetorical} {Status}},
	volume = {28},
	issn = {0891-2017},
	shorttitle = {Summarizing {Scientific} {Articles}},
	url = {http://dx.doi.org/10.1162/089120102762671936},
	doi = {10.1162/089120102762671936},
	abstract = {In this article we propose a strategy for the summarization of scientific articles that concentrates on the rhetorical status of statements in an article: Material for summaries is selected in such a way that summaries can highlight the new contribution of the source article and situate it with respect to earlier work.},
	number = {4},
	journal = {Computational Linguistics},
	author = {Teufel, Simone and Moens, Marc},
	year = {2002},
	pages = {409--445}
}

@book{noauthor_natural_0,
	title = {Natural {Language} {Arguments}: {A} {Combined} {Approach}.},
	shorttitle = {Natural {Language} {Arguments}},
	url = {http://hal.inria.fr/hal-00724780},
	abstract = {With the growing use of the Social Web, an increasing number of applications for exchanging opinions with other people are becoming available online. These applications are widely adopted with the consequence that the number of opinions about the debated issues increases. In order to cut in on a debate, the participants need first to evaluate the opinions in favour or against the debated issue. Argumentation theory proposes algorithms and semantics to evaluate the set of accepted arguments, given the conflicts among them. The main problem is how to automatically generate the arguments from the natural language formulation of the opinions used in these applications. Our paper addresses this problem by proposing and evaluating the use of natural language techniques to generate the arguments. In particular, we adopt the textual entailment approach, a generic framework for applied semantics, where linguistic objects are mapped by means of semantic inferences at a textual level. We couple textual entailment together with a Dung-like argumentation system which allows us to identify the arguments that are accepted in the considered online debate. The originality of the proposed framework lies in the following point: natural language debates are ana- lyzed and the arguments are automatically extracted.},
	language = {English},
	year = {0}
}

@article{d._hitchcock_pragma-dialectical_2011,
	title = {The pragma-dialectical account of argument schemes},
	author = {D. Hitchcock, J. Wagemans},
	year = {2011}
}

@article{iyad_rahwan_representing_2011,
	title = {Representing and classifying arguments on the {Semantic} {Web}},
	volume = {26},
	issn = {1469-8005},
	doi = {10.1017/S0269888911000191},
	number = {04},
	journal = {The Knowledge Engineering Review},
	author = {Iyad Rahwan, Bita Banihashemi},
	year = {2011},
	pages = {487 -- 511}
}

@article{wyner_semi-automated_2012,
	title = {Semi-{Automated} {Argumentative} {Analysis} of {Online} {Product} {Reviews}.},
	volume = {245},
	journal = {COMMA},
	author = {Wyner, Adam and Schneider, Jodi and Atkinson, Katie and Bench-Capon, Trevor JM},
	year = {2012},
	pages = {43--50}
}

@book{cardie_proceedings_2015,
	address = {Denver, Colorado},
	title = {Proceedings of the {Second} {Workshop} on {Argumentation} {Mining}},
	url = {http://aclweb.org/anthology/W15-05},
	publisher = {Association for Computational Linguistics},
	editor = {Cardie, Claire},
	month = jun,
	year = {2015}
}

@article{joel_katzav_modelling_2008,
	title = {Modelling argument recognition and reconstruction},
	issn = {0378-2166},
	doi = {10.1016/j.pragma.2007.07.004},
	journal = {Journal of Pragmatics},
	author = {Joel Katzav, Chris Reed},
	year = {2008}
}

@inproceedings{bamman_open_2015,
	address = {Lisbon, Portugal},
	title = {Open {Extraction} of {Fine}-{Grained} {Political} {Statements}},
	url = {http://aclweb.org/anthology/D15-1008},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Bamman, David and Smith, Noah A.},
	month = sep,
	year = {2015},
	pages = {76--85}
}

@inproceedings{eckle-kohler_role_2015,
	address = {Lisbon, Portugal},
	title = {On the {Role} of {Discourse} {Markers} for {Discriminating} {Claims} and {Premises} in {Argumentative} {Discourse}},
	url = {http://aclweb.org/anthology/D15-1267},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Eckle-Kohler, Judith and Kluge, Roland and Gurevych, Iryna},
	month = sep,
	year = {2015},
	pages = {2236--2242}
}

@article{walton_artificial_nodate,
	title = {Some {Artificial} {Intelligence} {Tools} for {Argument} {Evaluation}: {An} {Introduction}},
	shorttitle = {Some {Artificial} {Intelligence} {Tools} for {Argument} {Evaluation}},
	journal = {Argumentation},
	author = {Walton, Douglas},
	pages = {1--24}
}

@article{reed_structured_2014,
	title = {Structured {Arguments} and {Their} {Aggregation}: {A} {Reply} to {Selinger}},
	volume = {28},
	issn = {0920-427X},
	url = {http://dx.doi.org/10.1007/s10503-014-9327-1},
	doi = {10.1007/s10503-014-9327-1},
	language = {English},
	number = {3},
	journal = {Argumentation},
	author = {Reed, Chris},
	year = {2014},
	keywords = {Aggregation, Artificial intelligence, Structured argumentation},
	pages = {395--399}
}

@inproceedings{cardie_proceedings_2015-1,
	address = {Denver, CO},
	title = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	url = {http://www.aclweb.org/anthology/W15-05},
	publisher = {Association for Computational Linguistics},
	editor = {Cardie, Claire},
	month = jun,
	year = {2015}
}

@book{bianka_trevisan_indicators_2014,
	title = {Indicators of {Argument}-conclusion {Relationships}. {An} {Approach} for {Argumentation} {Mining} in {German} {Discourses}},
	url = {http://dx.doi.org/10.13140/2.1.3623.5044},
	language = {eng},
	publisher = {Unpublished},
	author = {{Bianka Trevisan} and {Eva-Maria Jakobs} and {Eva Dickmeis} and {Thomas Niehr}},
	year = {2014}
}

@article{peldszus_argument_2013,
	title = {From {Argument} {Diagrams} to {Argumentation} {Mining} in {Texts}: {A} {Survey}},
	volume = {7},
	issn = {1557-3958},
	shorttitle = {From {Argument} {Diagrams} to {Argumentation} {Mining} in {Texts}},
	url = {http://www.ling.uni-potsdam.de/ peldszus/ijcini2013-preprint.pdf},
	doi = {10.4018/jcini.2013010101},
	abstract = {In this paper, the authors consider argument mining as the task of building a formal representation for an argumentative piece of text. Their goal is to provide a critical survey of the literature on both the resulting representations i.e., argument diagramming techniques and on the various aspects of the automatic analysis process. For representation, the authors also provide a synthesized proposal of a scheme that combines advantages from several of the earlier approaches; in addition, the authors discuss the relationship between representing argument structure and the rhetorical structure of texts in the sense of Mann and Thompsons 1988 RST. Then, for the argument mining problem, the authors also cover the literature on closely-related tasks that have been tackled in Computational Linguistics, because they think that these can contribute to more powerful argument mining systems than the first prototypes that were built in recent years. The paper concludes with the authors' suggestions for the major challenges that should be addressed in the field of argument mining.},
	number = {1},
	journal = {International Journal of Cognitive Informatics and Natural Intelligence},
	author = {Peldszus, Andreas and Stede, Manfred},
	month = jan,
	year = {2013},
	note = {http://dx.doi.org/10.4018/jcini.2013010101},
	keywords = {Annotation Scheme, Argument Diagram, Argumentation, Rhetorical Structure Theory, Theory of Argumentation Structure, argument mining},
	pages = {1--31}
}

@inproceedings{ibn_faiz_extracting_2014,
	address = {Baltimore, Maryland},
	title = {Extracting {Higher} {Order} {Relations} {From} {Biomedical} {Text}},
	url = {http://www.aclweb.org/anthology/W14-2114},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Ibn Faiz, Syeed and Mercer, Robert},
	month = jun,
	year = {2014},
	pages = {100--101}
}

@inproceedings{park_identifying_2014,
	address = {Baltimore, Maryland},
	title = {Identifying {Appropriate} {Support} for {Propositions} in {Online} {User} {Comments}},
	url = {http://www.aclweb.org/anthology/W14-2105},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Park, Joonsuk and Cardie, Claire},
	month = jun,
	year = {2014},
	pages = {29--38}
}

@inproceedings{trevisan_indicators_2014,
	address = {Baltimore, Maryland},
	title = {Indicators of {Argument}-conclusion {Relationships}. {An} {Approach} for {Argumentation} {Mining} in {German} {Discourses}},
	url = {http://www.aclweb.org/anthology/W14-2116},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Trevisan, Bianka and Dickmeis, Eva and Jakobs, Eva-Maria and Niehr, Thomas},
	month = jun,
	year = {2014},
	pages = {104--105}
}

@inproceedings{mao_extracting_2014,
	address = {Baltimore, Maryland},
	title = {Extracting {Imperatives} from {Wikipedia} {Article} for {Deletion} {Discussions}},
	url = {http://www.aclweb.org/anthology/W14-2117},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Mao, Fiona and Mercer, Robert and Xiao, Lu},
	month = jun,
	year = {2014},
	pages = {106--107}
}

@incollection{egilmez_extending_2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Extending {Social} {Abstract} {Argumentation} with {Votes} on {Attacks}},
	copyright = {©2014 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-54372-2 978-3-642-54373-9},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-54373-9_2},
	abstract = {Social abstract argumentation laid theoretical foundations for future online debating systems with formal backbones and semantics. The advantage of these envisioned new systems is their capability of formally justifying the social outcomes of their debates. Many recent extensions proposed for argumentation in general have addressed the issue that not all attacks between arguments are equal, especially in the eyes of the crowd. This work generalises social abstract argumentation to incorporate voting on attacks, inducing a social notion of attack strengths.},
	language = {en},
	number = {8306},
	booktitle = {Theory and {Applications} of {Formal} {Argumentation}},
	publisher = {Springer Berlin Heidelberg},
	author = {Eğilmez, Sinan and Martins, João and Leite, João},
	editor = {Black, Elizabeth and Modgil, Sanjay and Oren, Nir},
	month = aug,
	year = {2013},
	keywords = {Artificial Intelligence (incl. Robotics), Theory of Computation},
	pages = {16--31}
}

@article{fabrizio_macagno_implicatures_2013,
	title = {Implicatures as {Forms} of {Argument}},
	doi = {10.1007/978-3-319-01011-3_9},
	author = {Fabrizio Macagno, Douglas Walton},
	year = {2013},
	pages = {203--224}
}

@article{walton_how_2011,
	title = {How to {Refute} an {Argument} {Using} {Artificial} {Intelligence}},
	author = {Walton, Douglas},
	year = {2011}
}

@inproceedings{khoo_extracting_2000,
	address = {Stroudsburg, PA, USA},
	series = {{ACL} '00},
	title = {Extracting {Causal} {Knowledge} from a {Medical} {Database} {Using} {Graphical} {Patterns}},
	url = {http://dx.doi.org/10.3115/1075218.1075261},
	doi = {10.3115/1075218.1075261},
	abstract = {This paper reports the first part of a project that aims to develop a knowledge extraction and knowledge discovery system that extracts causal knowledge from textual databases. In this initial study, we develop a method to identify and extract cause-effect information that is explicitly expressed in medical abstracts in the Medline database. A set of graphical patterns were constructed that indicate the presence of a causal relation in sentences, and which part of the sentence represents the cause and which part represents the effect. The patterns are matched with the syntactic parse trees of sentences, and the parts of the parse tree that match with the slots in the patterns are extracted as the cause or the effect.},
	booktitle = {Proceedings of the 38th {Annual} {Meeting} on {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Khoo, Christopher S. G. and Chan, Syin and Niu, Yun},
	year = {2000},
	pages = {336--343}
}

@incollection{macagno_implicatures_2013,
	series = {Perspectives in {Pragmatics}, {Philosophy} \& {Psychology}},
	title = {Implicatures as {Forms} of {Argument}},
	copyright = {©2013 Springer International Publishing Switzerland},
	isbn = {978-3-319-01010-6 978-3-319-01011-3},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-01011-3_9},
	abstract = {In this paper, we use concepts, structure and tools from argumentation theory to show how conversational implicatures are triggered by conflicts of presumptions. Presumptive implicatures are shown to be based on defeasible forms of inference used in conditions of lack of knowledge, including analogical reasoning, inference to the best explanation, practical reasoning, appeal to pity, and argument from cause. Such inferences are modelled as communicative strategies used to fill knowledge gaps by shifting the burden of proof to provide the missing contrary evidence to the other party in a dialogue. Through a series of illustrative examples, we show how such principles of inference are based on common knowledge about the ordinary course of events shared by participants in a structured dialogue setting in which they take turns putting forward and responding to speech acts.},
	language = {en},
	number = {1},
	booktitle = {Perspectives on {Pragmatics} and {Philosophy}},
	publisher = {Springer International Publishing},
	author = {Macagno, Fabrizio and Walton, Douglas},
	editor = {Capone, Alessandro and Piparo, Franco Lo and Carapezza, Marco},
	year = {2013},
	keywords = {Analogy, Argumentation, Argumentation schemes, Implicatures, Implicit speech acts, Indirect speech acts, Linguistics (general), Philosophy, Pragmatics, Pragmatism, Speech acts},
	pages = {203--225}
}

@inproceedings{sridhar_joint_2015,
	address = {Beijing, China},
	title = {Joint {Models} of {Disagreement} and {Stance} in {Online} {Debate}},
	url = {http://www.aclweb.org/anthology/P15-1012},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Sridhar, Dhanya and Foulds, James and Huang, Bert and Getoor, Lise and Walker, Marilyn},
	month = jul,
	year = {2015},
	pages = {116--125}
}

@inproceedings{peldszus_joint_2015,
	address = {Lisbon, Portugal},
	title = {Joint prediction in {MST}-style discourse parsing for argumentation mining},
	url = {http://aclweb.org/anthology/D15-1110},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Peldszus, Andreas and Stede, Manfred},
	month = sep,
	year = {2015},
	pages = {938--948}
}

@article{grosse_integrating_nodate,
	title = {Integrating argumentation and sentiment analysis for mining opinions from {Twitter}},
	journal = {AI Communications},
	author = {Grosse, Kathrin and González, María P and Chesñevar, Carlos I and Maguitman, Ana G}
}

@inproceedings{bex_generalising_2014,
	title = {Generalising argument dialogue with the {Dialogue} {Game} {Execution} {Platform}},
	url = {http://dx.doi.org/10.3233/978-1-61499-436-7-141},
	doi = {10.3233/978-1-61499-436-7-141},
	booktitle = {Computational {Models} of {Argument} - {Proceedings} of {COMMA} 2014, {Atholl} {Palace} {Hotel}, {Scottish} {Highlands}, {UK}, {September} 9-12, 2014},
	author = {Bex, Floris and Lawrence, John and Reed, Chris},
	year = {2014},
	pages = {141--152}
}

@article{walton_intelligent_2016,
	title = {Intelligent {Practical} {Reasoning} for {Autonomous} {Agents}: {An} {Introduction}},
	volume = {8},
	number = {1},
	journal = {Review of European Studies},
	author = {Walton, Douglas},
	year = {2016},
	pages = {1}
}

@inproceedings{green_identifying_2015,
	address = {Denver, CO},
	title = {Identifying {Argumentation} {Schemes} in {Genetics} {Research} {Articles}},
	url = {http://www.aclweb.org/anthology/W15-0502},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Green, Nancy},
	month = jun,
	year = {2015},
	pages = {12--21}
}

@inproceedings{sobhani_argumentation_2015,
	address = {Denver, CO},
	title = {From {Argumentation} {Mining} to {Stance} {Classification}},
	url = {http://www.aclweb.org/anthology/W15-0509},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Sobhani, Parinaz and Inkpen, Diana and Matwin, Stan},
	month = jun,
	year = {2015},
	pages = {67--77}
}

@inproceedings{nguyen_extracting_2015,
	address = {Denver, CO},
	title = {Extracting {Argument} and {Domain} {Words} for {Identifying} {Argument} {Components} in {Texts}},
	url = {http://www.aclweb.org/anthology/W15-0503},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Huy and Litman, Diane},
	month = jun,
	year = {2015},
	pages = {22--28}
}

@inproceedings{yanase_learning_2015,
	address = {Denver, CO},
	title = {Learning {Sentence} {Ordering} for {Opinion} {Generation} of {Debate}},
	url = {http://www.aclweb.org/anthology/W15-0512},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Yanase, Toshihiko and Miyoshi, Toshinori and Yanai, Kohsuke and Sato, Misa and Iwayama, Makoto and Niwa, Yoshiki and Reisert, Paul and Inui, Kentaro},
	month = jun,
	year = {2015},
	pages = {94--103}
}

@inproceedings{abbott_internet_nodate,
	address = {Paris, France},
	title = {Internet {Argument} {Corpus} 2.0: {An} {SQL} schema for {Dialogic} {Social} {Media} and the {Corpora} to go with it},
	isbn = {978-2-9517408-9-1},
	url = {http://www.lrec-conf.org/proceedings/lrec2016/summaries/1126.html},
	language = {english},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2016)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Abbott, Rob and Ecker, Brian and Anand, Pranav and Walker, Marilyn},
	editor = {Chair), Nicoletta Calzolari (Conference and Choukri, Khalid and Declerck, Thierry and Grobelnik, Marko and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios}
}

@inproceedings{mochales_palau_creating_2009,
	address = {Barcelona},
	title = {Creating an argumentation corpus: do theories apply to real arguments? {A} case study on the legal argumentation of the {ECHR}},
	url = {https://lirias.kuleuven.be/handle/123456789/426412},
	doi = {10.1145/1568234.1568238},
	booktitle = {Proceedings of the {Twelfth} {International} {Conference} on {Artificial} {Intelligence} and {Law} ({ICAIL} 2009), {Twelfth} international conference on artificial intelligence and law ({ICAIL} 2009)., {Barcelona}, {Spain}, 8-12 {June} 2009},
	publisher = {ACM},
	author = {Mochales Palau, Raquel and Ieven, Aagje},
	year = {2009},
	pages = {21--30}
}

@incollection{mochales_palau_automatic_2009,
	address = {Amsterdam},
	title = {Automatic argumentation detection and its role in law and the semantic web},
	url = {https://lirias.kuleuven.be/handle/123456789/197362},
	publisher = {IOS press},
	author = {Mochales Palau, Raquel and Moens, Marie-Francine},
	editor = {Breuker, Joost and Casanovas, Pompeu and Klein, Michel and Francesconi, Enrico},
	year = {2009}
}

@phdthesis{mochales_palau_automatic_2011,
	title = {Automatic {Detection} and {Classification} of {Argumentation} in a {Legal} {Case} ({Automatische} detectie en classificatie van de argumentatie in een juridische zaak)},
	url = {https://lirias.kuleuven.be/handle/123456789/305094},
	school = {Faculty of Engineering Science},
	author = {Mochales Palau, Raquel},
	month = jul,
	year = {2011},
	note = {Moens, Marie-Francine and De Schreye, Daniel (supervisors)}
}

@unpublished{mochales_palau_automatic_2007,
	title = {Automatic detection of arguments in legal texts},
	url = {https://lirias.kuleuven.be/handle/123456789/146821},
	author = {Mochales Palau, Raquel and Moens, Marie-Francine},
	year = {2007},
	note = {19th Belgian-Dutch Conference on Artificial Intelligence, Utrecht, The Netherlands, November 5-6, 2007}
}

@book{verheij_computational_2012,
	title = {Computational {Models} of {Argument}: {Proceedings} of {COMMA} 2012},
	isbn = {978-1-61499-110-6},
	shorttitle = {Computational {Models} of {Argument}},
	abstract = {The subject of argumentation has been studied since ancient times, but it has seen major innovations since the advent of the computer age. Software already exists which can create and evaluate arguments in high-stake situations, such as medical diagnosis and criminal investigation; formal systems can help us appreciate the role of the value judgments which underlie opposing positions; and it is even possible to enter into argumentative dialogues as if playing a computer game. This book presents the 28 full papers, 17 short papers and a number of system demonstrations, described in an extended abstract, from the 2012 biennial Computational Models of Argument (COMMA) conference, held in Vienna, Austria. Papers by the invited speakers Professor Trevor Bench-Capon, Professor Erik Krabbe and Professor Keith Stenning are also included. This year, for the first time, COMMA invited the submission of papers for an innovative applications track, and those which were accepted for presentation are included in this volume. Argumentation can be studied from many angles, including the artificial, natural and theoretical systems perspective.Presentations at the 2012 conference addressed the subject from these perspectives and many more.},
	language = {en},
	publisher = {IOS Press},
	author = {Verheij, Bart and Szeider, Stefan and Woltran, Stefan},
	year = {2012},
	keywords = {Computers / Intelligence (AI) \& Semantics}
}

@inproceedings{winkels_experiments_2013,
	address = {New York, NY, USA},
	series = {{ICAIL} '13},
	title = {Experiments in {Automated} {Support} for {Argument} {Reconstruction}},
	isbn = {978-1-4503-2080-1},
	url = {http://doi.acm.org/10.1145/2514601.2514633},
	doi = {10.1145/2514601.2514633},
	abstract = {This paper describes the outcomes of experiments in automated support for argument reconstruction from natural language texts. We investigated several possibilities to support a manual process by using natural language processing, from classifying pieces of text as either argumentative or non-argumentative to clustering text fragments in the hope that these clusters would contain similar arguments. Results are diverse, but also show that we cannot come a long way without an extensive pre-tagged corpus.},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Law}},
	publisher = {ACM},
	author = {Winkels, Radboud and Douw, Jochem and Veldhoen, Sara},
	year = {2013},
	keywords = {argument mining, clustering, policy modelling},
	pages = {232--236}
}

@inproceedings{carstens_enhancing_2013,
	address = {New York, NY, USA},
	series = {{WISDOM} '13},
	title = {Enhancing {Sentiment} {Extraction} from {Text} by {Means} of {Arguments}},
	isbn = {978-1-4503-2332-1},
	url = {http://doi.acm.org/10.1145/2502069.2502073},
	doi = {10.1145/2502069.2502073},
	abstract = {Sentiment Analysis is concerned with (1) differentiating opinionated text from factual text and, in the case of opinionated text, (2) determine its polarity. With this paper, we address problem (1) and present A-SVM (Argument enhanced Support Vector Machines), a multimodal system that focuses on the discrimination of opinionated text from non-opinionated text with the help of (i) Support Vector Machines (SVM) and (ii) arguments, acquired by means of a user feedback mechanism, and used to improve the SVM classifications. We have used a prototype to investigate the validity of approaching Sentiment Analysis in this multi faceted manner by comparing straightforward Machine Learning techniques with our multimodal system architecture. All evaluations were executed using a purpose-built corpus of annotated text and A-SVM's classification performance was compared to that of SVM. The classification of a test set of approximately 4,500 n-grams yielded an increase in classification precision of 5.6\%.},
	booktitle = {Proceedings of the {Second} {International} {Workshop} on {Issues} of {Sentiment} {Discovery} and {Opinion} {Mining}},
	publisher = {ACM},
	author = {Carstens, Lucas and Toni, Francesca},
	year = {2013},
	keywords = {A-SVM, Argumentation, sentiment analysis, support vector machines, user feedback},
	pages = {4:1--4:9}
}

@inproceedings{schneider_dimensions_2012,
	address = {Berlin, Heidelberg},
	series = {{EKAW}'12},
	title = {Dimensions of {Argumentation} in {Social} {Media}},
	isbn = {978-3-642-33875-5},
	url = {http://dx.doi.org/10.1007/978-3-642-33876-2_4},
	doi = {10.1007/978-3-642-33876-2_4},
	abstract = {Mining social media for opinions is important to governments and businesses. Current approaches focus on sentiment and opinion detection. Yet, people also justify their views, giving arguments. Understanding arguments in social media would yield richer knowledge about the views of individuals and collectives. Extracting arguments from social media is difficult. Messages appear to lack indicators for argument, document structure, or inter-document relationships. In social media, lexical variety, alternative spellings, multiple languages, and alternative punctuation are common. Social media also encompasses numerous genres. These aspects can confound the extraction of well-formed knowledge bases of argument. We chart out the various aspects in order to isolate them for further analysis and processing.},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Knowledge} {Engineering} and {Knowledge} {Management}},
	publisher = {Springer-Verlag},
	author = {Schneider, Jodi and Davis, Brian and Wyner, Adam},
	year = {2012},
	pages = {21--25}
}

@inproceedings{feng_classifying_2011,
	address = {Stroudsburg, PA, USA},
	series = {{HLT} '11},
	title = {Classifying {Arguments} by {Scheme}},
	isbn = {978-1-932432-87-9},
	url = {http://dl.acm.org/citation.cfm?id=2002472.2002597},
	abstract = {Argumentation schemes are structures or templates for various kinds of arguments. Given the text of an argument with premises and conclusion identified, we classify it as an instance of one of five common schemes, using features specific to each scheme. We achieve accuracies of 63–91\% in one-against-others classification and 80–94\% in pairwise classification (baseline = 50\% in both cases).},
	booktitle = {Proceedings of the 49th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies} - {Volume} 1},
	publisher = {Association for Computational Linguistics},
	author = {Feng, Vanessa Wei and Hirst, Graeme},
	year = {2011},
	pages = {987--996}
}

@book{walton_argumentation_1996,
	address = {Mahwah, N.J},
	series = {{LEA} titles in argumentation},
	title = {Argumentation schemes for presumptive reasoning},
	isbn = {0-8058-2071-X},
	language = {eng},
	publisher = {Erlbaum},
	author = {Walton, Douglas N.},
	year = {1996},
	keywords = {Argumentation, Hypothese, Präsupposition}
}

@book{walton_argumentation_2008,
	address = {Cambridge [u.a.]},
	edition = {1. publ},
	title = {Argumentation schemes},
	isbn = {978-0-521-89790-7},
	url = {http://www.loc.gov/catdir/enhancements/fy0809/2007045337-b.html},
	language = {eng},
	publisher = {Cambridge Univ. Press},
	author = {Walton, Douglas N. and Reed, Chris and Macagno, Fabrizio},
	year = {2008},
	note = {Hier auch später erschienene, unveränderte Nachdrucke},
	keywords = {Argumentationstheorie}
}

@inproceedings{boltuzic_back_2014,
	address = {Baltimore, Maryland},
	title = {Back up your {Stance}: {Recognizing} {Arguments} in {Online} {Discussions}},
	url = {http://www.aclweb.org/anthology/W14-2107},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Boltužić, Filip and Šnajder, Jan},
	month = jun,
	year = {2014},
	pages = {49--58}
}

@inproceedings{schneider_automated_2014,
	address = {Baltimore, Maryland},
	title = {Automated argumentation mining to the rescue? {Envisioning} argumentation and decision-making support for debates in open online collaboration communities},
	url = {http://www.aclweb.org/anthology/W14-2108},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Schneider, Jodi},
	month = jun,
	year = {2014},
	pages = {59--63}
}

@article{cabrio_combining_2012,
	title = {Combining {Textual} {Entailment} and {Argumentation} {Theory} for {Supporting} {Online} {Debates} {Interactions}},
	volume = {2},
	url = {http://aclanthology.info/papers/combining-textual-entailment-and-argumentation-theory-for-supporting-online-debates-interactions},
	journal = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
	author = {Cabrio, Elena and Villata, Serena},
	year = {2012},
	pages = {208--212}
}

@article{fabrizio_macagno_classifying_2015,
	title = {Classifying the {Patterns} of {Natural} {Arguments}},
	volume = {48},
	issn = {1527-2079},
	number = {1},
	journal = {Philosophy and Rhetoric},
	author = {Fabrizio Macagno, Douglas Walton},
	year = {2015},
	pages = {26--53}
}

@inproceedings{buckingham_shum_cohere:_2008,
	address = {Toulouse, France},
	title = {Cohere: {Towards} {Web} 2.0 {Argumentation}},
	isbn = {978-1-58603-859-5},
	shorttitle = {Cohere},
	url = {http://www.irit.fr/comma08/accepted.html},
	abstract = {Students, researchers and professional analysts lack effective tools to make personal and collective sense of problems while working in distributed teams. Central to this work is the process of sharing–and contesting–interpretations via different forms of argument. How does the 'Web 2.0' paradigm challenge us to deliver useful, usable tools for online argumentation? This paper reviews the current state of the art in Web Argumentation, describes key features of the Web 2.0 orientation, and identifies some of the tensions that must be negotiated in bringing these worlds together. It then describes how these design principles are interpreted in Cohere, a web tool for social bookmarking, idea-linking, and argument visualization.},
	publisher = {IOS Press},
	author = {Buckingham Shum, Simon},
	year = {2008},
	pages = {97--108}
}

@book{baroni_computational_2010,
	title = {Computational {Models} of {Argument}: {Proceedings} of {COMMA} 2010},
	isbn = {978-1-60750-618-8},
	shorttitle = {Computational {Models} of {Argument}},
	abstract = {Presents papers from the Third Conference on Computational Models of Argument, held in September 2010 in Desanzano del Garda, Italy. Providing a view of this important research field, this book is of interest to those involved in the use and development of artificial intelligence systems.},
	language = {en},
	publisher = {IOS Press},
	author = {Baroni, Pietro and Cerutti, F. and Giacomin, M. and Simari, Guillermo R.},
	year = {2010},
	keywords = {Computers / Intelligence (AI) \& Semantics}
}

@inproceedings{eduardo_blanco_causal_2008,
	address = {Marrakech, Morocco},
	title = {Causal {Relation} {Extraction}},
	isbn = {2-9517408-4-0},
	language = {english},
	booktitle = {Proceedings of the {Sixth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'08)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Eduardo Blanco, Nuria Castell and Moldovan, Dan},
	editor = {Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Daniel Tapias},
	year = {2008},
	note = {http://www.lrec-conf.org/proceedings/lrec2008/}
}

@book{borries_computerunterstutzung_1997,
	title = {Computerunterstützung der {Argumentation} in {Gruppen}: {Aufbereitung} einer {Sprechaktsequenz} nach {Habermas} und {Vorstellung} eines {Prototypen}},
	isbn = {978-3-322-90283-2},
	shorttitle = {Computerunterstützung der {Argumentation} in {Gruppen}},
	url = {https://books.google.de/books?id=oYmkBwAAQBAJ&pg=PA199&lpg=PA199&dq=modellierung+der+argumentation&source=bl&ots=XGWQLpVn6e&sig=ZlceXp9YX2DB9bYCvlZ6VUowx3c&hl=de&sa=X&ei=gHRjVbOJO8GwsQGlqYGwDA&ved=0CE0Q6AEwCTgK#v=onepage&q=modellierung%20der%20argumentation&f=false},
	abstract = {Der Autor gibt einen Überblick über die wesentlichen Bereiche der Argumentationsforschung und über Computersysteme, die die Argumentation in Gruppen unterstützen. Die Erkenntnisse fließen in ein neues System zur Förderung von herrschaftsfreier Argumentation, Verhandlung und Problemlösung in Gruppen.},
	language = {de},
	publisher = {Springer-Verlag},
	author = {Börries, Ludwig},
	year = {1997},
	keywords = {Business \& Economics / General}
}

@article{walton_building_2012,
	title = {Building a {System} for {Finding} {Objections} to an {Argument}},
	volume = {26},
	issn = {0920-427X},
	url = {http://dx.doi.org/10.1007/s10503-012-9261-z},
	doi = {10.1007/s10503-012-9261-z},
	language = {English},
	number = {3},
	journal = {Argumentation},
	author = {Walton, Douglas},
	year = {2012},
	keywords = {Argument from inconsistent commitment, Argument invention, Argument visualization tools, Argumentation schemes, Critical questions, Proleptic argumentation, Rebuttal, Refutation},
	pages = {369--391}
}

@inproceedings{bilu_automatic_2015,
	address = {Denver, CO},
	title = {Automatic {Claim} {Negation}: {Why}, {How} and {When}},
	shorttitle = {Automatic {Claim} {Negation}},
	url = {http://www.aclweb.org/anthology/W15-0511},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Bilu, Yonatan and Hershcovich, Daniel and Slonim, Noam},
	month = jun,
	year = {2015},
	pages = {84--93}
}

@inproceedings{park_conditional_2015,
	address = {Denver, CO},
	title = {Conditional {Random} {Fields} for {Identifying} {Appropriate} {Types} of {Support} for {Propositions} in {Online} {User} {Comments}},
	url = {http://www.aclweb.org/anthology/W15-0506},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Park, Joonsuk and Katiyar, Arzoo and Yang, Bishan},
	month = jun,
	year = {2015},
	pages = {39--44}
}

@inproceedings{nguyen_context-aware_2016,
	address = {Berlin, Germany},
	title = {Context-aware {Argumentative} {Relation} {Mining}},
	url = {http://www.aclweb.org/anthology/P16-1107},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Huy and Litman, Diane},
	month = aug,
	year = {2016},
	pages = {1127--1137}
}

@article{walker_framework_2011,
	title = {A framework for the extraction and modeling of fact-finding reasoning from legal decisions: lessons from the {Vaccine}/{Injury} {Project} {Corpus}},
	volume = {19},
	issn = {0924-8463},
	shorttitle = {A framework for the extraction and modeling of fact-finding reasoning from legal decisions},
	doi = {10.1007/s10506-011-9115-2},
	abstract = {This article describes the Vaccine/Injury Project Corpus, a collection of legal decisions awarding or denying compensation for health injuries allegedly due to vaccinations, together with models of the logical structure of the reasoning of the factfinders in those cases. This unique corpus provides useful data for formal and informal logic theory, for natural-language research in linguistics, and for artificial intelligence research. More importantly, the article discusses lessons learned from developing protocols for manually extracting the logical structure and generating the logic models. It identifies sub-tasks in the extraction process, discusses challenges to automation, and provides insights into possible solutions for automation. In particular, the framework and strategies developed here, together with the corpus data, should allow “top–down” and contextual approaches to automation, which can supplement “bottom-up” linguistic approaches. Illustrations throughout the article use examples drawn from the Corpus.},
	language = {eng},
	number = {4},
	journal = {Artificial Intelligence and Law},
	author = {Walker, Vern and Carie, Nathaniel and DeWitt, Courtney and Lesh, Eric},
	year = {2011},
	keywords = {Argumentation mining, Automation, Legal evidence, Legal rule, Logic schema, Vaccines},
	pages = {291--331}
}

@inproceedings{mochales_palau_argumentation_2009,
	address = {New York},
	title = {Argumentation mining: the detection, classification and structure of arguments in text},
	url = {https://lirias.kuleuven.be/handle/123456789/234784},
	booktitle = {Proceedings of the {Twelfth} {International} {Conference} on {Artificial} {Intelligence} and {Law} ({ICAIL} 2009), {Twelfth} international conference on artificial intelligence and law ({ICAIL} 2009), {Barcelona}, {Spain}, 8-12 {June} 2009},
	publisher = {ACM},
	author = {Mochales Palau, Raquel and Moens, Marie-Francine},
	year = {2009},
	pages = {98--109}
}

@article{mochales_palau_argumentation_2011,
	title = {Argumentation mining},
	volume = {19},
	url = {https://lirias.kuleuven.be/handle/123456789/291845},
	number = {1},
	journal = {Artificial Intelligence and Law},
	author = {Mochales Palau, Raquel and Moens, Marie-Francine},
	year = {2011},
	pages = {1--22}
}

@inproceedings{mochales_palau_acila_2007,
	title = {{ACILA} - {Automatic} detection of arguments in legal cases},
	url = {https://lirias.kuleuven.be/handle/123456789/146815},
	booktitle = {Proceedings of the {Workshop} on {Semantic} {Web} {Technology} for {Law}, {Workshop} on {Semantic} {Web} {Technology} for {Law}, {Stanford}, {CA}, {USA}, {June} 16, 2007},
	author = {Mochales Palau, Raquel and Moens, Marie-Francine},
	year = {2007},
	pages = {5--9}
}

@incollection{abbas_argument_2010,
	series = {Studies in {Computational} {Intelligence}},
	title = {Argument {Mining} from {RADB} and {Its} {Usage} in {Arguing} {Agents} and {Intelligent} {Tutoring} {System}},
	copyright = {©2010 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-14434-9 978-3-642-14435-6},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-14435-6_5},
	abstract = {Argumentation is an interdisciplinary research area that incorporates many fields such as artificial intelligence, multi-agent systems, and collaborative learning. In this chapter, we describe argument mining techniques from a structured argument database “RADB”, a sort of relational database we designed specially for organizing argument databases, and their usage in arguing agents and intelligent tutoring systems. The RADB repository depends on the Argumentation Interchange Format Ontology (AIF) using “Walton Theory” for argument analysis. It presents a novel approach that summarizes the argument data set into structured form “RADB” in order to (i) facilitate the data interoperability among various agents/humans/tools, (ii) provide the ability to freely navigate the repository by integrating the data mining techniques gathered in a classifier agent; mine the RADB repository and retrieve the most relevant arguments to the users’ queries, (iii) illustrate an agent-based learning environment outline, where the mining classifier agent and the RADB are incorporated together within an intelligent tutoring system (ITS). Such incorporation assists in (i) deepening the understanding of negotiation, decision making, and critical thinking, (ii) guiding the analysis process to refine the user’s underlying classification, and improving the analysis and the students’ intellectual process. Later in the chapter, we describe an effective usage of argument mining for arguing agents, which interact with each other in the Internet environment and argues about issues concerned, casting arguments and counter-arguments each other to reach an agreement. We illustrate how argument mining allows to strengthen arguing agent intelligence, resulting in expanding the main concern in formal argumentation frameworks that is to formalize methods in which the final statuses of arguments are to be decided semantically and/or dialectically. In both usages, we yield new forms of argument-based intelligence, which allows establishing one’s own argument by comparing diverse views and opinions and uncovering new leads, differently from simple refutation aiming at cutting down other parties.},
	language = {en},
	number = {310},
	booktitle = {Innovations in {Multi}-{Agent} {Systems} and {Applications} - 1},
	publisher = {Springer Berlin Heidelberg},
	author = {Abbas, Safia and Sawamura, Hajime},
	editor = {Srinivasan, Dipti and Jain, Lakhmi C.},
	year = {2010},
	keywords = {Appl.Mathematics/Computational Methods of Engineering, Artificial Intelligence (incl. Robotics)},
	pages = {113--147}
}

@article{schneider_review_2013,
	title = {A {Review} of {Argumentation} for the {Social} {Semantic} {Web}},
	volume = {4},
	issn = {1570-0844},
	url = {http://dl.acm.org/citation.cfm?id=2590215.2590218},
	abstract = {Argumentation represents the study of views and opinions that humans express with the goal of reaching a conclusion through logical reasoning. Since the 1950's, several models have been proposed to capture the essence of informal argumentation in different settings. With the emergence of the Web, and then the Semantic Web, this modeling shifted towards ontologies, while from the development perspective, we witnessed an important increase in Web 2.0 human-centered collaborative deliberation tools. Through a review of more than 150 scholarly papers, this article provides a comprehensive and comparative overview of approaches to modeling argumentation for the Social Semantic Web. We start from theoretical foundational models and investigate how they have influenced Social Web tools. We also look into Semantic Web argumentation models. Finally we end with Social Web tools for argumentation, including online applications combining Web 2.0 and Semantic Web technologies, following the path to a global World Wide Argument Web.},
	number = {2},
	journal = {Semant. web},
	author = {Schneider, Jodi and Groza, Tudor and Passant, Alexandre},
	month = apr,
	year = {2013},
	keywords = {Argumentation, Ontologies, Semantic Web, Social Web},
	pages = {159--218}
}

@book{walton_argument_1996,
	address = {Toronto [u.a.]},
	series = {Toronto studies in philosophy},
	title = {Argument structure: a pragmatic theory},
	isbn = {0-8020-0768-6},
	shorttitle = {Argument structure},
	language = {eng},
	publisher = {Univ. of Toronto Press},
	author = {Walton, Douglas N.},
	year = {1996},
	keywords = {Argument, Logik}
}

@inproceedings{walker_annotating_2014,
	address = {Baltimore, Maryland},
	title = {Annotating {Patterns} of {Reasoning} about {Medical} {Theories} of {Causation} in {Vaccine} {Cases}: {Toward} a {Type} {System} for {Arguments}},
	url = {http://www.aclweb.org/anthology/W14-2101},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Walker, Vern and Vazirova, Karina and Sanford, Cass},
	month = jun,
	year = {2014},
	pages = {1--10}
}

@inproceedings{houngbo_automated_2014,
	address = {Baltimore, Maryland},
	title = {An automated method to build a corpus of rhetorically-classified sentences in biomedical texts},
	url = {http://www.aclweb.org/anthology/W14-2103},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Houngbo, Hospice and Mercer, Robert},
	month = jun,
	year = {2014},
	pages = {19--23}
}

@inproceedings{song_applying_2014,
	address = {Baltimore, Maryland},
	title = {Applying {Argumentation} {Schemes} for {Essay} {Scoring}},
	url = {http://www.aclweb.org/anthology/W14-2110},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Song, Yi and Heilman, Michael and Beigman Klebanov, Beata and Deane, Paul},
	month = jun,
	year = {2014},
	pages = {69--78}
}

@inproceedings{ghosh_analyzing_2014,
	address = {Baltimore, Maryland},
	title = {Analyzing {Argumentative} {Discourse} {Units} in {Online} {Interactions}},
	url = {http://www.aclweb.org/anthology/W14-2106},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Ghosh, Debanjan and Muresan, Smaranda and Wacholder, Nina and Aakhus, Mark and Mitsui, Matthew},
	month = jun,
	year = {2014},
	pages = {39--48}
}

@inproceedings{aharoni_benchmark_2014,
	address = {Baltimore, Maryland},
	title = {A {Benchmark} {Dataset} for {Automatic} {Detection} of {Claims} and {Evidence} in the {Context} of {Controversial} {Topics}},
	url = {http://www.aclweb.org/anthology/W14-2109},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Aharoni, Ehud and Polnarov, Anatoly and Lavee, Tamar and Hershcovich, Daniel and Levy, Ran and Rinott, Ruty and Gutfreund, Dan and Slonim, Noam},
	month = jun,
	year = {2014},
	note = {https://www.research.ibm.com/haifa/dept/vst/mlta\_benchmark.shtml},
	pages = {64--68}
}

@article{bex_argublogging:_2014,
	title = {{ArguBlogging}: {An} application for the {Argument} {Web}},
	volume = {25},
	issn = {1570-8268},
	shorttitle = {{ArguBlogging}},
	url = {http://www.sciencedirect.com/science/article/pii/S1570826814000079},
	doi = {10.1016/j.websem.2014.02.002},
	abstract = {In this paper, we present a software tool for ‘ArguBlogging’, which allows users to construct debate and discussions across blogs, linking existing and new online resources to form distributed, structured conversations. Arguments and counterarguments can be posed by giving opinions on one’s own blog and replying to other bloggers’ posts. The resulting argument structure is connected to the Argument Web, in which argumentative structures are made semantically explicit and machine-processable. We discuss the ArguBlogging tool and the underlying infrastructure and ontology of the Argument Web.},
	journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
	author = {Bex, Floris and Snaith, Mark and Lawrence, John and Reed, Chris},
	year = {2014},
	keywords = {Argumentation, Blogging, Opinions, Web Apps},
	pages = {9--15}
}

@phdthesis{zablith_argdf:_2007,
	type = {Dissertation},
	title = {{ArgDF}: {Arguments} on the {Semantic} {Web}},
	school = {The British University in Dubai Jointly with The University of Edinburgh},
	author = {Zablith, Fouad},
	year = {2007}
}

@inproceedings{stab_annotating_2014,
	address = {Dublin, Ireland},
	title = {Annotating {Argument} {Components} and {Relations} in {Persuasive} {Essays}},
	url = {http://anthology.aclweb.org/C/C14/C14-1142.pdf},
	abstract = {In this paper, we present a novel approach to model arguments, their components and relations in persuasive essays in English. We propose an annotation scheme that includes the annotation of claims and premises as well as support and attack relations for capturing the structure of argumentative discourse. We further conduct a manual annotation study with three annotators on 90 persuasive essays. The obtained inter-rater agreement of αU = 0.72 for argument components and α = 0.81 for argumentative relations indicates that the proposed annotation scheme successfully guides annotators to substantial agreement. The final corpus and the annotation guidelines are freely available to encourage future research in argument recognition.},
	language = {English},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Computational} {Linguistics} ({COLING} 2014)},
	publisher = {Dublin City University and Association for Computational Linguistics},
	author = {Stab, Christian and Gurevych, Iryna},
	editor = {Tsujii, Junichi and Hajic, Jan},
	month = aug,
	year = {2014},
	pages = {1501--1510}
}

@inproceedings{stab_argumentation_2014,
	address = {Bertinoro, Italy},
	title = {Argumentation {Mining} in {Persuasive} {Essays} and {Scientific} {Articles} from the {Discourse} {Structure} {Perspective}},
	url = {https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2014/FrontiersArg2014_PrePrint.pdf},
	abstract = {In this paper, we analyze and discuss approaches to argumentation mining from the discourse structure perspective. We chose persuasive essays and scientific articles as our example domains. By analyzing several example arguments and providing an overview of previous work on argumentation mining, we derive important tasks that are currently not addressed by existing argumentation mining systems, most importantly, the identification of argumentation structures. We discuss the relation of this task to automated discourse analysis and describe preliminary results of two annotation studies focusing on the annotation of argumentation structure. Based on our findings, we derive three challenges for encouraging future research on argumentation mining.},
	booktitle = {Proceedings of the {Workshop} on {Frontiers} and {Connections} between {Argumentation} {Theory} and {Natural} {Language} {Processing}},
	publisher = {CEUR-WS},
	author = {Stab, Christian and Kirschner, Christian and Eckle-Kohler, Judith and {Iryna Gurevych}},
	editor = {Cabrio, Elena and Villata, Serena and Wyner, Adam},
	month = jul,
	year = {2014},
	pages = {40--49}
}

@inproceedings{habernal_argumentation_2014,
	address = {Bertinoro, Italy},
	title = {Argumentation {Mining} on the {Web} from {Information} {Seeking} {Perspective}},
	url = {https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2014/argumentation-on-the-web-final-preprint.pdf},
	abstract = {In this paper, we argue that an annotation scheme for argumentation mining is a function of the task requirements and the corpus properties. There is no one-size-fits-all argumentation theory to be applied to realistic data on the Web. In two annotation studies, we experiment with 80 German newspaper editorials from the Web and about one thousand English documents from forums, comments, and blogs. Our example topics are taken from the educational domain. To formalize the problem of annotating arguments, in the first case, we apply a Claim-Premise scheme, and in the second case, we modify Toulmin's scheme. We find that the choice of the argument components to be annotated strongly depends on the register, the length of the document, and inherently on the literary devices and structures used for expressing argumentation. We hope that these findings will facilitate the creation of reliably annotated argumentation corpora for a wide range of tasks and corpus types and will help to bridge the gap between argumentation theories and actual application needs.},
	booktitle = {Proceedings of the {Workshop} on {Frontiers} and {Connections} between {Argumentation} {Theory} and {Natural} {Language} {Processing}},
	publisher = {CEUR-WS},
	author = {Habernal, Ivan and Eckle-Kohler, Judith and Gurevych, Iryna},
	editor = {Cabrio, Elena and Villata, Serena and Wyner, Adam},
	month = jul,
	year = {2014},
	pages = {26--39}
}

@article{wells_domain_2012,
	title = {A domain specific language for describing diverse systems of dialogue},
	volume = {10},
	issn = {15708683},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1570868312000602},
	doi = {10.1016/j.jal.2012.09.001},
	language = {en},
	number = {4},
	journal = {Journal of Applied Logic},
	author = {Wells, S. and Reed, C.A.},
	year = {2012},
	pages = {309--329}
}

@inproceedings{rooney_applying_2012,
	title = {Applying kernel methods to argumentation mining},
	url = {http://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS12/paper/view/4366},
	booktitle = {Twenty-{Fifth} {International} {FLAIRS} {Conference}},
	author = {Rooney, Niall and Wang, Hui and Browne, Fiona},
	year = {2012}
}

@article{walton_argumentation_2016,
	title = {An {Argumentation} {Interface} for {Expert} {Opinion} {Evidence}},
	volume = {29},
	issn = {1467-9337},
	url = {http://dx.doi.org/10.1111/raju.12115},
	doi = {10.1111/raju.12115},
	number = {1},
	journal = {Ratio Juris},
	author = {Walton, Douglas and Zhang, Nanning},
	year = {2016},
	pages = {59--82}
}

@inproceedings{kiesel_shared_2015,
	address = {Denver, CO},
	title = {A {Shared} {Task} on {Argumentation} {Mining} in {Newspaper} {Editorials}},
	url = {http://www.aclweb.org/anthology/W15-0505},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Kiesel, Johannes and Al Khatib, Khalid and Hagen, Matthias and Stein, Benno},
	month = jun,
	year = {2015},
	pages = {35--38}
}

@inproceedings{oraby_and_2015,
	address = {Denver, CO},
	title = {And {That}'s {A} {Fact}: {Distinguishing} {Factual} and {Emotional} {Argumentation} in {Online} {Dialogue}},
	shorttitle = {And {That}'s {A} {Fact}},
	url = {http://www.aclweb.org/anthology/W15-0515},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Oraby, Shereen and Reed, Lena and Compton, Ryan and Riloff, Ellen and Walker, Marilyn and Whittaker, Steve},
	month = jun,
	year = {2015},
	pages = {116--126}
}

@inproceedings{wyner_argument_2015,
	address = {Denver, CO},
	title = {Argument {Discovery} and {Extraction} with the {Argument} {Workbench}},
	url = {http://www.aclweb.org/anthology/W15-0510},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Wyner, Adam and Peters, Wim and Price, David},
	month = jun,
	year = {2015},
	pages = {78--83}
}

@inproceedings{reisert_computational_2015,
	address = {Denver, CO},
	title = {A {Computational} {Approach} for {Generating} {Toulmin} {Model} {Argumentation}},
	url = {http://www.aclweb.org/anthology/W15-0507},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Reisert, Paul and Inoue, Naoya and Okazaki, Naoaki and Inui, Kentaro},
	month = jun,
	year = {2015},
	pages = {45--55}
}

@inproceedings{sardianos_argument_2015,
	address = {Denver, CO},
	title = {Argument {Extraction} from {News}},
	url = {http://www.aclweb.org/anthology/W15-0508},
	booktitle = {Proceedings of the 2nd {Workshop} on {Argumentation} {Mining}},
	publisher = {Association for Computational Linguistics},
	author = {Sardianos, Christos and Katakis, Ioannis Manousos and Petasis, Georgios and Karkaletsis, Vangelis},
	month = jun,
	year = {2015},
	pages = {56--66}
}
@article{etzioni_unsupervised_2005,
	title = {Unsupervised named-entity extraction from the {Web}: {An} experimental study},
	volume = {165},
	issn = {0004-3702},
	shorttitle = {Unsupervised named-entity extraction from the {Web}},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370205000366},
	doi = {10.1016/j.artint.2005.03.001},
	abstract = {The KnowItAll system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an unsupervised, domain-independent, and scalable manner. The paper presents an overview of KnowItAll's novel architecture and design principles, emphasizing its distinctive ability to extract information without any hand-labeled training examples. In its first major run, KnowItAll extracted over 50,000 class instances, but suggested a challenge: How can we improve KnowItAll's recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Pattern Learning learns domain-specific extraction rules, which enable additional extractions. Subclass Extraction automatically identifies sub-classes in order to boost recall (e.g., “chemist” and “biologist” are identified as sub-classes of “scientist”). List Extraction locates lists of class instances, learns a “wrapper” for each list, and extracts elements of each list. Since each method bootstraps from KnowItAll's domain-independent methods, the methods also obviate hand-labeled training examples. The paper reports on experiments, focused on building lists of named entities, that measure the relative efficacy of each method and demonstrate their synergy. In concert, our methods gave KnowItAll a 4-fold to 8-fold increase in recall at precision of 0.90, and discovered over 10,000 cities missing from the Tipster Gazetteer.},
	number = {1},
	urldate = {2014-07-12},
	journal = {Artificial Intelligence},
	author = {Etzioni, Oren and Cafarella, Michael and Downey, Doug and Popescu, Ana-Maria and Shaked, Tal and Soderland, Stephen and Weld, Daniel S. and Yates, Alexander},
	month = jun,
	year = {2005},
	keywords = {Pointwise mutual information, Unsupervised, information extraction, question answering},
	pages = {91--134}
}

@misc{noauthor_buchkapitel_nodate,
	title = {Buchkapitel [{PDF}]: {AutoTutor} 2013: {Conversation}-{Based} {Online} {Intelligent} {Tutoring} {System} with {Rich} {Media} ({Interactive} {Event}) {\textbar} {E}-{Technik}, {Informatik} + {IT} - {Springer} für {Professionals}},
	shorttitle = {Buchkapitel [{PDF}]},
	url = {http://www.springerprofessional.de/4520198},
	abstract = {Aus dem eBook: Artificial Intelligence in Education von David Hutchison, Takeo Kanade, Josef Kittler, Jon M. Kleinberg, Friedemann Mattern, John C. Mitchell, Moni Naor, Oscar Nierstrasz, C. Pandu Rangan, Bernhard Steffen, Madhu Sudan, Demetri Terzopoulos, Doug Tygar, Moshe Y. Vardi, Gerhard Weikum, Randy Goebel, Jörg Siekmann, Wolfgang Wahlster, H. Chad Lane, Kalina Yacef, Jack Mostow, Philip Pavlik: AutoTuto 2013 is an advanced version of the intelligent tutoring system, proven to be effective in e},
	urldate = {2014-09-28TZ},
	note = {00000}
}

@misc{noauthor_emotive_nodate,
	title = {Emotive {Computing} {Group}},
	url = {http://141.225.218.248/web-cslwebroot/emotion/index4.htm},
	urldate = {2014-09-30TZ},
	note = {00000}
}

@inproceedings{del_corro_clausie:_2013,
	title = {{ClausIE}: clause-based open information extraction},
	shorttitle = {{ClausIE}},
	url = {http://dl.acm.org/citation.cfm?id=2488420},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 22nd international conference on {World} {Wide} {Web}},
	author = {Del Corro, Luciano and Gemulla, Rainer},
	year = {2013},
	note = {00082},
	pages = {355--366}
}

@misc{noauthor_distant-supervision_nodate,
	title = {Distant-{Supervision} {Learning} {Algorithm} - {GM}-{RKB}},
	url = {http://www.gabormelli.com/RKB/Distant-Supervision_Learning_Algorithm},
	urldate = {2016-10-05TZ}
}

@inproceedings{yates_textrunner:_2007,
	address = {Stroudsburg, PA, USA},
	series = {{NAACL}-{Demonstrations} '07},
	title = {{TextRunner}: {Open} {Information} {Extraction} on the {Web}},
	shorttitle = {{TextRunner}},
	url = {http://dl.acm.org/citation.cfm?id=1614164.1614177},
	abstract = {Traditional information extraction systems have focused on satisfying precise, narrow, pre-specified requests from small, homogeneous corpora. In contrast, the TextRunner system demonstrates a new kind of information extraction, called Open Information Extraction (OIE), in which the system makes a single, data-driven pass over the entire corpus and extracts a large set of relational tuples, without requiring any human input. (Banko et al., 2007) TextRunner is a fully-implemented, highly scalable example of OIE. TextRunner's extractions are indexed, allowing a fast query mechanism.},
	urldate = {2015-08-20},
	booktitle = {Proceedings of {Human} {Language} {Technologies}: {The} {Annual} {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Yates, Alexander and Cafarella, Michael and Banko, Michele and Etzioni, Oren and Broadhead, Matthew and Soderland, Stephen},
	year = {2007},
	pages = {25--26}
}

@article{etzioni_open_2008,
	title = {Open {Information} {Extraction} from the {Web}},
	volume = {51},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1409360.1409378},
	doi = {10.1145/1409360.1409378},
	abstract = {Targeted IE methods are transforming into open-ended techniques.},
	number = {12},
	urldate = {2014-07-12},
	journal = {Commun. ACM},
	author = {Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S.},
	year = {2008},
	pages = {68--74}
}

@article{schwenk_continuous_2007,
	title = {Continuous space language models},
	volume = {21},
	issn = {08852308},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0885230806000325},
	doi = {10.1016/j.csl.2006.09.003},
	language = {en},
	number = {3},
	urldate = {2016-09-26TZ},
	journal = {Computer Speech \& Language},
	author = {Schwenk, Holger},
	month = jul,
	year = {2007},
	pages = {492--518}
}

@misc{kendall_libguides:_nodate,
	title = {{LibGuides}: {PubMed}, {Web} of {Science}, or {Google} {Scholar}? {A} behind-the-scenes guide for life scientists. : {So} which is better: {PubMed}, {Web} of {Science}, or {Google} {Scholar}?},
	copyright = {Copyright Michigan State University Libraries 2016},
	shorttitle = {{LibGuides}},
	url = {http://libguides.lib.msu.edu/c.php?g=96972&p=627295},
	language = {en},
	urldate = {2016-09-09TZ},
	author = {Kendall, Susan},
	note = {00001}
}

@article{staff_boosting_nodate,
	title = {Boosting {Bookmark} {Category} {Web} {Page} {Classification} {Accuracy} using {Multiple} {Clustering} {Approaches}},
	url = {https://secure.um.edu.mt/__data/assets/pdf_file/0006/51738/wict08_submission_3.pdf},
	urldate = {2016-08-18TZ},
	author = {Staff, Chris},
	note = {00000}
}

@misc{noauthor_syntax-begleitblatt.pdf_nodate,
	title = {Syntax-{Begleitblatt}.pdf},
	url = {https://www.uni-frankfurt.de/59466459/Syntax-Begleitblatt.pdf},
	urldate = {2016-07-28TZ},
	note = {00000}
}

@article{barenfanger_e-learning_nodate,
	title = {E-{Learning} and {Computational} {Linguistics} {An} {Introduction}},
	url = {http://www.jlcl.org/2011_Heft1/H2011-1.pdf#page=5},
	urldate = {2016-07-28TZ},
	journal = {Language Resources and Technologies in Learning and Teaching Sprachressourcen und-technologien in Lehre und},
	author = {Bärenfänger, Maja and Stührenberg, Maik},
	note = {00000}
}

@article{zinsmeister_chancen_2011,
	title = {Chancen und {Probleme} der {Nutzung} von {Korpora}, {Taggern} und anderen {Sprachressourcen} in {Seminaren}},
	volume = {26},
	url = {http://kops.uni-konstanz.de/handle/123456789/16648},
	number = {1},
	urldate = {2016-07-28TZ},
	journal = {Journal for Language Technology and Computational Linguistics},
	author = {Zinsmeister, Heike},
	year = {2011},
	note = {00000},
	pages = {67--79}
}

@article{oder_xmax_struktur_nodate,
	title = {Struktur von {Phrasen}},
	url = {http://home.uni-leipzig.de/muellerg/mu604.pdf},
	urldate = {2016-07-27TZ},
	author = {oder Xmax, X. P.},
	note = {00000}
}

@article{erpenbeck_kompetenz_2002,
	title = {Kompetenz und {Performanz} im {Bild} moderner {Selbstorganisationstheorie}},
	volume = {21},
	url = {http://www.forschungsnetzwerk.at/downloadpub/erpenbeck_03_4_2002.pdf},
	urldate = {2016-07-27TZ},
	journal = {Bundesinstitut für Berufsbildung (Hg.): Berufsbildung für eine globale Gesellschaft. Perspektiven im},
	author = {Erpenbeck, John},
	year = {2002},
	note = {00010},
	pages = {1--12}
}

@article{sheehan_formal_2010,
	title = {Formal and functional approaches to disharmonic word orders},
	url = {http://www.ncl.ac.uk/linguistics/assets/documents/SHEEHAN.pdf},
	urldate = {2016-07-22TZ},
	journal = {Newcastle Working Papers in Linguistics},
	author = {Sheehan, Michelle},
	year = {2010},
	note = {00003},
	pages = {146}
}

@inproceedings{houy_argumentumtowards_2012,
	title = {{ARGUMENTUM}–{Towards} computer-supported analysis, retrieval and synthesis of argumentation structures in humanities using the example of jurisprudence},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.401.5714&rep=rep1&type=pdf},
	urldate = {2016-07-14TZ},
	booktitle = {Poster and {Demo} {Track} of the 35th {German} {Conference} on {Artificial} {Intelligence} ({KI} 2012), {Saarbrücken}, {Germany}},
	publisher = {Citeseer},
	author = {Houy, Constantin and Fettke, Peter and Loos, Peter and Speiser, Iris and Herberger, Maximilian and Gass, Alfred and Nortmann, Ulrich},
	year = {2012},
	note = {00004}
}

@article{houy_konzeption_2015,
	title = {Konzeption und {Implementierung} eines {Werkzeuges} zur automatisierten {Identifikation} und {Analyse} von {Argumentationsstrukturen} anhand der {Entscheidungen} des {Bundesverfassungsgerichts} im {Digital}-{Humanities}-{Projekt} {ARGUMENTUM}},
	volume = {15},
	issn = {1618-2162, 1610-1995},
	url = {http://link.springer.com/10.1007/s13222-014-0175-9},
	doi = {10.1007/s13222-014-0175-9},
	language = {de},
	number = {1},
	urldate = {2016-07-14TZ},
	journal = {Datenbank-Spektrum},
	author = {Houy, Constantin and Niesen, Tim and Calvillo, Jesús and Fettke, Peter and Loos, Peter and Krämer, Annika and Schmidt, Klaas and Herberger, Maximilian and Speiser, Iris and Gass, Alfred and Schneider, Luc and Philippi, Tim},
	month = mar,
	year = {2015},
	note = {00003},
	pages = {15--23}
}

@article{copestake_minimal_2005,
	title = {Minimal {Recursion} {Semantics}: {An} {Introduction}},
	volume = {3},
	issn = {1570-7075, 1572-8706},
	shorttitle = {Minimal {Recursion} {Semantics}},
	url = {http://link.springer.com/10.1007/s11168-006-6327-9},
	doi = {10.1007/s11168-006-6327-9},
	language = {en},
	number = {2-3},
	urldate = {2016-06-29TZ},
	journal = {Research on Language and Computation},
	author = {Copestake, Ann and Flickinger, Dan and Pollard, Carl and Sag, Ivan A.},
	month = jul,
	year = {2005},
	pages = {281--332}
}

@inproceedings{burchardt_fate:_2008,
	title = {{FATE}: a {FrameNet}-{Annotated} {Corpus} for {Textual} {Entailment}.},
	shorttitle = {{FATE}},
	url = {http://www.cs.brandeis.edu/~marc/misc/proceedings/lrec-2008/pdf/143_paper.pdf},
	urldate = {2014-03-26TZ},
	booktitle = {{LREC}},
	author = {Burchardt, Aljoscha and Pennacchiotti, Marco},
	year = {2008},
	note = {00000}
}

@inproceedings{etzioni_web-scale_2004,
	address = {New York, NY, USA},
	series = {{WWW} '04},
	title = {Web-scale information extraction in knowitall: (preliminary results)},
	isbn = {1-58113-844-X},
	shorttitle = {Web-scale information extraction in knowitall},
	url = {http://doi.acm.org/10.1145/988672.988687},
	doi = {10.1145/988672.988687},
	abstract = {Manually querying search engines in order to accumulate a large bodyof factual information is a tedious, error-prone process of piecemealsearch. Search engines retrieve and rank potentially relevantdocuments for human perusal, but do not extract facts, assessconfidence, or fuse information from multiple documents. This paperintroduces KnowItAll, a system that aims to automate the tedious process ofextracting large collections of facts from the web in an autonomous,domain-independent, and scalable manner.The paper describes preliminary experiments in which an instance of KnowItAll, running for four days on a single machine, was able to automatically extract 54,753 facts. KnowItAll associates a probability with each fact enabling it to trade off precision and recall. The paper analyzes KnowItAll's architecture and reports on lessons learned for the design of large-scale information extraction systems.},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 13th international conference on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Etzioni, Oren and Cafarella, Michael and Downey, Doug and Kok, Stanley and Popescu, Ana-Maria and Shaked, Tal and Soderland, Stephen and Weld, Daniel S. and Yates, Alexander},
	year = {2004},
	note = {00000},
	keywords = {information extraction, mutual information, pmi, search},
	pages = {100--110}
}

@article{dmello_multimodal_2010,
	title = {Multimodal semi-automated affect detection from conversational cues, gross body language, and facial features},
	volume = {20},
	url = {http://link.springer.com/article/10.1007/s11257-010-9074-4},
	number = {2},
	urldate = {2014-06-17TZ},
	journal = {User Modeling and User-Adapted Interaction},
	author = {D’Mello, Sidney K. and Graesser, Arthur},
	year = {2010},
	note = {00000},
	pages = {147--187}
}

@inproceedings{paquette_sensor-free_2014,
	title = {Sensor-{Free} {Affect} {Detection} for a {Simulation}-{Based} {Science} {Inquiry} {Learning} {Environment}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_1},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer},
	author = {Paquette, Luc and Baker, Ryan SJD and Sao Pedro, Michael A. and Gobert, Janice D. and Rossi, Lisa and Nakama, Adam and Kauffman-Rogoff, Zakkai},
	year = {2014},
	note = {00000},
	pages = {1--10}
}

@inproceedings{tiedemann_building_2009,
	title = {Building a large machine-aligned parallel treebank},
	url = {http://ufal.ms.mff.cuni.cz/pedt2.0/publications/Proceedings_TLT8.pdf#page=209},
	urldate = {2013-11-05TZ},
	booktitle = {Eighth {International} {Workshop} on {Treebanks} and {Linguistic} {Theories}},
	author = {Tiedemann, Jörg and Kotzé, Gideon},
	year = {2009},
	note = {00000},
	pages = {197}
}

@inproceedings{schmitz_open_2012,
	title = {Open language learning for information extraction},
	url = {http://dl.acm.org/citation.cfm?id=2391009},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 2012 {Joint} {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and {Computational} {Natural} {Language} {Learning}},
	author = {Schmitz, Michael and Bart, Robert and Soderland, Stephen and Mausam and Etzioni, Oren},
	year = {2012},
	note = {00000},
	pages = {523--534}
}

@inproceedings{burchardt_salsa_2006,
	title = {The {SALSA} corpus: a {German} corpus resource for lexical semantics},
	shorttitle = {The {SALSA} corpus},
	url = {http://www.cl.uni-heidelberg.de/~frank/papers/lrec06_burchardt_salsa.pdf},
	urldate = {2014-03-25TZ},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}-2006)},
	author = {Burchardt, Aljoscha and Erk, Katrin and Frank, Anette and Kowalski, Andrea and Padó, Sebastian and Pinkal, Manfred},
	year = {2006},
	note = {00000}
}

@article{nwana_intelligent_1990,
	title = {Intelligent tutoring systems: an overview},
	volume = {4},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Intelligent tutoring systems},
	url = {http://link.springer.com/article/10.1007/BF00168958},
	doi = {10.1007/BF00168958},
	abstract = {This is a non-expert overview of Intelligent Tutoring Systems (ITSs), a way in which Artificial Intelligence (AI) techniques are being applied to education. It introduces ITSs and the motivation for them. It looks at its history: its evolution from Computer-Assisted Instruction (CAI). After looking at the structure of a ‘typical’ ITS, the paper further examines and discusses some other architectures. Several classic ITSs are reviewed, mainly due to their historical significance or because they best demonstrate some of the principles of intelligent tutoring. A reasonably representative list of ITSs is also provided in order to provide a better appreciation of this vibrant field as well as reveal the scope of existing tutors. The paper concludes, perhaps more appropriately, with some of the author's viewpoints on a couple of controversial issues in the intelligent tutoring domain.},
	language = {en},
	number = {4},
	urldate = {2014-09-28TZ},
	journal = {Artificial Intelligence Review},
	author = {Nwana, Hyacinth S.},
	month = dec,
	year = {1990},
	note = {00000},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Science, general, Nonlinear Dynamics, Complex Systems, Chaos, Neural Networks},
	pages = {251--277}
}

@inproceedings{mcquiggan_diagnosing_2006,
	title = {Diagnosing self-efficacy in intelligent tutoring systems: {An} empirical study},
	shorttitle = {Diagnosing self-efficacy in intelligent tutoring systems},
	url = {http://link.springer.com/chapter/10.1007/11774303_56},
	urldate = {2014-06-17TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer},
	author = {McQuiggan, Scott W. and Lester, James C.},
	year = {2006},
	note = {00000},
	pages = {565--574}
}

@inproceedings{wang_empathic_2006,
	title = {Empathic tutoring software agents using real-time eye tracking},
	url = {http://dl.acm.org/citation.cfm?id=1117346},
	urldate = {2014-09-29TZ},
	booktitle = {Proceedings of the 2006 symposium on {Eye} tracking research \& applications},
	publisher = {ACM},
	author = {Wang, Hua and Chignell, Mark and Ishizuka, Mitsuru},
	year = {2006},
	note = {00000},
	pages = {73--78}
}

@article{gangemi_frame-based_2014,
	title = {Frame-{Based} {Detection} of {Opinion} {Holders} and {Topics}: {A} {Model} and a {Tool}},
	volume = {9},
	issn = {1556-603X},
	shorttitle = {Frame-{Based} {Detection} of {Opinion} {Holders} and {Topics}},
	doi = {10.1109/MCI.2013.2291688},
	abstract = {Sentilo is a model and a tool to detect holders and topics of opinion sentences. Sentilo implements an approach based on the neo-Davidsonian assumption that events and situations are the primary entities for contextualizing opinions, which makes it able to distinguish holders, main topics, and sub-topics of an opinion. It uses a heuristic graph mining approach that relies on FRED, a machine reader for the Semantic Web that leverages Natural Language Processing (NLP) and Knowledge Representation (KR) components jointly with cognitively-inspired frames. The evaluation results are excellent for holder detection (F1: 95\%), very good for subtopic detection (F1: 78\%), and good for topic detection (F1: 68\%).},
	number = {1},
	journal = {IEEE Computational Intelligence Magazine},
	author = {Gangemi, A. and Presutti, V. and Reforgiato Recupero, D.},
	month = feb,
	year = {2014},
	note = {00000},
	keywords = {Computational modeling, FRED, Feature extraction, KR components, NLP, OWL, Semantics, Sentilo, Syntactics, cognition, cognitively-inspired frames, data mining, frame-based detection, graph theory, heuristic graph mining approach, knowledge representation, knowledge representation components, machine reader, natural language processing, neo-Davidsonian assumption, opinion holders, opinion sentences, semantic Web, sentiment analysis, subtopic detection, topic detection},
	pages = {20--30}
}

@book{carver_cognition_2013,
	title = {Cognition and {Instruction}: {Twenty}-five {Years} of {Progress}},
	isbn = {978-1-135-64899-2},
	shorttitle = {Cognition and {Instruction}},
	abstract = {This volume is based on papers presented at the 30th Carnegie Mellon Symposium on Cognition. This particular symposium was conceived in reference to the 1974 symposium entitled Cognition and Instruction. In the 25 years since that symposium, reciprocal relationships have been forged between psychology and education, research and practice, and laboratory and classroom learning contexts. Synergistic advances in theories, empirical findings, and instructional practice have been facilitated by the establishment of new interdisciplinary journals, teacher education courses, funding initiatives, and research institutes. So, with all of this activity, where is the field of cognition and instruction? How much progress has been made in 25 years? What remains to be done? This volume proposes and illustrates some exciting and challenging answers to these questions.   Chapters in this volume describe advances and challenges in four areas, including development and instruction, teachers and instructional strategies, tools for learning from instruction, and social contexts of instruction and learning. Detailed analyses of tasks, subjects' knowledge and processes, and the changes in performance over time have led to new understanding of learners' representations, their use of multiple strategies, and the important role of metacognitive processes. New methods for assessing and tracking the development and elaboration of knowledge structures and processing strategies have yielded new conceptualizations of the process of change. Detailed cognitive analysis of expert teachers, as well as a direct focus on enhancing teachers' cognitive models of learners and use of effective instructional strategies, are other areas that have seen tremendous growth and refinement in the past 25 years. Similarly, the strong impact of curriculum materials and activities based on a thorough cognitive analysis of the task has been extended to the use of technological tools for learning, such as intelligent tutors and complex computer based instructional interfaces. Both the shift to conducting a significant portion of the cognition and instruction research in real classrooms and the increased collaboration between academics and educators have brought the role of the social context to center stage.},
	language = {en},
	publisher = {Psychology Press},
	author = {Carver, Sharon M. and Klahr, David},
	month = jun,
	year = {2013},
	note = {00000},
	keywords = {EDUCATION / Educational Psychology, Psychology / Cognitive Psychology \& Cognition, Psychology / Developmental / Child}
}

@article{graesser_using_2007,
	title = {Using {LSA} in {AutoTutor}: {Learning} through mixed initiative dialogue in natural language},
	shorttitle = {Using {LSA} in {AutoTutor}},
	url = {http://books.google.com/books?hl=de&lr=&id=JbzCzPvzpmQC&oi=fnd&pg=PA243&dq=graesser+Using+LSA+in+AutoTutor:+Learning+through+mixed+-+initiative+dia+logue+in+natural+language&ots=aMG0I_QZLL&sig=3N7siCNQwgyi09JZT41Nz8C9llU},
	urldate = {2014-10-01TZ},
	journal = {Handbook of latent semantic analysis},
	author = {Graesser, A. C. and Penumatsa, Phanni and Ventura, Matthew and Cai, Zhiqiang and Hu, Xiangen},
	year = {2007},
	note = {00000},
	pages = {243--262}
}

@inproceedings{kim_overview_2011,
	title = {Overview of {BioNLP} shared task 2011},
	url = {http://dl.acm.org/citation.cfm?id=2107692},
	urldate = {2013-08-27TZ},
	booktitle = {Proceedings of the {BioNLP} {Shared} {Task} 2011 {Workshop}},
	author = {Kim, Jin-Dong and Pyysalo, Sampo and Ohta, Tomoko and Bossy, Robert and Nguyen, Ngan and Tsujii, Jun'ichi},
	year = {2011},
	note = {00000},
	pages = {1--6}
}

@book{lazarus_emotion_1991,
	address = {New York,  NY,  US},
	title = {Emotion and adaptation},
	volume = {xiii},
	copyright = {(c) 2012 APA, all rights reserved},
	isbn = {0-19-506994-3 (Hardcover)},
	abstract = {The work provides a complete theory of emotional processes, explaining how different emotions are elicited and expressed, and how the emotional range of individuals develops over their lifetime. The author's approach puts emotion in a central role as a complex, patterned, organic reaction to both daily events and long-term efforts on the part of the individual to survive and flourish. . . . After defining emotion and discussing issues of classification and measurement, Lazarus turns to the topics of motivation, cognition, and causality as key concepts in this theory. Next, he looks at individual emotions, both negative and positive, and examines how they are generated. Then he reviews individual emotional development and the social influences that shape it. Finally, he considers the long-term consequences of emotion on physical health and well-being, and the treatment and prevention of emotional dysfunction. As a comprehensive treatment of the emotions, the book will interest students, clinicians, and researchers involved in personality, social and clinical psychology, as well as cognitive and developmental psychology. It may also be used as a supplemental textbook in courses on the psychology of adjustment, emotion, and motivation.},
	publisher = {Oxford University Press},
	author = {Lazarus, Richard S.},
	year = {1991},
	note = {00000},
	keywords = {*Adaptability (Personality), *Emotional Development, *Emotions, Emotionality (Personality)}
}

@inproceedings{johansson_lth:_2007,
	title = {{LTH}: semantic structure extraction using nonprojective dependency trees},
	shorttitle = {{LTH}},
	url = {http://dl.acm.org/citation.cfm?id=1621522},
	urldate = {2014-03-31TZ},
	booktitle = {Proceedings of the 4th {International} {Workshop} on {Semantic} {Evaluations}},
	publisher = {Association for Computational Linguistics},
	author = {Johansson, Richard and Nugues, Pierre},
	year = {2007},
	note = {00000},
	pages = {227--230}
}

@misc{noauthor_named-entity_2013,
	title = {Named-entity recognition},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://en.wikipedia.org/w/index.php?title=Named-entity_recognition&oldid=565171592},
	abstract = {Named-entity recognition (NER) (also known as entity identification and entity extraction) is a subtask of information extraction that seeks to locate and classify atomic elements in text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.},
	language = {en},
	urldate = {2013-07-29TZ},
	journal = {Wikipedia, the free encyclopedia},
	month = jul,
	year = {2013},
	note = {00000 
Page Version ID: 565171592}
}

@article{krause_anwendung_1992,
	title = {Anwendung der {Affektforschung} auf die psychoanalytisch-psychotherapeutische {Praxis}},
	volume = {8},
	issn = {0178-7667},
	url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=5572209},
	language = {ger},
	number = {3},
	urldate = {2014-09-29TZ},
	journal = {Forum der Psychoanalyse},
	author = {Krause, R. and Steimer-Krause, E. and Ullrich, B.},
	year = {1992},
	note = {00000},
	keywords = {Afecto afectividad, Affect affectivity, Affect affectivité, Diagnosis, Diagnostic, Diagnóstico, Hombre, Homme, Human, Investigación científica, Personalidad, Personality, Personnalité, Proceso terapéutico, Processus thérapeutique, Psicoanálisis, Psychanalyse, Psychoanalysis, Recherche scientifique, Scientific research, Therapeutic process},
	pages = {238--253}
}

@book{ruppenhofer_framenet_2006,
	title = {{FrameNet} {II}: {Extended} theory and practice},
	shorttitle = {{FrameNet} {II}},
	url = {http://framenet2.icsi.berkeley.edu/docs/r1.5/book.pdf},
	urldate = {2014-03-26TZ},
	author = {Ruppenhofer, Josef and Ellsworth, Michael and Petruck, Miriam RL and Johnson, Christopher R. and Scheffczyk, Jan},
	year = {2006},
	note = {00000}
}

@inproceedings{surdeanu_multi-instance_2012,
	title = {Multi-instance multi-label learning for relation extraction},
	url = {http://dl.acm.org/citation.cfm?id=2391003},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 2012 {Joint} {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and {Computational} {Natural} {Language} {Learning}},
	author = {Surdeanu, Mihai and Tibshirani, Julie and Nallapati, Ramesh and Manning, Christopher D.},
	year = {2012},
	note = {00000},
	pages = {455--465}
}

@inproceedings{sidney_integrating_2005,
	title = {Integrating affect sensors in an intelligent tutoring system},
	url = {http://141.225.218.248/web-homeroot/graesser/publications/AddPapers/iui-ai-05.pdf},
	urldate = {2014-06-17TZ},
	booktitle = {Affective {Interactions}: {The} {Computer} in the {Affective} {Loop} {Workshop} at},
	author = {Sidney, K. Dmello and Craig, Scotty D. and Gholson, Barry and Franklin, Stan and Picard, Rosalind and Graesser, Arthur C.},
	year = {2005},
	note = {00000},
	pages = {7--13}
}

@incollection{mills_quit_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {To {Quit} or {Not} to {Quit}: {Predicting} {Future} {Behavioral} {Disengagement} from {Reading} {Patterns}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3 978-3-319-07221-0},
	shorttitle = {To {Quit} or {Not} to {Quit}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_3},
	abstract = {This research predicted behavioral disengagement using quitting behaviors while learning from instructional texts. Supervised machine learning algorithms were used to predict if students would quit an upcoming text by analyzing reading behaviors observed in previous texts. Behavioral disengagement (quitting) at any point during the text was predicted with an accuracy of 76.5\% (48\% above chance), before students even began engaging with the text. We also predicted if a student would quit reading on the first page of a text or continue reading past the first page with an accuracy of 88.5\% (29\% above chance), as well as if students would quit sometime after the first page with an accuracy of 81.4\% (51\% greater than chance). Both actual quits and predicted quits were significantly related to learning, which provides some evidence for the predictive validity of our model. Implications and future work related to ITSs are also discussed.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Mills, Caitlin and Bosch, Nigel and Graesser, Art and D’Mello, Sidney},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	note = {00000},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, ITSs, Multimedia Information Systems, User Interfaces and Human Computer Interaction, affect detection, disengagement, engagement, reading},
	pages = {19--28}
}

@techreport{noauthor_importance_nodate,
	title = {{THE} {IMPORTANCE} {OF} {SYNTACTIC} {PARSING} {AND} {INFERENCE} {IN} {SEMANTIC} {ROLE} {LABEL}},
	url = {http://www.coli.uni-saarland.de/courses/comsem-11/material/peter_stahl-punyakanok.pdf},
	note = {00000}
}

@incollection{mcquiggan_early_2007,
	title = {Early prediction of student frustration},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-74889-2_61},
	urldate = {2014-06-17TZ},
	booktitle = {Affective {Computing} and {Intelligent} {Interaction}},
	publisher = {Springer},
	author = {Mcquiggan, Scott W. and Lee, Sunyoung and Lester, James C.},
	year = {2007},
	note = {00000},
	pages = {698--709}
}

@article{afzal_evaluating_2007,
	title = {Evaluating learner experience from affective cues},
	url = {http://www.di.uniba.it/intint/DC-ACII07/Afzal.pdf},
	abstract = {Learning with computers is typically self-paced. Appraisal of the learner’s experience is therefore crucial for making machine-learner interactions ‘truly intelligent’ and ins
tinctive. As a significant aspect of Affective Learning, affect recognition need
s to be considered in light of its implications and appliance to computer
based learning environments. Drawing on this motivation, I propose to investigate the potential of using facial expression analysis to model affect in learning as a means for evaluating learner state.},
	urldate = {2014-09-30TZ},
	journal = {Affective Computing},
	author = {Afzal, Shazia},
	year = {2007},
	note = {00000}
}

@article{daniel_information_1995,
	title = {Information function of empathic emotion: {Learning} that we value the other's welfare},
	volume = {68},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1315(Electronic);0022-3514(Print)},
	shorttitle = {Information function of empathic emotion},
	doi = {10.1037/0022-3514.68.2.300},
	abstract = {Empathic feelings arise when a person values another's welfare and perceives the other to be in need. As a result, level of empathic response can be used to infer how much one values the welfare of a person in need. Four experiments were conducted to test these ideas. Experiments 1 and 2 revealed that a similarity manipulation led to increased valuing of a similar person's welfare and, in turn, to increased empathy when this person was in need. Experiments 3 and 4 revealed that direct manipulations of empathy (perspective-taking instructions, or false physiological arousal feedback) led to increased empathy and, in turn, to increased valuing of the welfare of the person in need. Once induced, this valuing was a relatively stable disposition; it remained even after empathy had declined.},
	number = {2},
	journal = {Journal of Personality and Social Psychology},
	author = {Daniel, C. and Turk, Cynthia L. and Shaw, Laura L. and Klein, Tricia R.},
	year = {1995},
	note = {00000},
	keywords = {*Biofeedback, *Empathy, *Experimental Instructions, *Feedback, Social Comparison},
	pages = {300--313}
}

@article{surdeanu_combination_2007,
	title = {Combination {Strategies} for {Semantic} {Role} {Labeling}.},
	volume = {29},
	url = {http://www.aaai.org/Papers/JAIR/Vol29/JAIR-2905.pdf},
	urldate = {2013-07-31TZ},
	journal = {J. Artif. Intell. Res.(JAIR)},
	author = {Surdeanu, Mihai and Màrquez, Lluís and Carreras, Xavier and Comas, Pere},
	year = {2007},
	note = {00000},
	pages = {105--151}
}

@article{craig_emote_2008,
	title = {Emote aloud during learning with {AutoTutor}: {Applying} the {Facial} {Action} {Coding} {System} to cognitive–affective states during learning},
	volume = {22},
	issn = {0269-9931, 1464-0600},
	shorttitle = {Emote aloud during learning with {AutoTutor}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/02699930701516759},
	doi = {10.1080/02699930701516759},
	language = {en},
	number = {5},
	urldate = {2014-06-17TZ},
	journal = {Cognition \& Emotion},
	author = {Craig, Scotty D. and D'Mello, Sidney and Witherspoon, Amy and Graesser, Art},
	month = aug,
	year = {2008},
	note = {00000},
	pages = {777--788}
}

@inproceedings{christensen_towards_2013,
	title = {Towards {Coherent} {Multi}-{Document} {Summarization}},
	url = {http://www.aclweb.org/anthology/N/N13/N13-1136.pdf},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of {NAACL}-{HLT}},
	author = {Christensen, Janara and Mausam, Stephen Soderland and Etzioni, Oren},
	year = {2013},
	note = {00000},
	pages = {1163--1173}
}

@article{ma_intelligent_2014,
	title = {Intelligent {Tutoring} {Systems} and {Learning} {Outcomes}: {A} {Meta}-{Analysis}},
	copyright = {(c) 2014 APA, all rights reserved},
	issn = {1939-2176(Electronic);0022-0663(Print)},
	shorttitle = {Intelligent {Tutoring} {Systems} and {Learning} {Outcomes}},
	doi = {10.1037/a0037123},
	abstract = {Intelligent Tutoring Systems (ITS) are computer programs that model learners’ psychological states to provide individualized instruction. They have been developed for diverse subject areas (e.g., algebra, medicine, law, reading) to help learners acquire domain-specific, cognitive and metacognitive knowledge. A meta-analysis was conducted on research that compared the outcomes from students learning from ITS to those learning from non-ITS learning environments. The meta-analysis examined how effect sizes varied with type of ITS, type of comparison treatment received by learners, type of learning outcome, whether knowledge to be learned was procedural or declarative, and other factors. After a search of major bibliographic databases, 107 effect sizes involving 14,321 participants were extracted and analyzed. The use of ITS was associated with greater achievement in comparison with teacher-led, large-group instruction (g = .42), non-ITS computer-based instruction (g = .57), and textbooks or workbooks (g = .35). There was no significant difference between learning from ITS and learning from individualized human tutoring (g = –.11) or small-group instruction (g = .05). Significant, positive mean effect sizes were found regardless of whether the ITS was used as the principal means of instruction, a supplement to teacher-led instruction, an integral component of teacher-led instruction, or an aid to homework. Significant, positive effect sizes were found at all levels of education, in almost all subject domains evaluated, and whether or not the ITS provided feedback or modeled student misconceptions. The claim that ITS are relatively effective tools for learning is consistent with our analysis of potential publication bias.},
	journal = {Journal of Educational Psychology},
	author = {Ma, Wenting and Adesope, Olusola O. and Nesbit, John C. and Liu, Qing},
	year = {2014},
	note = {00000},
	pages = {No Pagination Specified}
}

@incollection{lee_towards_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards {Automatically} {Detecting} {Whether} {Student} {Is} in {Flow}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3 978-3-319-07221-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_2},
	abstract = {Csikszentmihalyi’s flow theory states the components (e.g., balance between skill and challenge) that lead to an optimal state (referred to as flow state, or under flow experience) of intrinsic motivation and personal experience. Recent research has begun to validate the claims stated by the theory and extend the provided statements to the design of pedagogical interactions. To incorporate the theory in a design, automatic detector of flow is required. However, little attention has been drawn to this filed, and the detection of flow is currently still dominated by using surveys. Hence, within this paper, we present an automated detector which is able to identify the students that are in flow. This detector is developed using a step regression approach, with data collected from college students learning linear algebra from a step-based tutoring system.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Lee, Po-Ming and Jheng, Sin-Yu and Hsiao, Tzu-Chien},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	note = {00000},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, Educational Data Mining, Flow Theory, Intelligent Tutoring System, Multimedia Information Systems, Student Modeling, User Interfaces and Human Computer Interaction},
	pages = {11--18}
}

@article{devedzic_education_2004,
	title = {Education and the {Semantic} {W} eb},
	volume = {14},
	url = {http://www.info2.uqam.ca/~nkambou/DIC9340/seances/seance2-3-4-5/Ontology/IJAIED2004.pdf},
	urldate = {2014-09-29TZ},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Devedzic, Vladan},
	year = {2004},
	note = {00000},
	pages = {39--65}
}

@article{corbett_intelligent_1997,
	title = {Intelligent tutoring systems},
	url = {http://act-r.psy.cmu.edu/wordpress/wp-content/uploads/2012/12/173Chapter_37_Intelligent_Tutoring_Systems.pdf},
	urldate = {2014-09-28TZ},
	journal = {Handbook of humancomputer interaction},
	author = {Corbett, Albert T. and Koedinger, Kenneth R. and Anderson, John R.},
	year = {1997},
	note = {00000},
	pages = {849--874}
}

@article{graesser_intelligent_2001,
	title = {Intelligent tutoring systems with conversational dialogue},
	volume = {22},
	url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/1591},
	number = {4},
	urldate = {2014-09-28TZ},
	journal = {AI magazine},
	author = {Graesser, Arthur C. and VanLehn, Kurt and Rosé, Carolyn P. and Jordan, Pamela W. and Harter, Derek},
	year = {2001},
	note = {00000},
	pages = {39}
}

@inproceedings{jaques_predicting_2014,
	title = {Predicting {Affect} from {Gaze} {Data} during {Interaction} with an {Intelligent} {Tutoring} {System}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_4},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer},
	author = {Jaques, Natasha and Conati, Cristina and Harley, Jason M. and Azevedo, Roger},
	year = {2014},
	note = {00000},
	pages = {29--38}
}

@incollection{blanchard_automated_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Automated {Physiological}-{Based} {Detection} of {Mind} {Wandering} during {Learning}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3 978-3-319-07221-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_7},
	abstract = {Unintentional lapses of attention, or mind wandering, are ubiquitous and detrimental during learning. Hence, automated methods that detect and combat mind wandering might be beneficial to learning. As an initial step in this direction, we propose to detect mind wandering by monitoring physiological measures of skin conductance and skin temperature. We conducted a study in which student’s physiology signals were measured while they learned topics in research methods from instructional texts. Momentary self-reports of mind wandering were collected with standard probe-based methods. We computed features from the physiological signals in windows leading up to the probes and trained supervised classification models to detect mind wandering. We obtained a kappa, a measurement of accuracy corrected for random guessing, of .22, signaling feasibility of detecting MW in a student-independent manner. Though modest, we consider this result to be an important step towards fully-automated unobtrusive detection of mind wandering during learning.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Blanchard, Nathaniel and Bixler, Robert and Joyce, Tera and D’Mello, Sidney},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	note = {00000},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, Multimedia Information Systems, User Interfaces and Human Computer Interaction, machine learning, mind wandering, skin conductance, skin temperature},
	pages = {55--60}
}

@phdthesis{das_semi-supervised_2012,
	title = {Semi-{Supervised} and {Latent}-{Variable} {Models} of {Natural} {Language} {Semantics}},
	url = {http://www.lti.cs.cmu.edu/research/thesis/2012/cmulti12007.pdf},
	urldate = {2014-03-31TZ},
	school = {University of Illinois},
	author = {Das, Dipanjan},
	year = {2012},
	note = {00007}
}

@inproceedings{surdeanu_ensemble_2010,
	title = {Ensemble models for dependency parsing: cheap and good?},
	shorttitle = {Ensemble models for dependency parsing},
	url = {http://dl.acm.org/citation.cfm?id=1858090},
	urldate = {2013-07-26TZ},
	booktitle = {Human {Language} {Technologies}: {The} 2010 {Annual} {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}},
	author = {Surdeanu, Mihai and Manning, Christopher D.},
	year = {2010},
	note = {00058},
	pages = {649--652}
}

@article{frijda_laws_1988,
	title = {The laws of emotion.},
	volume = {43},
	url = {http://psycnet.apa.org/journals/amp/43/5/349/},
	number = {5},
	urldate = {2014-09-29TZ},
	journal = {American psychologist},
	author = {Frijda, Nico H.},
	year = {1988},
	note = {00733},
	pages = {349}
}

@inproceedings{das_semafor_2010,
	title = {{SEMAFOR} 1.0: {Probabilistic} frame-semantic parsing},
	url = {http://dl.acm.org/citation.cfm?id=1858136},
	urldate = {2014-03-31TZ},
	booktitle = {Human language technologies: {The} 2010 annual conference of the {North} {American} chapter of the association for computational linguistics},
	publisher = {Association for Computational Linguistics},
	author = {Das, Dipanjan and Schneider, Nathan and Chen, Desai and Smith, Noah A.},
	year = {2010},
	note = {00000},
	pages = {948--956}
}

@article{immordino-yang_we_2007,
	title = {We feel, therefore we learn: {The} relevance of affective and social neuroscience to education},
	volume = {1},
	shorttitle = {We feel, therefore we learn},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1751-228X.2007.00004.x/full},
	number = {1},
	urldate = {2014-09-30TZ},
	journal = {Mind, brain, and education},
	author = {Immordino-Yang, Mary Helen and Damasio, Antonio},
	year = {2007},
	note = {00570},
	pages = {3--10}
}

@inproceedings{fader_identifying_2011,
	address = {Stroudsburg, PA, USA},
	series = {{EMNLP} '11},
	title = {Identifying relations for open information extraction},
	isbn = {978-1-937284-11-4},
	url = {http://dl.acm.org/citation.cfm?id=2145432.2145596},
	abstract = {Open Information Extraction (IE) is the task of extracting assertions from massive corpora without requiring a pre-specified vocabulary. This paper shows that the output of state-of-the-art Open IE systems is rife with uninformative and incoherent extractions. To overcome these problems, we introduce two simple syntactic and lexical constraints on binary relations expressed by verbs. We implemented the constraints in the ReVerb Open IE system, which more than doubles the area under the precision-recall curve relative to previous extractors such as TextRunner and woepos. More than 30\% of ReVerb's extractions are at precision 0.8 or higher---compared to virtually none for earlier systems. The paper concludes with a detailed analysis of ReVerb's errors, suggesting directions for future work.},
	urldate = {2013-07-29TZ},
	booktitle = {Proceedings of the {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Fader, Anthony and Soderland, Stephen and Etzioni, Oren},
	year = {2011},
	note = {00513},
	pages = {1535--1545}
}

@article{anderson_what_2001,
	title = {What role do cognitive architectures play in intelligent tutoring systems},
	url = {http://books.google.de/books?hl=de&lr=&id=wYm1vg4LU-wC&oi=fnd&pg=PA227&dq=Intelligent+tutoring+system+cognitive+states+-affect&ots=0nvlaWVHME&sig=gg0db-55KXMJ3tWayuHbmjZLPos},
	urldate = {2014-09-29TZ},
	journal = {Cognition \& Instruction: Twenty-five years of progress},
	author = {Anderson, John R. and Gluck, Kevin},
	year = {2001},
	note = {00100},
	pages = {227--262}
}

@article{brosch_3_2008,
	title = {3 {Plädoyer} für das {Komponenten}-{Prozess}-{Modell} als theoretische {Grundlage} der experimentellen {Emotionsforschung}},
	url = {http://www.affective-sciences.ch/system/files/biblio/Brosch%26Scherer_2008_KPM.pdf},
	urldate = {2014-09-10TZ},
	author = {Brosch, Tobias and Scherer, Klaus R.},
	year = {2008},
	note = {00004}
}

@incollection{vanlehn_architecture_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Architecture} of {Why}2-{Atlas}: {A} {Coach} for {Qualitative} {Physics} {Essay} {Writing}},
	copyright = {©2002 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-43750-5 978-3-540-47987-1},
	shorttitle = {The {Architecture} of {Why}2-{Atlas}},
	url = {http://link.springer.com/chapter/10.1007/3-540-47987-2_20},
	abstract = {The Why2-Atlas system teaches qualitative physics by having students write paragraph-long explanations of simple mechanical phenomena. The tutor uses deep syntactic analysis and abductive theorem proving to convert the student’s essay to a proof. The proof formalizes not only what was said, but the likely beliefs behind what was said. This allows the tutor to uncover misconceptions as well as to detect missing correct parts of the explanation. If the tutor finds such a flaw in the essay, it conducts a dialogue intended to remedy the missing or misconceived beliefs, then asks the student to correct the essay. It often takes several iterations of essay correction and dialogue to get the student to produce an acceptable explanation. Pilot subjects have been run, and an evaluation is in progress. After explaining the research questions that the system addresses, the bulk of the paper describes the system’s architecture and operation.},
	language = {en},
	number = {2363},
	urldate = {2014-09-28TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {VanLehn, Kurt and Jordan, Pamela W. and Rosé, Carolyn P. and Bhembe, Dumisizwe and Böttner, Michael and Gaydos, Andy and Makatchev, Maxim and Pappuswamy, Umarani and Ringenberg, Michael and Roque, Antonio and Siler, Stephanie and Srivastava, Ramesh},
	editor = {Cerri, Stefano A. and Gouardères, Guy and Paraguaçu, Fàbio},
	month = jan,
	year = {2002},
	note = {00221},
	keywords = {Artificial Intelligence (incl. Robotics), Computers and Education, Information Systems Applications (incl.Internet), Multimedia Information Systems, User Interfaces and Human Computer Interaction},
	pages = {158--167}
}

@article{kast_wie_2007,
	title = {Wie der {Bauch} dem {Kopf} beim {Denken} hilft},
	url = {http://www.denkladen.de/docs/703980Rezm.pdf},
	urldate = {2014-09-30TZ},
	journal = {Die Kraft der Intuition. Frankfurt a./M},
	author = {Kast, Bas},
	year = {2007},
	note = {00062}
}

@incollection{fillmore_case_1968,
	address = {London},
	title = {The {Case} for {Case}},
	url = {http://pdf.thepdfportal.com/PDFFiles/123480.pdf},
	urldate = {2014-03-31TZ},
	booktitle = {Universals in linguistic theory},
	publisher = {Holt, Rinehart and Winston},
	author = {Fillmore, Charles J.},
	year = {1968},
	note = {08717},
	pages = {1--88}
}

@book{lawler_using_1998,
	title = {Using {Computers} in {Linguistics}: {A} {Practical} {Guide}},
	isbn = {978-0-415-16792-5},
	shorttitle = {Using {Computers} in {Linguistics}},
	abstract = {Computing has had a dramatic impact on the discipline of linguistics and is shaping the way we conceptualize both linguistics and language. Using Computers in Linguistics provides a non-technical introduction to recent developments in linguistic computing and offers specific guidance to the linguist or language professional who wishes to take advantage of them. Divided into eight chapters, each of the expert contributors focus on a different aspect of the interaction of computing and linguistics looking either at computational resources: the Internet, software for fieldwork and teaching linguistics, Unix utilities, or at computational developments: the availability of electronic texts, new methodologies in natural language processing, the development of the CELLAR computing environment for linguistic analysis.},
	language = {en},
	publisher = {Routledge},
	author = {Lawler, John M. and Dry, Hellen Aristar},
	year = {1998},
	note = {00056},
	keywords = {Language Arts \& Disciplines / Linguistics / General}
}

@inproceedings{strain_exploring_2012,
	title = {Exploring relationships between learners’ affective states, metacognitive processes, and learning outcomes},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-30950-2_8},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer},
	author = {Strain, Amber Chauncey and Azevedo, Roger and D’Mello, Sidney},
	year = {2012},
	note = {00005},
	pages = {59--64}
}

@article{meyer_discovering_2002,
	title = {Discovering emotion in classroom motivation research},
	volume = {37},
	url = {http://www.tandfonline.com/doi/abs/10.1207/S15326985EP3702_5},
	number = {2},
	urldate = {2014-06-17TZ},
	journal = {Educational psychologist},
	author = {Meyer, Debra K. and Turner, Julianne C.},
	year = {2002},
	note = {00392},
	pages = {107--114}
}

@inproceedings{bohnet_very_2010,
	title = {Very high accuracy and fast dependency parsing is not a contradiction},
	url = {http://dl.acm.org/citation.cfm?id=1873792},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Computational} {Linguistics}},
	author = {Bohnet, Bernd},
	year = {2010},
	note = {00358},
	pages = {89--97}
}

@article{barrett_experience_2007,
	title = {The {Experience} of {Emotion}},
	volume = {58},
	issn = {0066-4308},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1934613/},
	doi = {10.1146/annurev.psych.58.110405.085709},
	abstract = {Experiences of emotion are content-rich events that emerge at the level of psychological description, but must be causally constituted by neurobiological processes. This chapter outlines an emerging scientific agenda for understanding what these experiences feel like and how they arise. We review the available answers to what is felt (i.e., the content that makes up an experience of emotion) and how neurobiological processes instantiate these properties of experience. These answers are then integrated into a broad framework that describes, in psychological terms, how the experience of emotion emerges from more basic processes. We then discuss the role of such experiences in the economy of the mind and behavior.},
	urldate = {2014-09-29TZ},
	journal = {Annual review of psychology},
	author = {Barrett, Lisa Feldman and Mesquita, Batja and Ochsner, Kevin N. and Gross, James J.},
	year = {2007},
	pmid = {17002554},
	pmcid = {PMC1934613},
	note = {00791 },
	pages = {373--403}
}

@misc{noauthor_lojban_2013,
	title = {Lojban},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://de.wikipedia.org/w/index.php?title=Lojban&oldid=120754025},
	abstract = {Die Plansprache Lojban [ˈloʒban] (Sprachcode nach ISO 639-2: jbo) wurde 1987 von der Logical Language Group entwickelt. Sie basiert auf der ebenfalls künstlichen Sprache Loglan. Bei der Entwicklung wurde besonderer Wert darauf gelegt, eine benutzbare, möglichst umfassende und frei verfügbare Sprache zu schaffen. Der Wortschatz der Grundwörter ist aus Wortstämmen der sechs weltweit meistgesprochenen Sprachen nach einem bestimmten Algorithmus gebildet. Diese Ursprungssprachen sind Arabisch, Chinesisch, Englisch, Hindi, Russisch, Spanisch.},
	language = {de},
	urldate = {2013-07-24TZ},
	journal = {Wikipedia},
	month = jul,
	year = {2013},
	note = {00000 
Page Version ID: 120754025}
}
@incollection{boekaerts_towards_2003,
	title = {Towards a model that integrates motivation, affect and learning},
	volume = {173},
	number = {189},
	booktitle = {{BJEP} {Monograph} {Series} {II}, {Number} 2-{Development} and {Motivation}},
	publisher = {British Psychological Society},
	author = {Boekaerts, Monique},
	year = {2003},
	note = {00058},
	pages = {173--189}
}

@incollection{dweck_messages_2002,
	address = {San Diego,  CA,  US},
	title = {Messages that motivate: {How} praise molds students' beliefs, motivation, and performance (in surprising ways)},
	copyright = {(c) 2012 APA, all rights reserved},
	isbn = {0-12-064455-X (Hardcover)},
	shorttitle = {Messages that motivate},
	abstract = {Shows how the feedback teachers give to students can mold their beliefs about their intelligence and, in turn, their motivation and achievement. In discussing beliefs that play a key role in motivation, the author focuses on one particular kind of belief, namely, students' "theories" about their intelligence. Two of these theories are describe: the belief that intelligence is a fixed trait that cannot be developed vs the idea that intelligence is a malleable quality, a potential that can be cultivated. Then, the author explains how these theories of intelligence can be changed to increase motivation and achievement.},
	booktitle = {Improving academic achievement:  {Impact} of psychological factors on education},
	publisher = {Academic Press},
	author = {Dweck, Carol S.},
	year = {2002},
	note = {00235},
	keywords = {*Academic Achievement, *Academic Achievement Motivation, *Intelligence, *Motivation, Student Attitudes},
	pages = {37--60}
}

@misc{neumann_open_2012,
	address = {DFKI},
	title = {Open {Domain} {Information} {Extraction}},
	url = {http://www.dfki.de/~neumann/InformationExtractionLecture2011/sessions/10-openIE.pdf},
	author = {Neumann, Günter},
	month = jan,
	year = {2012},
	note = {00000}
}

@inproceedings{brants_tiger_2002,
	title = {The {TIGER} treebank},
	volume = {168},
	url = {http://www.coli.uni-saarland.de/publikationen/softcopies/Brants:2002:TT.pdf},
	urldate = {2014-03-27TZ},
	booktitle = {Proceedings of the workshop on treebanks and linguistic theories},
	author = {Brants, Sabine and Dipper, Stefanie and Hansen, Silvia and Lezius, Wolfgang and Smith, George},
	year = {2002},
	note = {00547}
}

@book{ekman_gesichtsausdruck_1988,
	title = {Gesichtsausdruck und {Gefühl}: 20 {Jahre} {Forschung} von {Paul} {Ekman}},
	shorttitle = {Gesichtsausdruck und {Gefühl}},
	publisher = {Junfermann-Verlag},
	author = {Ekman, Paul and von Salisch, Maria},
	year = {1988},
	note = {00188}
}

@misc{noauthor_manuel_nodate,
	title = {Manuel {Kountz} - {Deutschland} {\textbar} {LinkedIn}},
	url = {http://de.linkedin.com/pub/manuel-kountz/83/b62/65},
	urldate = {2014-03-27TZ},
	note = {00000}
}

@misc{noauthor_affekt_2014,
	title = {Affekt},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://de.wikipedia.org/w/index.php?title=Affekt&oldid=132980447},
	abstract = {Der Affekt (von lat. afficere: antun; in einen Zustand versetzen; mit etwas erfüllen, versehen) ist eine Gemütserregung (englisch: occurring emotion etwas, das einem passiert).[1] Sie hat eine Ausdrucksdimension, eine körperliche Dimension und eine motivationale Dimension. Ein Lächeln kann beispielsweise ein Ausdruck für den Affekt Sympathie sein, Erröten, im körperlichen Bereich, bezeichnend für den Affekt Scham und die Bereitschaft, mit der Faust auf den Tisch zu hauen, eine charakteristische Motivation aus dem Affekt Zorn heraus sein.[2]},
	language = {de},
	urldate = {2014-09-29TZ},
	journal = {Wikipedia},
	month = sep,
	year = {2014},
	note = {00003 
Page Version ID: 132980447}
}

@inproceedings{smith_bootstrapping_2007,
	title = {Bootstrapping {Feature}-{Rich} {Dependency} {Parsers} with {Entropic} {Priors}.},
	url = {http://acl.ldc.upenn.edu/D/D07/D07-1070.pdf},
	urldate = {2013-07-26TZ},
	booktitle = {{EMNLP}-{CoNLL}},
	author = {Smith, David A. and Eisner, Jason},
	year = {2007},
	note = {00024},
	pages = {667--677}
}

@article{craig_affect_2004,
	title = {Affect and learning: {An} exploratory look into the role of affect in learning with {AutoTutor}},
	volume = {29},
	issn = {1358-1651},
	shorttitle = {Affect and learning},
	url = {http://www.tandfonline.com/doi/abs/10.1080/1358165042000283101},
	doi = {10.1080/1358165042000283101},
	language = {en},
	number = {3},
	urldate = {2014-09-30TZ},
	journal = {Journal of Educational Media},
	author = {Craig, Scotty and Graesser, Arthur and Sullins, Jeremiah and Gholson, Barry},
	month = oct,
	year = {2004},
	note = {00408},
	pages = {241--250}
}

@inproceedings{punyakanok_semantic_2004,
	address = {Stroudsburg, PA, USA},
	series = {{COLING} '04},
	title = {Semantic role labeling via integer linear programming inference},
	url = {http://dx.doi.org/10.3115/1220355.1220552},
	doi = {10.3115/1220355.1220552},
	abstract = {We present a system for the semantic role labeling task. The system combines a machine learning technique with an inference procedure based on integer linear programming that supports the incorporation of linguistic and structural constraints into the decision process. The system is tested on the data provided in CoNLL-2004 shared task on semantic role labeling and achieves very competitive results.},
	urldate = {2013-07-31TZ},
	booktitle = {Proceedings of the 20th international conference on {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Punyakanok, Vasin and Roth, Dan and Yih, Wen-tau and Zimak, Dav},
	year = {2004},
	note = {00164}
}

@article{baker_better_2010,
	title = {Better to be frustrated than bored: {The} incidence, persistence, and impact of learners’ cognitive–affective states during interactions with three different computer-based learning environments},
	volume = {68},
	issn = {10715819},
	shorttitle = {Better to be frustrated than bored},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581909001797},
	doi = {10.1016/j.ijhcs.2009.12.003},
	language = {en},
	number = {4},
	urldate = {2014-06-17TZ},
	journal = {International Journal of Human-Computer Studies},
	author = {Baker, Ryan S.J.d. and D'Mello, Sidney K. and Rodrigo, Ma.Mercedes T. and Graesser, Arthur C.},
	month = apr,
	year = {2010},
	note = {00293},
	pages = {223--241}
}

@article{koedinger_intelligent_1997,
	title = {Intelligent tutoring goes to school in the big city},
	volume = {8},
	url = {http://telearn.archives-ouvertes.fr/hal-00197383/},
	urldate = {2014-09-28TZ},
	journal = {International Journal of Artificial Intelligence in Education (IJAIED)},
	author = {Koedinger, Kenneth R. and Anderson, John R. and Hadley, William H. and Mark, Mary A. and {others}},
	year = {1997},
	note = {01192},
	pages = {30--43}
}

@inproceedings{hoffmann_learning_2010,
	title = {Learning 5000 relational extractors},
	url = {http://dl.acm.org/citation.cfm?id=1858711},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 48th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	author = {Hoffmann, Raphael and Zhang, Congle and Weld, Daniel S.},
	year = {2010},
	note = {00113},
	pages = {286--295}
}

@incollection{frasson_virtual_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Virtual {Environment} for {Monitoring} {Emotional} {Behaviour} in {Driving}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3 978-3-319-07221-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_10},
	abstract = {Emotions are an important behaviour of humans and may arise in driving situations. Uncontrolled emotions can lead to harmful effects. To control and reduce the negative impact of emotions, we have built a virtual driving environment in which we can capture and analyse emotions felt by the driver using EEG systems. By simulating specific emotional situations we can provoke these emotions and detect their types and intensity according to the driver. Then, in the environment, we generate corrective actions that are able to reduce the emotions. After a training period, the driver is able to correct the emotions by himself.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Frasson, Claude and Brosseau, Pierre Olivier and Tran, Thi Hong Dung},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	note = {00002},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, Driving, EEG, Emotional state, Emotions, Multimedia Information Systems, Simulation, User Interfaces and Human Computer Interaction},
	pages = {75--83}
}

@incollection{takhirov_integrated_2013,
	title = {An {Integrated} {Approach} for {Large}-{Scale} {Relation} {Extraction} from the {Web}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-37401-2_18},
	urldate = {2013-07-26TZ},
	booktitle = {Web {Technologies} and {Applications}},
	publisher = {Springer},
	author = {Takhirov, Naimdjon and Duchateau, Fabien and Aalberg, Trond and Sølvberg, Ingeborg},
	year = {2013},
	note = {00001},
	keywords = {Data Mining and Knowledge Discovery, Database Management, Information Storage and Retrieval, Knowledge Bases, Multimedia Information Systems, Relation Extraction, Web Mining},
	pages = {163--175}
}

@misc{noauthor_ontologie_2013,
	title = {Ontologie ({Informatik})},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://de.wikipedia.org/w/index.php?title=Ontologie_(Informatik)&oldid=120441652},
	abstract = {Ontologien in der Informatik sind meist sprachlich gefasste und formal geordnete Darstellungen einer Menge von Begrifflichkeiten und der zwischen ihnen bestehenden Beziehungen in einem bestimmten Gegenstandsbereich. Sie werden dazu genutzt, „Wissen“ in digitalisierter und formaler Form zwischen Anwendungsprogrammen und Diensten auszutauschen. Wissen umfasst dabei sowohl Allgemeinwissen als auch Wissen über sehr spezielle Themengebiete und Vorgänge.},
	language = {de},
	urldate = {2013-07-29TZ},
	journal = {Wikipedia},
	month = jul,
	year = {2013},
	note = {00000 
Page Version ID: 120441652}
}

@article{graesser_autotutor:_2004,
	title = {{AutoTutor}: {A} tutor with dialogue in natural language},
	volume = {36},
	issn = {0743-3808, 1532-5970},
	shorttitle = {{AutoTutor}},
	url = {http://link.springer.com/article/10.3758/BF03195563},
	doi = {10.3758/BF03195563},
	abstract = {AutoTutor is a learning environment that tutors students by holding a conversation in natural language. AutoTutor has been developed for Newtonian qualitative physics and computer literacy. Its design was inspired by explanation-based constructivist theories of learning, intelligent tutoring systems that adaptively respond to student knowledge, and empirical research on dialogue patterns in tutorial discourse. AutoTutor presents challenging problems (formulated as questions) from a curriculum script and then engages in mixed initiative dialogue that guides the student in building an answer. It provides the student with positive, neutral, or negative feedback on the student’s typed responses, pumps the student for more information, prompts the student to fill in missing words, gives hints, fills in missing information with assertions, identifies and corrects erroneous ideas, answers the student’s questions, and summarizes answers. AutoTutor has produced learning gains of approximately .70 sigma for deep levels of comprehension.},
	language = {en},
	number = {2},
	urldate = {2014-09-28TZ},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Graesser, Arthur C. and Lu, Shulan and Jackson, George Tanner and Mitchell, Heather Hite and Ventura, Mathew and Olney, Andrew and Louwerse, Max M.},
	month = may,
	year = {2004},
	note = {00366},
	keywords = {Cognitive Psychology},
	pages = {180--192}
}

@incollection{el_kaliouby_real-time_2005,
	title = {Real-time inference of complex mental states from facial expressions and head gestures},
	url = {http://link.springer.com/content/pdf/10.1007/0-387-27890-7_11.pdf},
	urldate = {2014-10-01TZ},
	booktitle = {Real-time vision for human-computer interaction},
	publisher = {Springer},
	author = {El Kaliouby, Rana and Robinson, Peter},
	year = {2005},
	note = {00273},
	pages = {181--200}
}

@article{hickey_affective_2014,
	title = {The {Affective} {Tutor}},
	volume = {29},
	issn = {1937-4771},
	url = {http://dl.acm.org/citation.cfm?id=2602724.2602735},
	abstract = {In this paper we present our initial work on an application, The Affective Tutor, envisioned to help instructors keep all students in a large lecture class engaged and actively learning material related to the course. We have found, by asking for feedback after every class, that in a large class of over 50 students, a significant number of students will feel the class went too slow and another group will feel the class went too fast. One of the most challenging aspects of teaching a large class is to keep the entire class engaged in the course material. The Affective Tutor helps instructors to determine in real-time how students feel about the pace of the class. The tool also helps instructors to pin-point confusing topics, and to tackle the problem of keeping students engaged by providing a monitored back-channel that allows the bored students to help the confused students get back on track and into an engaged mode.},
	number = {6},
	urldate = {2014-09-28TZ},
	journal = {J. Comput. Sci. Coll.},
	author = {Hickey, Timothy J. and Tarimo, William T.},
	month = jun,
	year = {2014},
	note = {00008},
	pages = {50--56}
}

@inproceedings{cheng_entityrank:_2007,
	title = {{EntityRank}: searching entities directly and holistically},
	shorttitle = {{EntityRank}},
	url = {http://dl.acm.org/citation.cfm?id=1325898},
	urldate = {2013-03-04TZ},
	booktitle = {Proceedings of the 33rd international conference on {Very} large data bases},
	author = {Cheng, Tao and Yan, Xifeng and Chang, Kevin Chen-Chuan},
	year = {2007},
	note = {00185},
	pages = {387--398}
}

@inproceedings{wu_open_2010,
	title = {Open information extraction using {Wikipedia}},
	url = {http://dl.acm.org/citation.cfm?id=1858694},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 48th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	author = {Wu, Fei and Weld, Daniel S.},
	year = {2010},
	note = {00326},
	pages = {118--127}
}

@book{picard_affective_2000,
	title = {Affective {Computing}},
	isbn = {978-0-262-66115-7},
	abstract = {The latest scientific findings indicate that emotions play an essential role in decision making, perception, learning, and more -- that is, they influence the very mechanisms of rational thinking. Not only too much, but too little emotion can impair decision making. According to Rosalind Picard, if we want computers to be genuinely intelligent and to interact naturally with us, we must give computers the ability to recognize, understand, even to have and express emotions.Part 1 of this book provides the intellectual framework for affective computing. It includes background on human emotions, requirements for emotionally intelligent computers, applications of affective computing, and moral and social questions raised by the technology. Part 2 discusses the design and construction of affective computers. Although this material is more technical than that in Part 1, the author has kept it less technical than typical scientific publications in order to make it accessible to newcomers. Topics in Part 2 include signal-based representations of emotions, human affect recognition as a pattern recognition and learning problem, recent and ongoing efforts to build models of emotion for synthesizing emotions in computers, and the new application area of affective wearable computers.},
	language = {en},
	publisher = {MIT Press},
	author = {Picard, Rosalind W.},
	year = {2000},
	note = {06107},
	keywords = {Computers / Computer Science, Computers / Intelligence (AI) \& Semantics, Computers / Virtual Worlds}
}

@article{pekrun_academic_2002,
	title = {Academic emotions in students' self-regulated learning and achievement: {A} program of qualitative and quantitative research},
	volume = {37},
	shorttitle = {Academic emotions in students' self-regulated learning and achievement},
	url = {http://www.tandfonline.com/doi/abs/10.1207/S15326985EP3702_4},
	number = {2},
	urldate = {2014-09-30TZ},
	journal = {Educational psychologist},
	author = {Pekrun, Reinhard and Goetz, Thomas and Titz, Wolfram and Perry, Raymond P.},
	year = {2002},
	note = {01636},
	pages = {91--105}
}

@article{ekman_measuring_1976,
	title = {Measuring facial movement},
	volume = {1},
	issn = {0361-3496, 1573-3653},
	url = {http://link.springer.com/article/10.1007/BF01115465},
	doi = {10.1007/BF01115465},
	abstract = {A procedure has been developed for measuring visibly different facial movements. The Facial Action Code was derived from an analysis of the anatomical basis of facial movement. The method can be used to describe any facial movement (observed in photographs, motion picture film or videotape) in terms of anatomically based action units. The development of the method is explained, contrasting it to other methods of measuring facial behavior. An example of how facial behavior is measured is provided, and ideas about research applications are discussed.},
	language = {en},
	number = {1},
	urldate = {2014-09-30TZ},
	journal = {Environmental psychology and nonverbal behavior},
	author = {Ekman, Paul and Friesen, Wallace V.},
	month = sep,
	year = {1976},
	note = {00593},
	keywords = {Communication, Psychology of Personality, Social Psychology, Sociology},
	pages = {56--75}
}

@article{dmello_disequilibrium_2012,
	title = {Disequilibrium in the mind, disharmony in the body},
	volume = {26},
	url = {http://www.tandfonline.com/doi/abs/10.1080/02699931.2011.575767},
	number = {2},
	urldate = {2014-06-17TZ},
	journal = {Cognition \& emotion},
	author = {D'Mello, Sidney and Dale, Rick and Graesser, Art},
	year = {2012},
	note = {00032},
	pages = {362--374}
}

@misc{noauthor_new_nodate,
	title = {New {Perspectives} on {Affect} and {Learning} {Technologies} - {Springer}},
	url = {http://link.springer.com/book/10.1007/978-1-4419-9625-1},
	urldate = {2014-09-30TZ},
	note = {00045}
}

@inproceedings{carlson_toward_2010,
	title = {Toward an {Architecture} for {Never}-{Ending} {Language} {Learning}.},
	url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/download/1879/2201},
	urldate = {2013-07-26TZ},
	booktitle = {{AAAI}},
	author = {Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka Jr, Estevam R. and Mitchell, Tom M.},
	year = {2010},
	note = {00763}
}

@inproceedings{litman_predicting_2004,
	address = {Stroudsburg, PA, USA},
	series = {{ACL} '04},
	title = {Predicting {Student} {Emotions} in {Computer}-human {Tutoring} {Dialogues}},
	url = {http://dx.doi.org/10.3115/1218955.1219000},
	doi = {10.3115/1218955.1219000},
	abstract = {We examine the utility of speech and lexical features for predicting student emotions in computer-human spoken tutoring dialogues. We first annotate student turns for negative, neutral, positive and mixed emotions. We then extract acoustic-prosodic features from the speech signal, and lexical items from the transcribed or recognized speech. We compare the results of machine learning experiments using these features alone or in combination to predict various categorizations of the annotated student emotions. Our best results yield a 19-36\% relative improvement in error reduction over a baseline. Finally, we compare our results with emotion prediction in human-human tutoring dialogues.},
	urldate = {2014-09-28TZ},
	booktitle = {Proceedings of the 42Nd {Annual} {Meeting} on {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Litman, Diane J. and Forbes-Riley, Kate},
	year = {2004},
	note = {00180}
}

@article{dmello_towards_2007,
	title = {Towards an affect-sensitive autotutor},
	volume = {22},
	url = {http://www.memphis.edu/psychology/graesser/publications/documents/dmello_ieee_is07.pdf},
	number = {4},
	urldate = {2014-09-28TZ},
	journal = {IEEE Intelligent Systems},
	author = {D’Mello, Sidney and Picard, Rosalind and Graesser, Arthur},
	year = {2007},
	note = {00285},
	pages = {53--61}
}

@book{nkambou_advances_2010,
	address = {Berlin},
	series = {Studies in computational intelligence},
	title = {Advances in intelligent tutoring systems},
	isbn = {978-3-642-14362-5},
	number = {v. 308},
	publisher = {Springer},
	editor = {Nkambou, Roger and Bourdeau, Jacqueline and Mizoguchi, Riichiro},
	year = {2010},
	note = {00098},
	keywords = {Artificial intelligence, Educational applications, Intelligent tutoring systems}
}

@article{graesser_autotutor:_2008,
	title = {{AutoTutor}: {Learning} through natural language dialogue that adapts to the cognitive and affective states of the learner},
	shorttitle = {{AutoTutor}},
	journal = {Recent innovations in educational technology that facilitate student learning},
	author = {Graesser, A. C. and Rus, Vasile and D’Mello, S. K. and Jackson, G. Tanner and Robinson, D. H. and Schraw, G.},
	year = {2008},
	note = {00022},
	pages = {95--125}
}

@article{anderson_cognitive_1995,
	title = {Cognitive tutors: {Lessons} learned},
	volume = {4},
	shorttitle = {Cognitive tutors},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327809jls0402_2},
	number = {2},
	urldate = {2014-09-29TZ},
	journal = {The journal of the learning sciences},
	author = {Anderson, John R. and Corbett, Albert T. and Koedinger, Kenneth R. and Pelletier, Ray},
	year = {1995},
	note = {01864},
	pages = {167--207}
}

@inproceedings{christensen_semantic_2010,
	address = {Stroudsburg, PA, USA},
	series = {{FAM}-{LbR} '10},
	title = {Semantic role labeling for open information extraction},
	url = {http://dl.acm.org/citation.cfm?id=1866775.1866782},
	abstract = {Open Information Extraction is a recent paradigm for machine reading from arbitrary text. In contrast to existing techniques, which have used only shallow syntactic features, we investigate the use of semantic features (semantic roles) for the task of Open IE. We compare TextRunner (Banko et al., 2007), a state of the art open extractor, with our novel extractor SRL-IE, which is based on UIUC's SRL system (Punyakanok et al., 2008). We find that SRL-IE is robust to noisy heterogeneous Web data and outperforms TextRunner on extraction quality. On the other hand, TextRunner performs over 2 orders of magnitude faster and achieves good precision in high locality and high redundancy extractions. These observations enable the construction of hybrid extractors that output higher quality results than TextRunner and similar quality as SRL-IE in much less time.},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the {NAACL} {HLT} 2010 {First} {International} {Workshop} on {Formalisms} and {Methodology} for {Learning} by {Reading}},
	publisher = {Association for Computational Linguistics},
	author = {Christensen, Janara and Mausam and Soderland, Stephen and Etzioni, Oren},
	year = {2010},
	note = {00039},
	pages = {52--60}
}

@inproceedings{pour_impact_2010,
	title = {The impact of system feedback on learners’ affective and physiological states},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-13388-6_31},
	urldate = {2014-06-17TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer},
	author = {Pour, Payam Aghaei and Hussain, M. Sazzad and AlZoubi, Omar and D’Mello, Sidney and Calvo, Rafael A.},
	year = {2010},
	note = {00041},
	pages = {264--273}
}

@inproceedings{litman_itspoke:_2004,
	title = {{ITSPOKE}: {An} intelligent tutoring spoken dialogue system},
	shorttitle = {{ITSPOKE}},
	url = {http://dl.acm.org/citation.cfm?id=1614027},
	urldate = {2014-09-29TZ},
	booktitle = {Demonstration {Papers} at {HLT}-{NAACL} 2004},
	publisher = {Association for Computational Linguistics},
	author = {Litman, Diane J. and Silliman, Scott},
	year = {2004},
	note = {00218},
	pages = {5--8}
}

@incollection{lehman_impact_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Impact of {Agent} {Role} on {Confusion} {Induction} and {Learning}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3 978-3-319-07221-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_6},
	abstract = {The presentation of contradictory information to trigger deeper processing and increase learning has been investigated in a variety of ways (e.g., conversational agents, worked examples). However, the impact of information source (e.g., expertise, gender) and the relationship between the contradicting sources (e.g., status level) has not been investigated to the same degree. We previously reported that confusion can successfully be induced and learning increased when contradictory information was presented by two conversational agents (tutor, peer student). In the present experiment we investigated contradictions posed by two peer student agents. Self-reports of confusion and learner responses to embedded forced-choice questions revealed that the contradictions still successfully induced confusion. There were, however, differences in the nature of confusion induction based on the inter-agent relationship (i.e., student-student vs. tutor-student). Learners performed better on transfer tasks when presented with contradictions compared to a no-contradiction control, but only when they were successfully confused.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Lehman, Blair and Graesser, Arthur},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	note = {00002},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, Intelligent tutoring systems, Multimedia Information Systems, Tutoring, User Interfaces and Human Computer Interaction, affect, animated pedagogical agents, confusion, contradiction, learning},
	pages = {45--54}
}

@inproceedings{afzal_modelling_2010,
	title = {Modelling {Affect} in {Learning} {Environments}-{Motivation} and {Methods}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5573217},
	urldate = {2014-09-30TZ},
	booktitle = {Advanced {Learning} {Technologies} ({ICALT}), 2010 {IEEE} 10th {International} {Conference} on},
	publisher = {IEEE},
	author = {Afzal, Shazia and Robinson, Peter},
	year = {2010},
	note = {00007},
	pages = {438--442}
}

@book{psotka_intelligent_1988,
	address = {Hillsdale, N.J},
	title = {Intelligent tutoring systems: lessons learned},
	isbn = {0-8058-0023-9},
	shorttitle = {Intelligent tutoring systems},
	publisher = {L. Erlbaum Associates},
	editor = {Psotka, Joseph and Massey, L. Daniel and Mutter, Sharon A.},
	year = {1988},
	note = {00253},
	keywords = {Automation Congresses, Congresses, Intelligent tutoring systems, Military education, United States}
}

@inproceedings{banko_open_2007,
	title = {Open {Information} {Extraction} from the {Web}.},
	volume = {7},
	url = {http://www.aaai.org/Papers/IJCAI/2007/IJCAI07-429.pdf},
	urldate = {2013-07-26TZ},
	booktitle = {{IJCAI}},
	author = {Banko, Michele and Cafarella, Michael J. and Soderland, Stephen and Broadhead, Matthew and Etzioni, Oren},
	year = {2007},
	note = {01116},
	pages = {2670--2676}
}

@inproceedings{gamallo_dependency-based_2012,
	title = {Dependency-based open information extraction},
	url = {http://dl.acm.org/citation.cfm?id=2389963},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the {Joint} {Workshop} on {Unsupervised} and {Semi}-{Supervised} {Learning} in {NLP}},
	author = {Gamallo, Pablo and Garcia, Marcos and Fernández-Lanza, Santiago},
	year = {2012},
	note = {00047},
	pages = {10--18}
}

@misc{noauthor_emotionstheorien_2014,
	title = {Emotionstheorien},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://de.wikipedia.org/w/index.php?title=Emotionstheorien&oldid=132963400},
	abstract = {Emotionstheorien sind Ansätze zur Erklärung, was Emotionen sind, wodurch sie verursacht werden und wie sie sich auf das Verhalten von Lebewesen auswirken. Es gibt verschiedene Arten, Emotionstheorien zu kategorisieren:},
	language = {de},
	urldate = {2014-09-10TZ},
	journal = {Wikipedia},
	month = sep,
	year = {2014},
	note = {00000 
Page Version ID: 132963400}
}

@incollection{cooper_effective_2000,
	title = {Effective affective in intelligent systems–building on evidence of empathy in teaching and learning},
	url = {http://link.springer.com/chapter/10.1007/10720296_3},
	urldate = {2014-09-29TZ},
	booktitle = {Affective interactions},
	publisher = {Springer},
	author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
	year = {2000},
	note = {00053},
	pages = {21--34}
}

@article{graesser_autotutor:_2005,
	title = {{AutoTutor}: an intelligent tutoring system with mixed-initiative dialogue},
	volume = {48},
	issn = {0018-9359},
	shorttitle = {{AutoTutor}},
	doi = {10.1109/TE.2005.856149},
	abstract = {AutoTutor simulates a human tutor by holding a conversation with the learner in natural language. The dialogue is augmented by an animated conversational agent and three-dimensional (3-D) interactive simulations in order to enhance the learner's engagement and the depth of the learning. Grounded in constructivist learning theories and tutoring research, AutoTutor achieves learning gains of approximately 0.8 sigma (nearly one letter grade), depending on the learning measure and comparison condition. The computational architecture of the system uses the .NET framework and has simplified deployment for classroom trials.},
	number = {4},
	journal = {IEEE Transactions on Education},
	author = {Graesser, AC. and Chipman, P. and Haynes, B.C. and Olney, A},
	month = nov,
	year = {2005},
	note = {00393},
	keywords = {.NET framework, 3D interactive simulation, Animation, AutoTutor simulation, Computational modeling, Conversational agents, Gain measurement, Humans, Injuries, Intelligent Tutoring System, Intelligent systems, Intelligent tutoring systems, Neck, Physics education, STEM learning, Speech analysis, Tutoring, animated conversational agent, distance learning, human tutor, mixed-initiative dialogue, natural language, natural language dialogue, natural languages},
	pages = {612--618}
}

@article{russell_core_2003,
	title = {Core affect and the psychological construction of emotion.},
	volume = {110},
	issn = {1939-1471, 0033-295X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.110.1.145},
	doi = {10.1037/0033-295X.110.1.145},
	language = {en},
	number = {1},
	urldate = {2014-09-30TZ},
	journal = {Psychological Review},
	author = {Russell, James A.},
	year = {2003},
	note = {02761},
	pages = {145--172}
}

@incollection{betten_discovery_1995,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The discovery of simple 7-designs with automorphism group {PΓL}(2, 32)},
	copyright = {©1995 Springer-Verlag},
	isbn = {978-3-540-60114-2 978-3-540-49440-9},
	url = {http://link.springer.com/chapter/10.1007/3-540-60114-7_10},
	abstract = {A computer package is being developed at Bayreuth for the generation and investigation of discrete structures. The package is a C and C++ class library of powerful algorithms endowed with graphical interface modules. Standard applications can be run automatically whereas research projects mostly require small C or C++ programs. The basic philosophy behind the system is to transform problems into standard problems of e.g. group theory, graph theory, linear algebra, graphics, or databases and then to use highly specialized routines from that field to tackle the problems. The transformations required often follow the same principles especially in the case of generation and isomorphism testing. We therefore explain some of this background. We relate orbit problems to double cosets and we offer a way to solve double coset problems in many important cases. Since the graph isomorphism problem is equivalent to a certain double coset problem, no polynomial algorithm can be expected to work in the general case. But the reduction techniques used still allow to solve problems of an interesting size. As an example we explain how the 7-designs in the title were found. The two simple 7-designs with parameters 7-(33, 8, 10) and 7-(33, 8, 16) are presented in this paper. To the best of our knowledge they are the first 7-designs with small λ and small number of blocks ever found. Teirlinck [19] had shown previously that non trivial t-designs without repeated blocks exist for all t. The smallest parameters for the case t=7 are 7-(4032015 + 7,8,4032015). The designs have PΓL(2, 32) as automorphism group, and they are constructed from the Kramer-Mesner method [7]. This group had previously been used by [13] in order to find simple 6-designs. The presentation of our results is compatible with that earlier publication. The Kramer-Mesner method requires to solve a system of linear diophantine equations by a \{0, 1\}-vector. We used the recent improvements by Schnorr of the LLL-algorithm for finding the two solutions to the 32 x 97 system.},
	number = {948},
	urldate = {2013-03-04TZ},
	booktitle = {Applied {Algebra}, {Algebraic} {Algorithms} and {Error}-{Correcting} {Codes}},
	publisher = {Springer Berlin Heidelberg},
	author = {Betten, Anton and Kerber, Adalbert and Kohnert, Axel and Laue, Reinhard and Wassermann, Alfred},
	editor = {Cohen, Gérard and Giusti, Marc and Mora, Teo},
	month = jan,
	year = {1995},
	note = {00038},
	keywords = {Algorithm Analysis and Problem Complexity, Coding and Information Theory, Combinatorics, Data Encryption, Symbolic and Algebraic Manipulation},
	pages = {131--145}
}

@inproceedings{afzal_natural_2009,
	title = {Natural affect data—collection \& annotation in a learning context},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5349537},
	abstract = {Automatic inference of affect relies on representative data. For viable applications of such technology the use of naturalistic over posed data has been increasingly emphasised. Creating a repository of naturalistic data is however a massively challenging task. We report results from a data collection exercise in one of the most significant application areas of affective computing, namely computer-based learning environments. The conceptual and methodological issues encountered during the process are discussed, and problems with labelling and annotation are identified. A comparison of the compiled database with some standard databases is also presented.},
	urldate = {2014-09-30TZ},
	booktitle = {Affective {Computing} and {Intelligent} {Interaction} and {Workshops}, 2009. {ACII} 2009. 3rd {International} {Conference} on},
	publisher = {IEEE},
	author = {Afzal, Shazia and Robinson, Peter},
	year = {2009},
	note = {00057},
	pages = {1--7}
}

@incollection{gertner_andes:_2000,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Andes: {A} {Coached} {Problem} {Solving} {Environment} for {Physics}},
	copyright = {©2000 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-67655-3 978-3-540-45108-2},
	shorttitle = {Andes},
	url = {http://link.springer.com/chapter/10.1007/3-540-45108-0_17},
	abstract = {Andes is an Intelligent Tutoring System for introductory college physics. The fundamental principles underlying the design of Andes are: (1) encourage the student to construct new knowledge by providing hints that require them to derive most of the solution on their own, (2) facilitate transfer from the system by making the interface as much like a piece of paper as possible, (3) give immediate feedback after each action to maximize the opportunities for learning and minimize the amount of time spent going down wrong paths, and (4) give the student flexibility in the order in which actions are performed, and allow them to skip steps when appropriate. This paper gives an overview of Andes, focusing on the overall architecture and the student’s experience using the system.},
	language = {en},
	number = {1839},
	urldate = {2014-09-28TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Gertner, Abigail S. and VanLehn, Kurt},
	editor = {Gauthier, Gilles and Frasson, Claude and VanLehn, Kurt},
	month = jan,
	year = {2000},
	note = {00245},
	keywords = {Artificial Intelligence (incl. Robotics), Computers and Education, Software Engineering, User Interfaces and Human Computer Interaction},
	pages = {133--142}
}

@article{lafferty_conditional_2001,
	title = {Conditional random fields: {Probabilistic} models for segmenting and labeling sequence data},
	shorttitle = {Conditional random fields},
	url = {http://repository.upenn.edu/cis_papers/159/},
	urldate = {2013-08-29TZ},
	author = {Lafferty, John and McCallum, Andrew and Pereira, Fernando CN},
	year = {2001},
	note = {09017}
}

@article{noauthor_besser:_2013,
	chapter = {Kolumnen},
	title = {Besser: {Der} {Aufstand} der {Weißen}},
	shorttitle = {Besser},
	url = {http://www.taz.de/!117372/},
	abstract = {Die Demokratisierung des politischen Islams ist gescheitert. Siebeneinhalb Thesen zum Aufstand gegen die Erdogan-Regierung.},
	urldate = {2013-06-14TZ},
	journal = {die tageszeitung},
	month = mar,
	year = {2013},
	note = {00000}
}

@inproceedings{etzioni_open_2011,
	title = {Open information extraction: {The} second generation},
	shorttitle = {Open information extraction},
	url = {http://dl.acm.org/citation.cfm?id=2283398},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the {Twenty}-{Second} international joint conference on {Artificial} {Intelligence}-{Volume} {Volume} {One}},
	author = {Etzioni, Oren and Fader, Anthony and Christensen, Janara and Soderland, Stephen and Mausam},
	year = {2011},
	note = {00251},
	pages = {3--10}
}

@article{moschitti_tree_2008,
	title = {Tree kernels for semantic role labeling},
	volume = {34},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/coli.2008.34.2.193},
	number = {2},
	urldate = {2014-02-06TZ},
	journal = {Computational Linguistics},
	author = {Moschitti, Alessandro and Pighin, Daniele and Basili, Roberto},
	year = {2008},
	note = {00136},
	pages = {193--224}
}

@misc{noauthor__nodate,
	title = {▶ {Hubenstocker} - {Expialigetisch} ({Move} {Your} {Feet} {Mixtape}) by {Hubenstocker}},
	url = {https://soundcloud.com/hubenstocker/expialigetisch-move-your-feet},
	abstract = {Explore the largest community of artists, bands, podcasters and creators of music \& audio},
	urldate = {2013-04-08TZ},
	journal = {SoundCloud},
	note = {00000},
	keywords = {audio, music, record, share, sound, soundcloud, sounds, tracks}
}

@book{calvo_new_2011,
	title = {New perspectives on affect and learning technologies},
	volume = {3},
	url = {http://link.springer.com/content/pdf/10.1007/978-1-4419-9625-1.pdf},
	urldate = {2014-09-30TZ},
	publisher = {Springer},
	author = {Calvo, Rafael A. and D'Mello, Sidney K.},
	year = {2011},
	note = {00045}
}

@book{jackendoff_semantics_1985,
	address = {Cambridge, Mass.},
	title = {Semantics and cognition},
	isbn = {0-262-10027-4 978-0-262-10027-4 0-262-60013-7 978-0-262-60013-2},
	language = {English},
	publisher = {MIT Press},
	author = {Jackendoff, Ray},
	year = {1985},
	note = {04970}
}

@article{turner_importance_2002,
	title = {The {Importance} of {Students}' {Goals} in {Their} {Emotional} {Experience} of {Academic} {Failure}: {Investigating} the {Precursors} and {Consequences} of {Shame}},
	volume = {37},
	issn = {0046-1520},
	shorttitle = {The {Importance} of {Students}' {Goals} in {Their} {Emotional} {Experience} of {Academic} {Failure}},
	url = {http://dx.doi.org/10.1207/S15326985EP3702_3},
	doi = {10.1207/S15326985EP3702_3},
	abstract = {This article uses the emotion of shame as an example for exploring relations of students' goals and emotions. Using the framework of self-regulation and motivation, the article discusses the precursors and consequences of this potentially devastating emotion. The research suggests that motivational and goal-related processes may be associated with triggering a shame reaction, but that they also can contribute to shame resiliency. Specifically, the article argues that having clear, important future goals-for which the course grade or course information is instrumentally connected-particularly facilitates students' recovery from a shame reaction. The article concludes, however, that having future goals that supply motivating power for students to engage in learning activities is not sufficient to bring about shame recovery. For students to obtain their future academic goals, they must have a repertoire of study strategies and volitional strategies as well as self-monitoring strategies, metacognitive strategies, and self-regulation that will facilitate the acquisition of immediate learning goals.},
	number = {2},
	urldate = {2014-09-30TZ},
	journal = {Educational Psychologist},
	author = {Turner, Jeannine E. and Husman, Jenefer and Schallert, Diane L.},
	month = jun,
	year = {2002},
	note = {00126},
	pages = {79--89}
}

@book{weiner_attributional_1986,
	title = {An attributional theory of motivation and emotion},
	publisher = {Springer-Verlag New York},
	author = {Weiner, Bernard},
	year = {1986},
	note = {06738}
}

@phdthesis{banko_open_2009,
	title = {Open information extraction for the web},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.212.5142&rep=rep1&type=pdf},
	urldate = {2013-07-26TZ},
	school = {Washington},
	author = {Banko, Michele},
	year = {2009},
	note = {00000}
}

@incollection{bosch_its_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {It’s {Written} on {Your} {Face}: {Detecting} {Affective} {States} from {Facial} {Expressions} while {Learning} {Computer} {Programming}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3 978-3-319-07221-0},
	shorttitle = {It’s {Written} on {Your} {Face}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_5},
	abstract = {We built detectors capable of automatically recognizing affective states of novice computer programmers from student-annotated videos of their faces recorded during an introductory programming tutoring session. We used the Computer Expression Recognition Toolbox (CERT) to track facial features based on the Facial Action Coding System, and machine learning techniques to build classification models. Confusion/Uncertainty and Frustration were distinguished from all other affective states in a student-independent fashion at levels above chance (Cohen’s kappa = .22 and .23, respectively), but detection accuracies for Boredom, Flow/Engagement, and Neutral were lower (kappas = .04, .11, and .07). We discuss the differences between detection of spontaneous versus fixed (polled) judgments as well as the features used in the models.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Bosch, Nigel and Chen, Yuxuan and D’Mello, Sidney},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	note = {00014},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, Multimedia Information Systems, User Interfaces and Human Computer Interaction},
	pages = {39--44}
}

@inproceedings{meyers_nombank_2004,
	title = {The {NomBank} project: {An} interim report},
	shorttitle = {The {NomBank} project},
	url = {http://acl.ldc.upenn.edu/hlt-naacl2004/frontiers/pdf/nombank-pap.pdf},
	urldate = {2013-07-29TZ},
	booktitle = {{HLT}-{NAACL} 2004 workshop: {Frontiers} in corpus annotation},
	author = {Meyers, Adam and Reeves, Ruth and Macleod, Catherine and Szekely, Rachel and Zielinska, Veronika and Young, Brian and Grishman, Ralph},
	year = {2004},
	note = {00253},
	pages = {24--31}
}

@inproceedings{dmello_autotutor_2008,
	title = {{AutoTutor} detects and responds to learners affective and cognitive states},
	url = {http://141.225.218.248/web-cslwebroot/emotion/files/dmello-affectwkshp-its08.pdf},
	abstract = {This paper provides a synthesis of
our research towards the devel-
opment of an affect-sensitive Intelligen
t Tutoring System called AutoTutor.
The affect-sensitive AutoTutor detects the emotions (boredom,
flow/engagement, confusion,
frustration) of a learner by monitoring conversational cues, gross body language, and facial features. It is also mindful of the learners’ affective and cognitive states in selecting its pedagogical and motivational dialogue moves. Finally, the
AutoTutor embodied pedagogical agent synthesizes affective responses through
animated facial expressions and modulated speech. The paper provides an overview of our theoretical framework, methodology, implementation details, and results.
disequilibrium
attribution theory},
	urldate = {2014-06-17TZ},
	booktitle = {Workshop on {Emotional} and {Cognitive} {Issues} at the {International} {Conference} on {Intelligent} {Tutoring} {Systems}},
	author = {D’Mello, Sidney and Jackson, Tanner and Craig, Scotty and Morgan, Brent and Chipman, Patrick and White, Holly and Person, Natalie and Kort, Barry and el Kaliouby, Rana and Picard, Rosalind and {others}},
	year = {2008},
	note = {00093}
}

@article{lu_pubmed_2011,
	title = {{PubMed} and beyond: a survey of web tools for searching biomedical literature},
	volume = {2011},
	issn = {1758-0463},
	shorttitle = {{PubMed} and beyond},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025693/},
	doi = {10.1093/database/baq036},
	abstract = {The past decade has witnessed the modern advances of high-throughput technology and rapid growth of research capacity in producing large-scale biological data, both of which were concomitant with an exponential growth of biomedical literature. This wealth of scholarly knowledge is of significant importance for researchers in making scientific discoveries and healthcare professionals in managing health-related matters. However, the acquisition of such information is becoming increasingly difficult due to its large volume and rapid growth. In response, the National Center for Biotechnology Information (NCBI) is continuously making changes to its PubMed Web service for improvement. Meanwhile, different entities have devoted themselves to developing Web tools for helping users quickly and efficiently search and retrieve relevant publications. These practices, together with maturity in the field of text mining, have led to an increase in the number and quality of various Web tools that provide comparable literature search service to PubMed. In this study, we review 28 such tools, highlight their respective innovations, compare them to the PubMed system and one another, and discuss directions for future development. Furthermore, we have built a website dedicated to tracking existing systems and future advances in the field of biomedical literature search. Taken together, our work serves information seekers in choosing tools for their needs and service providers and developers in keeping current in the field., Database URL: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/search},
	urldate = {2013-09-05TZ},
	journal = {Database: The Journal of Biological Databases and Curation},
	author = {Lu, Zhiyong},
	month = jan,
	year = {2011},
	pmid = {21245076},
	pmcid = {PMC3025693},
	note = {00203 }
}

@incollection{kashihara_knowledge_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Knowledge {Construction} with {Pseudo}-haptics},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3 978-3-319-07221-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_8},
	abstract = {Composing a knowledge map to represent knowledge included in an instructional material is an effective way to understand the material. We currently attempt to utilize tablet media for the knowledge map composition, which allows touch operations with fingers. In particular, we address the issues of how the touch operations could be accompanied with pseudo-haptic senses and whether these senses could produce better cognitive awareness and retention of knowledge learned from the material. Our approach to these issues is to design a model of pseudo-haptic effects that demonstrates what and how cognitive awareness is obtained from pseudo-haptic senses, and to develop a tablet tool on iPad presenting the pseudo-haptic senses as modeled. In this paper, we discuss knowledge construction with the tablet tool, and report the case study.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Kashihara, Akihiro and Shiota, Go},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	note = {00002},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, Multimedia Information Systems, User Interfaces and Human Computer Interaction, knowledge map, pseudo-haptics, tablet media, visual incongruity},
	pages = {61--68}
}

@article{graesser_how_2003,
	title = {How does one know whether a person understands a device? {The} quality of the questions the person asks when the device breaks down.},
	volume = {95},
	issn = {0022-0663},
	shorttitle = {How does one know whether a person understands a device?},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-0663.95.3.524},
	doi = {10.1037/0022-0663.95.3.524},
	language = {en},
	number = {3},
	urldate = {2014-09-30TZ},
	journal = {Journal of Educational Psychology},
	author = {Graesser, Arthur C. and Olde, Brent A.},
	year = {2003},
	note = {00203},
	pages = {524--536}
}

@techreport{kountz_extraktion_2006,
	type = {Studienarbeit},
	title = {Extraktion von {Dependenztripeln} aus der {TIGER}-{Baumbank}},
	number = {54},
	institution = {Universität Stuttgart},
	author = {Kountz, Manuel},
	year = {2006},
	note = {00001 
Studienarbeit Nr. 54}
}

@book{klinger_classical_2007,
	title = {Classical probabilistic models and conditional random fields},
	url = {http://www.scai.fraunhofer.de/fileadmin/images/bio/data_mining/paper/crf_klinger_tomanek.pdf},
	urldate = {2013-08-29TZ},
	publisher = {TU, Algorithm Engineering},
	author = {Klinger, Roman and Tomanek, Katrin},
	year = {2007},
	note = {00087}
}

@misc{noauthor_camus:_nodate,
	title = {Camus: {Das} {Ideal} der {Einfachheit}. {Eine} {Biographie}: {Amazon}.de: {Iris} {Radisch}: {Bücher}},
	url = {http://www.amazon.de/Camus-Ideal-Einfachheit-Eine-Biographie/dp/3499628015/ref=tmm_pap_swatch_0?_encoding=UTF8&sr=&qid=},
	urldate = {2015-05-04TZ},
	note = {00000}
}

@inproceedings{paulheim_discoverability_2013,
	title = {Discoverability of {SPARQL} {Endpoints} in {Linked} {Open} {Data}.},
	url = {http://iswc2013.semanticweb.org/sites/default/files/iswc_poster_17.pdf},
	urldate = {2015-05-04TZ},
	booktitle = {International {Semantic} {Web} {Conference} ({Posters} \& {Demos})},
	author = {Paulheim, Heiko and Hertling, Sven},
	year = {2013},
	note = {00008},
	pages = {245--248}
}

@misc{noauthor_virtuoso_2015,
	title = {Virtuoso {Universal} {Server}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://en.wikipedia.org/w/index.php?title=Virtuoso_Universal_Server&oldid=655236450},
	abstract = {Virtuoso Universal Server is a middleware and database engine hybrid that combines the functionality of a traditional RDBMS, ORDBMS, virtual database, RDF, XML, free-text, web application server and file server functionality in a single system. Rather than have dedicated servers for each of the aforementioned functionality realms, Virtuoso is a "universal server"; it enables a single multithreaded server process that implements multiple protocols. The open source edition of Virtuoso Universal Server is also known as OpenLink Virtuoso. The software has been developed by OpenLink Software with Kingsley Uyi Idehen and Orri Erling as the chief software architects.},
	language = {en},
	urldate = {2015-05-04TZ},
	journal = {Wikipedia, the free encyclopedia},
	month = apr,
	year = {2015},
	note = {00000 
Page Version ID: 655236450}
}

@book{csikszentmihalyi_flow:_1991,
	title = {Flow: {The} psychology of optimal experience},
	volume = {41},
	shorttitle = {Flow},
	url = {http://learn.moodle.net/pluginfile.php/6345/mod_glossary/attachment/893/flow_the_psychology_of_optimal_experience.pdf},
	urldate = {2014-10-01TZ},
	publisher = {HarperPerennial New York},
	author = {Csikszentmihalyi, Mihaly and Csikzentmihaly, Mihaly},
	year = {1991},
	note = {16463}
}

@book{ekman_facial_1978,
	title = {Facial action coding system: {A} technique for the measurement of facial movement. {Palo} {Alto}},
	shorttitle = {Facial action coding system},
	publisher = {CA: Consulting Psychologists Press},
	author = {Ekman, Paul and Friesen, Wallace V.},
	year = {1978},
	note = {00453}
}

@article{mcclelland_parallel_1986,
	title = {Parallel distributed processing},
	volume = {2},
	url = {http://www.researchgate.net/publication/229091444_Explorations_in_Parallel_Distributed_Processing_A_Handbook_of_Models_Programs_and_Exercises/file/60b7d51cad74438a64.pdf},
	urldate = {2014-10-01TZ},
	journal = {Explorations in the microstructure of cognition},
	author = {McClelland, James L. and Rumelhart, David E. and Group, PDP Research and {others}},
	year = {1986},
	note = {14125}
}

@inproceedings{cheng_autotutor_2013,
	title = {{AutoTutor} 2013: {Conversation}-{Based} {Online} {Intelligent} {Tutoring} {System} with {Rich} {Media} ({Interactive} {Event})},
	shorttitle = {{AutoTutor} 2013},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-39112-5_149},
	urldate = {2014-10-01TZ},
	booktitle = {Artificial {Intelligence} in {Education}},
	publisher = {Springer},
	author = {Cheng, Qinyu and Cheng, Keli and Li, Haiying and Cai, Zhiqiang and Hu, Xiangen and Graesser, Art},
	year = {2013},
	note = {00000},
	pages = {930--931}
}

@book{piaget_origins_1952,
	address = {New York,  NY,  US},
	title = {The origins of intelligence in children},
	copyright = {(c) 2012 APA, all rights reserved},
	abstract = {This work, a second edition of which has very kindly been requested, was followed by La Construction du réel chez l'enfant and was to have been completed by a study of the genesis of imitation in the child. The latter piece of research, whose publication we have postponed because it is so closely connected with the analysis of play and representational symbolism, appeared in 1945, inserted in a third work, La formation du symbole chez l'enfant. Together these three works form one entity dedicated to the beginnings of intelligence, that is to say, to the various manifestations of sensorimotor intelligence and to the most elementary forms of expression. The theses developed in this volume, which concern in particular the formation of the sensorimotor schemata and the mechanism of mental assimilation, have given rise to much discussion which pleases us and prompts us to thank both our opponents and our sympathizers for their kind interest in our work.},
	publisher = {W W Norton \& Co},
	author = {Piaget, Jean and Cook, Margaret},
	year = {1952},
	note = {10479},
	keywords = {*Cognitive Development, *Intelligence, Assimilation (Cognitive Process), Childhood Play Development, Imitation (Learning), Nonverbal Communication, Perceptual Motor Development, Symbolism}
}

@article{gerrig_psychologie_2008,
	title = {Psychologie (18. {Aufl}.)},
	journal = {München: Person Studium},
	author = {Gerrig, Richard J. and Zimbardo, Philip G.},
	year = {2008},
	note = {00039}
}

@article{dmello_autotutor_2012,
	title = {{AutoTutor} and affective autotutor: {Learning} by talking with cognitively and emotionally intelligent computers that talk back},
	volume = {2},
	issn = {21606455},
	shorttitle = {{AutoTutor} and affective autotutor},
	url = {http://dl.acm.org/citation.cfm?doid=2395123.2395128},
	doi = {10.1145/2395123.2395128},
	language = {en},
	number = {4},
	urldate = {2014-06-17TZ},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {D'mello, Sidney and Graesser, Art},
	month = dec,
	year = {2012},
	note = {00026},
	pages = {1--39}
}

@misc{noauthor_anna_nodate,
	title = {Anna {Stylianidou} {Research} {Project}},
	url = {http://nccasymposium.bmth.ac.uk/2007/anna_stylianidou/facexpress.html},
	urldate = {2014-09-30TZ},
	note = {00000}
}

@article{martin_influence_2003,
	title = {The influence of gender on mood effects in advertising},
	volume = {20},
	issn = {0742-6046, 1520-6793},
	url = {http://doi.wiley.com/10.1002/mar.10070},
	doi = {10.1002/mar.10070},
	language = {en},
	number = {3},
	urldate = {2014-09-30TZ},
	journal = {Psychology and Marketing},
	author = {Martin, Brett A. S.},
	month = mar,
	year = {2003},
	note = {00057},
	pages = {249--273}
}

@book{meyer_einfuhrung_2001,
	address = {Bern etc.},
	edition = {Auflage: 2., überarb. Aufl.},
	title = {Einführung in die {Emotionspsychologie}, {Bd}.1, {Die} {Emotionstheorien} von {Watson}, {James} und {Schachter}},
	isbn = {9783456836485},
	abstract = {Für die Neuauflage wurde der Band I der nun dreibändigen «Einführung in die Emotionspsychologie» vollständig überarbeitet. Im Gegensatz zu den vorhandenen deutschsprachigen Lehrbüchern zur Emotionspsychologie ist diese Einführung explizit theorieorientiert. Der Text wurde so gestaltet, dass er einerseits grundlegend genug ist, um auch für Anfänger verständlich zu sein, andererseits aber auch präzise genug, um Leserinnen und Leser auf die selbständige Lektüre der Fachliteratur vorzubereiten. Im einführenden Kapitel werden grundlegende Begriffe und Konzepte der Emotionspsychologie erläutert. In den drei nachfolgenden Kapiteln werden die klassisch-behavioristische Theorie der Emotionen und ihre Nachwirkungen (Kapitel 2), die Emotionstheorie von William James und neo-jamesianische Emotionstheorien (Kapitel 3) sowie kognitiv-physiologische Theorien der Emotionen (Kapitel 4) behandelt. In jedem Kapitel werden die neuesten einschlägigen Forschungsergebnisse berücksichtigt. Darüber schlagen die Autoren Brücken zur Klinischen Psychologie.},
	language = {Deutsch},
	publisher = {Huber, Bern},
	author = {Meyer, Wulf-Uwe and Reisenzein, Rainer and Schützwohl, Achim},
	month = sep,
	year = {2001},
	note = {00000}
}

@inproceedings{dmello_modeling_2007,
	title = {Modeling and {Scaffolding} {Affective} {Experiences} to {Impact} {Learning}},
	url = {http://www.researchgate.net/publication/221297651_Modeling_and_Scaffolding_Affective_Experiences_to_Impact_Learning/file/d912f50d0ba76d67d8.pdf#page=3},
	urldate = {2014-09-30TZ},
	booktitle = {{WORKSHOP} {ON} {MODELING} {AND} {SCAFFOLDING} {AFFECTIVE} {EXPERIENCES} {TO} {IMPACT} {LEARNING}},
	author = {D’MELLO, Sidney and Craig, Scotty and El Kaliouby, Rana and Alsmeyer, Madeline and Rebolledo-Mendez, Genaro},
	year = {2007},
	note = {00000}
}

@inproceedings{arroyo_emotion_2009,
	title = {Emotion {Sensors} {Go} {To} {School}.},
	volume = {200},
	url = {http://centerforknowledgecommunication.com/publications/recentPubsandAwards/2009/AIED%20SENSORS%20CameraReady.pdf},
	urldate = {2014-06-17TZ},
	booktitle = {{AIED}},
	author = {Arroyo, Ivon and Cooper, David G. and Burleson, Winslow and Woolf, Beverly Park and Muldner, Kasia and Christopherson, Robert},
	year = {2009},
	note = {00169},
	pages = {17--24}
}
@article{moreno_case_2001,
	title = {The case for social agency in computer-based teaching: {Do} students learn more deeply when they interact with animated pedagogical agents?},
	volume = {19},
	shorttitle = {The case for social agency in computer-based teaching},
	url = {http://www.tandfonline.com/doi/abs/10.1207/S1532690XCI1902_02},
	number = {2},
	urldate = {2014-09-29TZ},
	journal = {Cognition and Instruction},
	author = {Moreno, Roxana and Mayer, Richard E. and Spires, Hiller A. and Lester, James C.},
	year = {2001},
	pages = {177--213}
}

@incollection{girotto_tool_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Tool} for {Integrating} {Log} and {Video} {Data} for {Exploratory} {Analysis} and {Model} {Generation}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07220-3, 978-3-319-07221-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_9},
	abstract = {Analysis of students’ log data to understand their process as they solve problems is an essential part of educational technology research. Models of correct and buggy student behavior can be generated from this log data and used as a basis for intelligent feedback. Another important technique for understanding problem-solving process is video protocol analysis, but historically, this has not been well integrated with log data. In this paper, we describe a tool to 1) facilitate the annotation of log data with information from video data, and 2) automatically generate models of student problem-solving process that include both video and log data. We demonstrate the utility of the tool with analysis of student use of a teachable robot system for geometry.},
	language = {en},
	number = {8474},
	urldate = {2014-09-29TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Girotto, Victor and Thomas, Elissa and Lozano, Cecil and Muldner, Kasia and Burleson, Winslow and Walker, Erin},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	month = jan,
	year = {2014},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Document Preparation and Text Processing, Multimedia Information Systems, User Interfaces and Human Computer Interaction, cognitive modeling, intelligent tutor, log analysis tool},
	pages = {69--74}
}

@article{wenger_artificial_1987,
	title = {Artificial intelligence and tutoring systems},
	url = {http://www.info2.uqam.ca/~nkambou/DIC9340/seances/seance2-3-4-5/Ontology/IJAIED2004.pdf},
	urldate = {2014-09-29TZ},
	author = {Wenger, Etienne},
	year = {1987}
}

@article{steenbergen-hu_meta-analysis_2013,
	title = {A meta-analysis of the effectiveness of intelligent tutoring systems on {K}–12 students’ mathematical learning},
	volume = {105},
	copyright = {(c) 2013 APA, all rights reserved},
	issn = {1939-2176(Electronic);0022-0663(Print)},
	doi = {10.1037/a0032447},
	abstract = {In this study, we meta-analyzed empirical research of the effectiveness of intelligent tutoring systems (ITS) on K–12 students’ mathematical learning. A total of 26 reports containing 34 independent samples met study inclusion criteria. The reports appeared between 1997 and 2010. The majority of included studies compared the effectiveness of ITS with that of regular classroom instruction. A few studies compared ITS with human tutoring or homework practices. Among the major findings are (a) overall, ITS had no negative and perhaps a small positive effect on K–12 students’ mathematical learning, as indicated by the average effect sizes ranging from g = 0.01 to g = 0.09, and (b) on the basis of the few studies that compared ITS with homework or human tutoring, the effectiveness of ITS appeared to be small to modest. Moderator analyses revealed 2 findings of practical importance. First, the effects of ITS appeared to be greater when the interventions lasted for less than a school year than when they lasted for 1 school year or longer. Second, the effectiveness of ITS for helping students drawn from the general population was greater than for helping low achievers. This finding draws attentions to the issue of whether computerized learning might contribute to the achievement gap between students with different achievement levels and aptitudes.},
	number = {4},
	journal = {Journal of Educational Psychology},
	author = {Steenbergen-Hu, Saiying and Cooper, Harris},
	year = {2013},
	keywords = {*Academic Achievement, *Intelligent Tutoring Systems, *Learning, *Mathematics Education, Tutoring},
	pages = {970--987}
}

@inproceedings{baker_berkeley_1998,
	title = {The berkeley framenet project},
	url = {http://dl.acm.org/citation.cfm?id=980860},
	urldate = {2014-03-26TZ},
	booktitle = {Proceedings of the 36th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and 17th {International} {Conference} on {Computational} {Linguistics}-{Volume} 1},
	publisher = {Association for Computational Linguistics},
	author = {Baker, Collin F. and Fillmore, Charles J. and Lowe, John B.},
	year = {1998},
	pages = {86--90}
}

@inproceedings{rehbein_adding_2012,
	title = {Adding nominal spice to {SALSA}-frame-semantic annotation of {German} nouns and verbs},
	url = {http://www.academia.edu/download/30881859/proceedings.pdf#page=89},
	urldate = {2014-03-25TZ},
	booktitle = {Proceedings of the 11th {Conference} on {Natural} {Language} {Processing} ({KONVENS}’12)},
	author = {Rehbein, Ines and Ruppenhofer, Joseph and Sporleder, Caroline and Pinkal, Manfred},
	year = {2012},
	pages = {89--97}
}

@misc{noauthor_freebase_nodate,
	title = {Freebase},
	url = {http://www.freebase.com},
	urldate = {2013-07-29TZ}
}

@techreport{de_marneffe_stanford_2008,
	address = {Stanford University},
	title = {Stanford typed dependencies manual},
	url = {http://nlp.stanford.edu/downloads/dependencies_manual.pdf},
	urldate = {2013-07-30TZ},
	author = {De Marneffe, Marie-Catherine and Manning, Christopher D.},
	year = {2008}
}

@article{nadeau_survey_2007,
	title = {A survey of named entity recognition and classification},
	volume = {30},
	url = {http://www.ingentaconnect.com/content/jbp/li/2007/00000030/00000001/art00002},
	number = {1},
	urldate = {2013-09-04TZ},
	journal = {Lingvisticae Investigationes},
	author = {Nadeau, David and Sekine, Satoshi},
	year = {2007},
	pages = {3--26}
}

@book{joel_ctrl_2013,
	title = {Ctrl alt delete: reboot your business. reboot your life. your future depends on it},
	isbn = {9781455523306  1455523305},
	shorttitle = {Ctrl alt delete},
	language = {English},
	publisher = {Business Plus},
	author = {Joel, Mitch},
	year = {2013}
}
@article{buchholz_system_1953,
	title = {The {System} {Design} of the {IBM} {Type} 701 {Computer}},
	volume = {41},
	issn = {0096-8390},
	doi = {10.1109/JRPROC.1953.274300},
	abstract = {In designing any new piece of equipment a choice has to be made from a number of alternatives. Rather than just enumerating the features incorporated in the IBM Type 701 Computer, an attempt is made to record the reasons for their choice. Emphasis is given to the features which are believed to be new. These include improved arithmetic and logical facilities, as well as the methods developed for controlling the extensive input and output equipment directly from the stored program.},
	number = {10},
	journal = {Proceedings of the IRE},
	author = {Buchholz, W.},
	year = {1953},
	keywords = {Appraisal, Arithmetic, Buildings, Centralized control, Concurrent computing, Data engineering, Design engineering, Large-scale systems, Logic, Writing},
	pages = {1262--1275}
}

@article{wolpert_stacked_1992,
	title = {Stacked generalization},
	volume = {5},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608005800231},
	number = {2},
	urldate = {2013-07-26TZ},
	journal = {Neural networks},
	author = {Wolpert, David H.},
	year = {1992},
	pages = {241--259}
}

@inproceedings{yao_structured_2011,
	title = {Structured relation discovery using generative models},
	url = {http://dl.acm.org/citation.cfm?id=2145587},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Yao, Limin and Haghighi, Aria and Riedel, Sebastian and McCallum, Andrew},
	year = {2011},
	pages = {1456--1466}
}

@article{theobald_10_2013,
	title = {10 years of probabilistic querying-what next?},
	url = {https://lirias.kuleuven.be/handle/123456789/403578},
	urldate = {2013-07-26TZ},
	journal = {Lecture Notes in Computer Science},
	author = {Theobald, Martin and De Raedt, Luc and Dylla, Maximilian and Kimmig, Angelika and Miliaraki, Iris},
	year = {2013}
}

@inproceedings{riedel_relation_2013,
	title = {Relation {Extraction} with {Matrix} {Factorization} and {Universal} {Schemas}},
	url = {http://www.newdesign.aclweb.org/anthology-new/N/N13/N13-1008.pdf},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of {NAACL}-{HLT}},
	author = {Riedel, Sebastian and Yao, Limin and McCallum, Andrew and Marlin, Benjamin M.},
	year = {2013},
	pages = {74--84}
}

@inproceedings{ritter_latent_2010,
	title = {A latent dirichlet allocation method for selectional preferences},
	url = {http://dl.acm.org/citation.cfm?id=1858725},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the 48th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	author = {Ritter, Alan and Etzioni, Oren},
	year = {2010},
	pages = {424--434}
}

@inproceedings{mcdonald_non-projective_2005,
	title = {Non-projective dependency parsing using spanning tree algorithms},
	url = {http://dl.acm.org/citation.cfm?id=1220641},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the conference on {Human} {Language} {Technology} and {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {McDonald, Ryan and Pereira, Fernando and Ribarov, Kiril and Haji{\textbackslash}vc, Jan},
	year = {2005},
	pages = {523--530}
}

@inproceedings{mintz_distant_2009,
	title = {Distant supervision for relation extraction without labeled data},
	url = {http://dl.acm.org/citation.cfm?id=1690287},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the {Joint} {Conference} of the 47th {Annual} {Meeting} of the {ACL} and the 4th {International} {Joint} {Conference} on {Natural} {Language} {Processing} of the {AFNLP}: {Volume} 2-{Volume} 2},
	author = {Mintz, Mike and Bills, Steven and Snow, Rion and Jurafsky, Dan},
	year = {2009},
	pages = {1003--1011}
}

@article{gildea_automatic_2002,
	title = {Automatic labeling of semantic roles},
	volume = {28},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/089120102760275983},
	number = {3},
	urldate = {2013-07-26TZ},
	journal = {Computational linguistics},
	author = {Gildea, Daniel and Jurafsky, Daniel},
	year = {2002},
	pages = {245--288}
}

@article{marquez_semantic_2008,
	title = {Semantic role labeling: an introduction to the special issue},
	volume = {34},
	shorttitle = {Semantic role labeling},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/coli.2008.34.2.145},
	number = {2},
	urldate = {2013-07-26TZ},
	journal = {Computational linguistics},
	author = {Màrquez, Lluís and Carreras, Xavier and Litkowski, Kenneth C. and Stevenson, Suzanne},
	year = {2008},
	pages = {145--159}
}

@inproceedings{che_multilingual_2009,
	title = {Multilingual dependency-based syntactic and semantic parsing},
	url = {http://dl.acm.org/citation.cfm?id=1596417},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the {Thirteenth} {Conference} on {Computational} {Natural} {Language} {Learning}: {Shared} {Task}},
	author = {Che, Wanxiang and Li, Zhenghua and Li, Yongqiang and Guo, Yuhang and Qin, Bing and Liu, Ting},
	year = {2009},
	pages = {49--54}
}

@inproceedings{akbik_kraken:_2012,
	title = {Kraken: {N}-ary facts in open information extraction},
	shorttitle = {Kraken},
	url = {http://dl.acm.org/citation.cfm?id=2391210},
	urldate = {2013-07-26TZ},
	booktitle = {Proceedings of the {Joint} {Workshop} on {Automatic} {Knowledge} {Base} {Construction} and {Web}-scale {Knowledge} {Extraction}},
	author = {Akbik, Alan and Löser, Alexander},
	year = {2012},
	pages = {52--56}
}

@misc{noauthor_maximum-likelihood-methode_2013,
	title = {Maximum-{Likelihood}-{Methode}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://de.wikipedia.org/w/index.php?title=Maximum-Likelihood-Methode&oldid=114948262},
	abstract = {Die Maximum-Likelihood-Methode (von engl. maximale Wahrscheinlichkeit) bezeichnet in der Statistik ein parametrisches Schätzverfahren. Dabei wird vereinfacht so vorgegangen, dass derjenige Parameter als Schätzung ausgewählt wird, gemäß dessen Verteilung die Realisierung der beobachteten Daten am plausibelsten erscheint.},
	language = {de},
	urldate = {2013-03-05TZ},
	journal = {Wikipedia},
	month = mar,
	year = {2013},
	note = {Page Version ID: 114948262}
}

@article{leising_toronto_2009,
	title = {The {Toronto} {Alexithymia} {Scale} ({TAS}-20): {A} measure of general psychological distress},
	volume = {43},
	issn = {0092-6566},
	shorttitle = {The {Toronto} {Alexithymia} {Scale} ({TAS}-20)},
	url = {http://www.sciencedirect.com/science/article/pii/S0092656609000828},
	doi = {10.1016/j.jrp.2009.03.009},
	abstract = {The Toronto Alexithymia Scale (Bagby, R. M., Parker, J. D. A., \&amp; Taylor, G. J. (1994). The twenty-item Toronto Alexithymia Scale-I. Item selection and cross-validation of the factor structure. Journal of Psychosomatic Research, 38, 23–32.) is the most commonly used measure of Alexithymia (= difficulties identifying and describing one’s own feelings). Sixty-three persons (34 psychiatric inpatients, 29 healthy controls) first filled in the TAS-20 and were then interviewed about their interpersonal relationships. Two raters coded the emotional experiences that the participants reported during these interviews. Contrary to expectations, participants with higher TAS-20 scores reported more emotions (particularly negative ones), and more different emotions, questioning the validity of the TAS-20 as a measure of Alexithymia. Based on correlation patterns and a joint factor analysis with two well-established measures of psychopathology, it is concluded that the TAS-20 assesses a general psychological distress factor.},
	number = {4},
	urldate = {2013-03-04TZ},
	journal = {Journal of Research in Personality},
	author = {Leising, Daniel and Grande, Tilman and Faber, Rainer},
	month = aug,
	year = {2009},
	keywords = {Alexithymia, Emotions, Experience, Expressivity, Rating, TAS-20, Validity},
	pages = {707--710}
}