
@book{borries_computerunterstutzung_1997,
  langid = {german},
  title = {Computerunterstützung der Argumentation in Gruppen: Aufbereitung einer Sprechaktsequenz nach Habermas und Vorstellung eines Prototypen},
  isbn = {978-3-322-90283-2},
  url = {https://books.google.de/books?id=oYmkBwAAQBAJ&pg=PA199&lpg=PA199&dq=modellierung+der+argumentation&source=bl&ots=XGWQLpVn6e&sig=ZlceXp9YX2DB9bYCvlZ6VUowx3c&hl=de&sa=X&ei=gHRjVbOJO8GwsQGlqYGwDA&ved=0CE0Q6AEwCTgK#v=onepage&q=modellierung%20der%20argumentation&f=false},
  shorttitle = {Computerunterstützung der Argumentation in Gruppen},
  abstract = {Der Autor gibt einen Überblick über die wesentlichen Bereiche der Argumentationsforschung und über Computersysteme, die die Argumentation in Gruppen unterstützen. Die Erkenntnisse fließen in ein neues System zur Förderung von herrschaftsfreier Argumentation, Verhandlung und Problemlösung in Gruppen.},
  publisher = {{Springer-Verlag}},
  date = {1997},
  keywords = {Business & Economics / General},
  author = {Börries, Ludwig}
}

@book{csikszentmihalyi_flow_1991,
  title = {Flow: {{The}} Psychology of Optimal Experience},
  volume = {41},
  url = {http://learn.moodle.net/pluginfile.php/6345/mod_glossary/attachment/893/flow_the_psychology_of_optimal_experience.pdf},
  shorttitle = {Flow},
  publisher = {{HarperPerennial New York}},
  urldate = {2014-10-01},
  date = {1991},
  author = {Csikszentmihalyi, Mihaly and Csikzentmihaly, Mihaly},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/NVB7749D/Csikszentmihalyi und Csikzentmihaly - 1991 - Flow The psychology of optimal experience.pdf},
  note = {16463}
}

@book{klinger_classical_2007,
  title = {Classical Probabilistic Models and Conditional Random Fields},
  url = {http://www.scai.fraunhofer.de/fileadmin/images/bio/data_mining/paper/crf_klinger_tomanek.pdf},
  publisher = {{TU, Algorithm Engineering}},
  urldate = {2013-08-29},
  date = {2007},
  author = {Klinger, Roman and Tomanek, Katrin},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FRTKI5VW/crf_klinger_tomanek.pdf},
  note = {00087}
}

@report{kountz_extraktion_2006,
  title = {Extraktion von {{Dependenztripeln}} Aus Der {{TIGER}}-{{Baumbank}}},
  number = {54},
  institution = {{Universität Stuttgart}},
  type = {Studienarbeit},
  date = {2006},
  author = {Kountz, Manuel},
  file = {C:\\Users\\Arne\\Documents\\Studium\\11. Semester\\ComputergestÃ¼tzte Analyse von Sprache\\korpora\\TIGER-DepTriples\\doc\\tiger-deptrip.pdf},
  note = {00001 
Studienarbeit Nr. 54}
}

@article{graesser_how_2003,
  langid = {english},
  title = {How Does One Know Whether a Person Understands a Device? {{The}} Quality of the Questions the Person Asks When the Device Breaks Down.},
  volume = {95},
  issn = {0022-0663},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-0663.95.3.524},
  doi = {10.1037/0022-0663.95.3.524},
  shorttitle = {How Does One Know Whether a Person Understands a Device?},
  number = {3},
  journaltitle = {Journal of Educational Psychology},
  urldate = {2014-09-30},
  date = {2003},
  pages = {524-536},
  author = {Graesser, Arthur C. and Olde, Brent A.},
  note = {00203}
}

@incollection{kashihara_knowledge_2014,
  langid = {english},
  title = {Knowledge {{Construction}} with {{Pseudo}}-Haptics},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_8},
  abstract = {Composing a knowledge map to represent knowledge included in an instructional material is an effective way to understand the material. We currently attempt to utilize tablet media for the knowledge map composition, which allows touch operations with fingers. In particular, we address the issues of how the touch operations could be accompanied with pseudo-haptic senses and whether these senses could produce better cognitive awareness and retention of knowledge learned from the material. Our approach to these issues is to design a model of pseudo-haptic effects that demonstrates what and how cognitive awareness is obtained from pseudo-haptic senses, and to develop a tablet tool on iPad presenting the pseudo-haptic senses as modeled. In this paper, we discuss knowledge construction with the tablet tool, and report the case study.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {61-68},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,Multimedia Information Systems,User Interfaces and Human Computer Interaction,knowledge map,pseudo-haptics,tablet media,visual incongruity},
  author = {Kashihara, Akihiro and Shiota, Go},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BB7MGU5Q/978-3-319-07221-0_8.html},
  note = {00002}
}

@article{lu_pubmed_2011,
  title = {{{PubMed}} and beyond: A Survey of Web Tools for Searching Biomedical Literature},
  volume = {2011},
  issn = {1758-0463},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025693/},
  doi = {10.1093/database/baq036},
  shorttitle = {{{PubMed}} and Beyond},
  abstract = {The past decade has witnessed the modern advances of high-throughput technology and rapid growth of research capacity in producing large-scale biological data, both of which were concomitant with an exponential growth of biomedical literature. This wealth of scholarly knowledge is of significant importance for researchers in making scientific discoveries and healthcare professionals in managing health-related matters. However, the acquisition of such information is becoming increasingly difficult due to its large volume and rapid growth. In response, the National Center for Biotechnology Information (NCBI) is continuously making changes to its PubMed Web service for improvement. Meanwhile, different entities have devoted themselves to developing Web tools for helping users quickly and efficiently search and retrieve relevant publications. These practices, together with maturity in the field of text mining, have led to an increase in the number and quality of various Web tools that provide comparable literature search service to PubMed. In this study, we review 28 such tools, highlight their respective innovations, compare them to the PubMed system and one another, and discuss directions for future development. Furthermore, we have built a website dedicated to tracking existing systems and future advances in the field of biomedical literature search. Taken together, our work serves information seekers in choosing tools for their needs and service providers and developers in keeping current in the field., Database URL: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/search},
  journaltitle = {Database: The Journal of Biological Databases and Curation},
  shortjournal = {Database (Oxford)},
  urldate = {2013-09-05},
  date = {2011-01-17},
  author = {Lu, Zhiyong},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Q3UZST93/Lu - 2011 - PubMed and beyond a survey of web tools for searc.pdf},
  eprinttype = {pmid},
  eprint = {21245076},
  pmcid = {PMC3025693},
  note = {00203}
}

@inproceedings{dmello_autotutor_2008,
  title = {{{AutoTutor}} Detects and Responds to Learners Affective and Cognitive States},
  url = {http://141.225.218.248/web-cslwebroot/emotion/files/dmello-affectwkshp-its08.pdf},
  abstract = {This paper provides a synthesis of
our research towards the devel-
opment of an affect-sensitive Intelligen
t Tutoring System called AutoTutor.
The affect-sensitive AutoTutor detects the emotions (boredom,
flow/engagement, confusion,
frustration) of a learner by monitoring conversational cues, gross body language, and facial features. It is also mindful of the learners’ affective and cognitive states in selecting its pedagogical and motivational dialogue moves. Finally, the
AutoTutor embodied pedagogical agent synthesizes affective responses through
animated facial expressions and modulated speech. The paper provides an overview of our theoretical framework, methodology, implementation details, and results.
disequilibrium
attribution theory},
  booktitle = {Workshop on {{Emotional}} and {{Cognitive Issues}} at the {{International Conference}} on {{Intelligent Tutoring Systems}}},
  urldate = {2014-06-17},
  date = {2008},
  author = {D’Mello, Sidney and Jackson, Tanner and Craig, Scotty and Morgan, Brent and Chipman, Patrick and White, Holly and Person, Natalie and Kort, Barry and el Kaliouby, Rana and Picard, Rosalind and {others}},
  options = {useprefix=true},
  note = {00093}
}

@inproceedings{ashley_toward_2013,
  location = {{New York, NY, USA}},
  title = {Toward {{Constructing Evidence}}-Based {{Legal Arguments Using Legal Decision Documents}} and {{Machine Learning}}},
  isbn = {978-1-4503-2080-1},
  url = {http://doi.acm.org/10.1145/2514601.2514622},
  doi = {10.1145/2514601.2514622},
  abstract = {This paper explores how to extract argumentation-relevant information automatically from a corpus of legal decision documents, and how to build new arguments using that information. For decision texts, we use the Vaccine/Injury Project (V/IP) Corpus, which contains default-logic annotations of argument structure. We supplement this with presuppositional annotations about entities, events, and relations that play important roles in argumentation, and about the level of confidence that arguments would be successful. We then propose how to integrate these semantic-pragmatic annotations with syntactic and domain-general semantic annotations, such as those generated in the DeepQA architecture, and outline how to apply machine learning and scoring techniques similar to those used in the IBM Watson system for playing the Jeopardy! question-answer game. We replace this game-playing goal, however, with the goal of learning to construct legal arguments.},
  booktitle = {Proceedings of the {{Fourteenth International Conference}} on {{Artificial Intelligence}} and {{Law}}},
  series = {ICAIL '13},
  publisher = {{ACM}},
  date = {2013},
  pages = {176--180},
  keywords = {DeepQA,IBM Watson,default-logic framework,legal argumentation,presuppositional annotation,text annotation},
  author = {Ashley, Kevin D. and Walker, Vern R.}
}

@inproceedings{meyers_nombank_2004,
  title = {The {{NomBank}} Project: {{An}} Interim Report},
  url = {http://acl.ldc.upenn.edu/hlt-naacl2004/frontiers/pdf/nombank-pap.pdf},
  shorttitle = {The {{NomBank}} Project},
  booktitle = {{{HLT}}-{{NAACL}} 2004 Workshop: {{Frontiers}} in Corpus Annotation},
  urldate = {2013-07-29},
  date = {2004},
  pages = {24--31},
  author = {Meyers, Adam and Reeves, Ruth and Macleod, Catherine and Szekely, Rachel and Zielinska, Veronika and Young, Brian and Grishman, Ralph},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XSDC8P6S/nombank-pap.pdf},
  note = {00253}
}

@incollection{bosch_its_2014,
  langid = {english},
  title = {It’s {{Written}} on {{Your Face}}: {{Detecting Affective States}} from {{Facial Expressions}} While {{Learning Computer Programming}}},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_5},
  shorttitle = {It’s {{Written}} on {{Your Face}}},
  abstract = {We built detectors capable of automatically recognizing affective states of novice computer programmers from student-annotated videos of their faces recorded during an introductory programming tutoring session. We used the Computer Expression Recognition Toolbox (CERT) to track facial features based on the Facial Action Coding System, and machine learning techniques to build classification models. Confusion/Uncertainty and Frustration were distinguished from all other affective states in a student-independent fashion at levels above chance (Cohen’s kappa = .22 and .23, respectively), but detection accuracies for Boredom, Flow/Engagement, and Neutral were lower (kappas = .04, .11, and .07). We discuss the differences between detection of spontaneous versus fixed (polled) judgments as well as the features used in the models.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {39-44},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,Multimedia Information Systems,User Interfaces and Human Computer Interaction},
  author = {Bosch, Nigel and Chen, Yuxuan and D’Mello, Sidney},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/8HHJ5F2T/978-3-319-07221-0_5.html},
  note = {00014}
}

@thesis{banko_open_2009,
  title = {Open Information Extraction for the Web},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.212.5142&rep=rep1&type=pdf},
  institution = {{Washington}},
  urldate = {2013-07-26},
  date = {2009},
  author = {Banko, Michele},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GC7USDC7/10.1.1.212.5142_Open Information Extraction for the Web.pdf},
  note = {00000}
}

@inproceedings{mao_extracting_2014,
  location = {{Baltimore, Maryland}},
  title = {Extracting {{Imperatives}} from {{Wikipedia Article}} for {{Deletion Discussions}}},
  url = {http://www.aclweb.org/anthology/W14-2117},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {106--107},
  author = {Mao, Fiona and Mercer, Robert and Xiao, Lu}
}

@book{weiner_attributional_1986,
  title = {An Attributional Theory of Motivation and Emotion},
  publisher = {{Springer-Verlag New York}},
  date = {1986},
  author = {Weiner, Bernard},
  note = {06738}
}

@inproceedings{abbott_internet_????,
  langid = {english},
  location = {{Paris, France}},
  title = {Internet {{Argument Corpus}} 2.0: {{An SQL}} Schema for {{Dialogic Social Media}} and the {{Corpora}} to Go with It},
  isbn = {978-2-9517408-9-1},
  url = {http://www.lrec-conf.org/proceedings/lrec2016/summaries/1126.html},
  booktitle = {Proceedings of the {{Tenth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}} 2016)},
  publisher = {{European Language Resources Association (ELRA)}},
  author = {Abbott, Rob and Ecker, Brian and Anand, Pranav and Walker, Marilyn},
  editor = {Chair), Nicoletta Calzolari (Conference and Choukri, Khalid and Declerck, Thierry and Grobelnik, Marko and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios}
}

@article{poole_exponential_2016,
  title = {Exponential Expressivity in Deep Neural Networks through Transient Chaos},
  url = {https://arxiv.org/abs/1606.05340},
  journaltitle = {arXiv preprint arXiv:1606.05340},
  urldate = {2016-10-25},
  date = {2016},
  author = {Poole, Ben and Lahiri, Subhaneil and Raghu, Maithra and Sohl-Dickstein, Jascha and Ganguli, Surya},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/QGMH6GAM/1606.05340v2.pdf}
}

@unpublished{mochales_palau_automatic_2007,
  title = {Automatic Detection of Arguments in Legal Texts},
  url = {https://lirias.kuleuven.be/handle/123456789/146821},
  date = {2007},
  author = {Mochales Palau, Raquel and Moens, Marie-Francine},
  note = {19th Belgian-Dutch Conference on Artificial Intelligence, Utrecht, The Netherlands, November 5-6, 2007}
}

@article{turner_importance_2002,
  title = {The {{Importance}} of {{Students}}' {{Goals}} in {{Their Emotional Experience}} of {{Academic Failure}}: {{Investigating}} the {{Precursors}} and {{Consequences}} of {{Shame}}},
  volume = {37},
  issn = {0046-1520},
  url = {http://dx.doi.org/10.1207/S15326985EP3702_3},
  doi = {10.1207/S15326985EP3702_3},
  shorttitle = {The {{Importance}} of {{Students}}' {{Goals}} in {{Their Emotional Experience}} of {{Academic Failure}}},
  abstract = {This article uses the emotion of shame as an example for exploring relations of students' goals and emotions. Using the framework of self-regulation and motivation, the article discusses the precursors and consequences of this potentially devastating emotion. The research suggests that motivational and goal-related processes may be associated with triggering a shame reaction, but that they also can contribute to shame resiliency. Specifically, the article argues that having clear, important future goals-for which the course grade or course information is instrumentally connected-particularly facilitates students' recovery from a shame reaction. The article concludes, however, that having future goals that supply motivating power for students to engage in learning activities is not sufficient to bring about shame recovery. For students to obtain their future academic goals, they must have a repertoire of study strategies and volitional strategies as well as self-monitoring strategies, metacognitive strategies, and self-regulation that will facilitate the acquisition of immediate learning goals.},
  number = {2},
  journaltitle = {Educational Psychologist},
  urldate = {2014-09-30},
  date = {2002-06-01},
  pages = {79-89},
  author = {Turner, Jeannine E. and Husman, Jenefer and Schallert, Diane L.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/QKP5KGEG/S15326985EP3702_3.html},
  note = {00126}
}

@article{houy_konzeption_2015,
  langid = {german},
  title = {Konzeption und Implementierung eines Werkzeuges zur automatisierten Identifikation und Analyse von Argumentationsstrukturen anhand der Entscheidungen des Bundesverfassungsgerichts im Digital-Humanities-Projekt ARGUMENTUM},
  volume = {15},
  issn = {1618-2162, 1610-1995},
  url = {http://link.springer.com/10.1007/s13222-014-0175-9},
  doi = {10.1007/s13222-014-0175-9},
  number = {1},
  journaltitle = {Datenbank-Spektrum},
  urldate = {2016-07-14},
  date = {2015-03},
  pages = {15-23},
  author = {Houy, Constantin and Niesen, Tim and Calvillo, Jesús and Fettke, Peter and Loos, Peter and Krämer, Annika and Schmidt, Klaas and Herberger, Maximilian and Speiser, Iris and Gass, Alfred and Schneider, Luc and Philippi, Tim},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/AQ98THDM/art%3A10.1007%2Fs13222-014-0175-9.pdf},
  note = {00003}
}

@article{reed_neural_2015,
  title = {Neural Programmer-Interpreters},
  url = {http://arxiv.org/abs/1511.06279},
  journaltitle = {arXiv preprint arXiv:1511.06279},
  urldate = {2016-10-25},
  date = {2015},
  author = {Reed, Scott and de Freitas, Nando},
  options = {useprefix=true},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/TH7QUAIG/1511.06279v4.pdf}
}

@article{sheehan_formal_2010,
  title = {Formal and Functional Approaches to Disharmonic Word Orders},
  url = {http://www.ncl.ac.uk/linguistics/assets/documents/SHEEHAN.pdf},
  journaltitle = {Newcastle Working Papers in Linguistics},
  urldate = {2016-07-22},
  date = {2010},
  pages = {146},
  author = {Sheehan, Michelle},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DF8Z6GBA/SHEEHAN.pdf},
  note = {00003}
}

@article{schneider_review_2013,
  title = {A {{Review}} of {{Argumentation}} for the {{Social Semantic Web}}},
  volume = {4},
  issn = {1570-0844},
  url = {http://dl.acm.org/citation.cfm?id=2590215.2590218},
  abstract = {Argumentation represents the study of views and opinions that humans express with the goal of reaching a conclusion through logical reasoning. Since the 1950's, several models have been proposed to capture the essence of informal argumentation in different settings. With the emergence of the Web, and then the Semantic Web, this modeling shifted towards ontologies, while from the development perspective, we witnessed an important increase in Web 2.0 human-centered collaborative deliberation tools. Through a review of more than 150 scholarly papers, this article provides a comprehensive and comparative overview of approaches to modeling argumentation for the Social Semantic Web. We start from theoretical foundational models and investigate how they have influenced Social Web tools. We also look into Semantic Web argumentation models. Finally we end with Social Web tools for argumentation, including online applications combining Web 2.0 and Semantic Web technologies, following the path to a global World Wide Argument Web.},
  number = {2},
  journaltitle = {Semant. web},
  date = {2013-04},
  pages = {159--218},
  keywords = {Argumentation,Ontologies,Semantic Web,Social Web},
  author = {Schneider, Jodi and Groza, Tudor and Passant, Alexandre}
}

@inproceedings{houy_argumentumtowards_2012,
  title = {{{ARGUMENTUM}}–{{Towards}} Computer-Supported Analysis, Retrieval and Synthesis of Argumentation Structures in Humanities Using the Example of Jurisprudence},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.401.5714&rep=rep1&type=pdf},
  booktitle = {Poster and {{Demo Track}} of the 35th {{German Conference}} on {{Artificial Intelligence}} ({{KI}} 2012), {{Saarbrücken}}, {{Germany}}},
  publisher = {{Citeseer}},
  urldate = {2016-07-14},
  date = {2012},
  author = {Houy, Constantin and Fettke, Peter and Loos, Peter and Speiser, Iris and Herberger, Maximilian and Gass, Alfred and Nortmann, Ulrich},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BPGTSDSV/ki2012pd07.pdf},
  note = {00004}
}

@book{jackendoff_semantics_1985,
  langid = {english},
  location = {{Cambridge, Mass.}},
  title = {Semantics and Cognition},
  isbn = {0-262-10027-4 978-0-262-10027-4 0-262-60013-7 978-0-262-60013-2},
  publisher = {{MIT Press}},
  date = {1985},
  author = {Jackendoff, Ray},
  note = {04970}
}

@inproceedings{khoo_extracting_2000,
  location = {{Stroudsburg, PA, USA}},
  title = {Extracting {{Causal Knowledge}} from a {{Medical Database Using Graphical Patterns}}},
  url = {http://dx.doi.org/10.3115/1075218.1075261},
  doi = {10.3115/1075218.1075261},
  abstract = {This paper reports the first part of a project that aims to develop a knowledge extraction and knowledge discovery system that extracts causal knowledge from textual databases. In this initial study, we develop a method to identify and extract cause-effect information that is explicitly expressed in medical abstracts in the Medline database. A set of graphical patterns were constructed that indicate the presence of a causal relation in sentences, and which part of the sentence represents the cause and which part represents the effect. The patterns are matched with the syntactic parse trees of sentences, and the parts of the parse tree that match with the slots in the patterns are extracted as the cause or the effect.},
  booktitle = {Proceedings of the 38th {{Annual Meeting}} on {{Association}} for {{Computational Linguistics}}},
  series = {ACL '00},
  publisher = {{Association for Computational Linguistics}},
  date = {2000},
  pages = {336--343},
  author = {Khoo, Christopher S. G. and Chan, Syin and Niu, Yun}
}

@book{calvo_new_2011,
  title = {New Perspectives on Affect and Learning Technologies},
  volume = {3},
  url = {http://link.springer.com/content/pdf/10.1007/978-1-4419-9625-1.pdf},
  publisher = {{Springer}},
  urldate = {2014-09-30},
  date = {2011},
  author = {Calvo, Rafael A. and D'Mello, Sidney K.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GVDI5PKK/978-1-4419-9625-1.html},
  note = {00045}
}

@online{__????-1,
  title = {▶ {{Hubenstocker}} - {{Expialigetisch}} ({{Move Your Feet Mixtape}}) by {{Hubenstocker}}},
  url = {https://soundcloud.com/hubenstocker/expialigetisch-move-your-feet},
  abstract = {Explore the largest community of artists, bands, podcasters and creators of music \& audio},
  journaltitle = {SoundCloud},
  urldate = {2013-04-08},
  keywords = {audio,music,record,share,sound,soundcloud,sounds,tracks},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/QPZVS64Z/expialigetisch-move-your-feet.html},
  note = {00000}
}

@article{moschitti_tree_2008,
  title = {Tree Kernels for Semantic Role Labeling},
  volume = {34},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/coli.2008.34.2.193},
  number = {2},
  journaltitle = {Computational Linguistics},
  urldate = {2014-02-06},
  date = {2008},
  pages = {193--224},
  author = {Moschitti, Alessandro and Pighin, Daniele and Basili, Roberto},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JTFKCKPG/coli.2008.34.2.pdf},
  note = {00136}
}

@inproceedings{etzioni_open_2011,
  title = {Open Information Extraction: {{The}} Second Generation},
  url = {http://dl.acm.org/citation.cfm?id=2283398},
  shorttitle = {Open Information Extraction},
  booktitle = {Proceedings of the {{Twenty}}-{{Second}} International Joint Conference on {{Artificial Intelligence}}-{{Volume Volume One}}},
  urldate = {2013-07-26},
  date = {2011},
  pages = {3--10},
  author = {Etzioni, Oren and Fader, Anthony and Christensen, Janara and Soderland, Stephen and Mausam},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\etzioni-ijcai2011_R2A2.pdf},
  note = {00251}
}

@article{_besser_2013,
  entrysubtype = {newspaper},
  title = {Besser: {{Der Aufstand}} Der {{Weißen}}},
  url = {http://www.taz.de/!117372/},
  shorttitle = {Besser},
  abstract = {Die Demokratisierung des politischen Islams ist gescheitert. Siebeneinhalb Thesen zum Aufstand gegen die Erdogan-Regierung.},
  journaltitle = {die tageszeitung},
  journalsubtitle = {Kolumnen},
  urldate = {2013-06-14},
  date = {2013-06-03},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/NKT5NMI9/!117372.html},
  note = {00000}
}

@article{lafferty_conditional_2001,
  title = {Conditional Random Fields: {{Probabilistic}} Models for Segmenting and Labeling Sequence Data},
  url = {http://repository.upenn.edu/cis_papers/159/},
  shorttitle = {Conditional Random Fields},
  urldate = {2013-08-29},
  date = {2001},
  author = {Lafferty, John and McCallum, Andrew and Pereira, Fernando CN},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DEGP5AII/viewcontent.pdf},
  note = {09017}
}

@article{duchi_adaptive_2011,
  title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  volume = {12},
  url = {http://www.jmlr.org/papers/v12/duchi11a.html},
  issue = {Jul},
  journaltitle = {Journal of Machine Learning Research},
  urldate = {2016-12-12},
  date = {2011},
  pages = {2121--2159},
  author = {Duchi, John and Hazan, Elad and Singer, Yoram},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JJB8CAUU/duchi11a.pdf}
}

@book{_syntax._2009,
  langid = {german},
  location = {{Tübingen}},
  title = {Syntax. 2 2},
  isbn = {978-3-86057-177-4},
  publisher = {{Stauffenburg}},
  date = {2009},
  note = {OCLC: 930387783}
}

@incollection{gertner_andes_2000,
  langid = {english},
  title = {Andes: {{A Coached Problem Solving Environment}} for {{Physics}}},
  isbn = {978-3-540-67655-3 978-3-540-45108-2},
  url = {http://link.springer.com/chapter/10.1007/3-540-45108-0_17},
  shorttitle = {Andes},
  abstract = {Andes is an Intelligent Tutoring System for introductory college physics. The fundamental principles underlying the design of Andes are: (1) encourage the student to construct new knowledge by providing hints that require them to derive most of the solution on their own, (2) facilitate transfer from the system by making the interface as much like a piece of paper as possible, (3) give immediate feedback after each action to maximize the opportunities for learning and minimize the amount of time spent going down wrong paths, and (4) give the student flexibility in the order in which actions are performed, and allow them to skip steps when appropriate. This paper gives an overview of Andes, focusing on the overall architecture and the student’s experience using the system.},
  number = {1839},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer Berlin Heidelberg}},
  urldate = {2014-09-28},
  date = {2000-01-01},
  pages = {133-142},
  keywords = {Artificial Intelligence (incl. Robotics),Computers and Education,Software Engineering,User Interfaces and Human Computer Interaction},
  author = {Gertner, Abigail S. and VanLehn, Kurt},
  editor = {Gauthier, Gilles and Frasson, Claude and VanLehn, Kurt},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Z9MKTTGE/3-540-45108-0_17.html},
  note = {00245}
}

@inproceedings{afzal_natural_2009,
  title = {Natural Affect Data—collection \& Annotation in a Learning Context},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5349537},
  abstract = {Automatic inference of affect relies on representative data. For viable applications of such technology the use of naturalistic over posed data has been increasingly emphasised. Creating a repository of naturalistic data is however a massively challenging task. We report results from a data collection exercise in one of the most significant application areas of affective computing, namely computer-based learning environments. The conceptual and methodological issues encountered during the process are discussed, and problems with labelling and annotation are identified. A comparison of the compiled database with some standard databases is also presented.},
  booktitle = {Affective {{Computing}} and {{Intelligent Interaction}} and {{Workshops}}, 2009. {{ACII}} 2009. 3rd {{International Conference}} On},
  publisher = {{IEEE}},
  urldate = {2014-09-30},
  date = {2009},
  pages = {1--7},
  author = {Afzal, Shazia and Robinson, Peter},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/SPKDMMAE/acii09b.pdf},
  note = {00057}
}

@incollection{betten_discovery_1995,
  title = {The Discovery of Simple 7-Designs with Automorphism Group {{PΓL}}(2, 32)},
  isbn = {978-3-540-60114-2 978-3-540-49440-9},
  url = {http://link.springer.com/chapter/10.1007/3-540-60114-7_10},
  abstract = {A computer package is being developed at Bayreuth for the generation and investigation of discrete structures. The package is a C and C++ class library of powerful algorithms endowed with graphical interface modules. Standard applications can be run automatically whereas research projects mostly require small C or C++ programs. The basic philosophy behind the system is to transform problems into standard problems of e.g. group theory, graph theory, linear algebra, graphics, or databases and then to use highly specialized routines from that field to tackle the problems. The transformations required often follow the same principles especially in the case of generation and isomorphism testing. We therefore explain some of this background. We relate orbit problems to double cosets and we offer a way to solve double coset problems in many important cases. Since the graph isomorphism problem is equivalent to a certain double coset problem, no polynomial algorithm can be expected to work in the general case. But the reduction techniques used still allow to solve problems of an interesting size. As an example we explain how the 7-designs in the title were found. The two simple 7-designs with parameters 7-(33, 8, 10) and 7-(33, 8, 16) are presented in this paper. To the best of our knowledge they are the first 7-designs with small λ and small number of blocks ever found. Teirlinck [19] had shown previously that non trivial t-designs without repeated blocks exist for all t. The smallest parameters for the case t=7 are 7-(4032015 + 7,8,4032015). The designs have PΓL(2, 32) as automorphism group, and they are constructed from the Kramer-Mesner method [7]. This group had previously been used by [13] in order to find simple 6-designs. The presentation of our results is compatible with that earlier publication. The Kramer-Mesner method requires to solve a system of linear diophantine equations by a \{0, 1\}-vector. We used the recent improvements by Schnorr of the LLL-algorithm for finding the two solutions to the 32 x 97 system.},
  number = {948},
  booktitle = {Applied {{Algebra}}, {{Algebraic Algorithms}} and {{Error}}-{{Correcting Codes}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer Berlin Heidelberg}},
  urldate = {2013-03-04},
  date = {1995-01-01},
  pages = {131-145},
  keywords = {Algorithm Analysis and Problem Complexity,Coding and Information Theory,Combinatorics,Data Encryption,Symbolic and Algebraic Manipulation},
  author = {Betten, Anton and Kerber, Adalbert and Kohnert, Axel and Laue, Reinhard and Wassermann, Alfred},
  editor = {Cohen, Gérard and Giusti, Marc and Mora, Teo},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Z478IUXB/10.html},
  note = {00038}
}

@incollection{macagno_implicatures_2013,
  langid = {english},
  title = {Implicatures as {{Forms}} of {{Argument}}},
  isbn = {978-3-319-01010-6 978-3-319-01011-3},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-01011-3_9},
  abstract = {In this paper, we use concepts, structure and tools from argumentation theory to show how conversational implicatures are triggered by conflicts of presumptions. Presumptive implicatures are shown to be based on defeasible forms of inference used in conditions of lack of knowledge, including analogical reasoning, inference to the best explanation, practical reasoning, appeal to pity, and argument from cause. Such inferences are modelled as communicative strategies used to fill knowledge gaps by shifting the burden of proof to provide the missing contrary evidence to the other party in a dialogue. Through a series of illustrative examples, we show how such principles of inference are based on common knowledge about the ordinary course of events shared by participants in a structured dialogue setting in which they take turns putting forward and responding to speech acts.},
  number = {1},
  booktitle = {Perspectives on {{Pragmatics}} and {{Philosophy}}},
  series = {Perspectives in Pragmatics, Philosophy \& Psychology},
  publisher = {{Springer International Publishing}},
  date = {2013},
  pages = {203--225},
  keywords = {Analogy,Argumentation,Argumentation schemes,Implicatures,Implicit speech acts,Indirect speech acts,Linguistics (general),Philosophy,Pragmatics,Pragmatism,Speech acts},
  author = {Macagno, Fabrizio and Walton, Douglas},
  editor = {Capone, Alessandro and Piparo, Franco Lo and Carapezza, Marco}
}

@online{_anna_????,
  title = {Anna {{Stylianidou Research Project}}},
  url = {http://nccasymposium.bmth.ac.uk/2007/anna_stylianidou/facexpress.html},
  urldate = {2014-09-30},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/SH49JMDN/facexpress.html},
  note = {00000}
}

@article{barenfanger_e-learning_????,
  title = {E-{{Learning}} and {{Computational Linguistics An Introduction}}},
  url = {http://www.jlcl.org/2011_Heft1/H2011-1.pdf#page=5},
  journaltitle = {Language Resources and Technologies in Learning and Teaching Sprachressourcen und-technologien in Lehre und},
  urldate = {2016-07-28},
  author = {Bärenfänger, Maja and Stührenberg, Maik},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/T7S3TEIF/H2011-1.pdf},
  note = {00000}
}

@article{russell_core_2003,
  langid = {english},
  title = {Core Affect and the Psychological Construction of Emotion.},
  volume = {110},
  issn = {1939-1471, 0033-295X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.110.1.145},
  doi = {10.1037/0033-295X.110.1.145},
  number = {1},
  journaltitle = {Psychological Review},
  urldate = {2014-09-30},
  date = {2003},
  pages = {145-172},
  author = {Russell, James A.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/7M3826UB/russel_psyc-rev2003.pdf},
  note = {02761}
}

@article{graesser_autotutor_2005,
  title = {{{AutoTutor}}: An Intelligent Tutoring System with Mixed-Initiative Dialogue},
  volume = {48},
  issn = {0018-9359},
  doi = {10.1109/TE.2005.856149},
  shorttitle = {{{AutoTutor}}},
  abstract = {AutoTutor simulates a human tutor by holding a conversation with the learner in natural language. The dialogue is augmented by an animated conversational agent and three-dimensional (3-D) interactive simulations in order to enhance the learner's engagement and the depth of the learning. Grounded in constructivist learning theories and tutoring research, AutoTutor achieves learning gains of approximately 0.8 sigma (nearly one letter grade), depending on the learning measure and comparison condition. The computational architecture of the system uses the .NET framework and has simplified deployment for classroom trials.},
  number = {4},
  journaltitle = {IEEE Transactions on Education},
  date = {2005-11},
  pages = {612-618},
  keywords = {.NET framework,3D interactive simulation,Animation,AutoTutor simulation,Computational modeling,Conversational agents,Gain measurement,Humans,Injuries,Intelligent Tutoring System,Intelligent systems,Intelligent tutoring systems,Neck,Physics education,STEM learning,Speech analysis,Tutoring,animated conversational agent,distance learning,human tutor,mixed-initiative dialogue,natural language,natural language dialogue,natural languages},
  author = {Graesser, AC. and Chipman, P. and Haynes, B.C. and Olney, A},
  note = {00393}
}

@incollection{cooper_effective_2000,
  title = {Effective Affective in Intelligent Systems–building on Evidence of Empathy in Teaching and Learning},
  url = {http://link.springer.com/chapter/10.1007/10720296_3},
  booktitle = {Affective Interactions},
  publisher = {{Springer}},
  urldate = {2014-09-29},
  date = {2000},
  pages = {21--34},
  author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/IEV6W37F/10720296_3.html},
  note = {00053}
}

@inproceedings{yanase_learning_2015,
  location = {{Denver, CO}},
  title = {Learning {{Sentence Ordering}} for {{Opinion Generation}} of {{Debate}}},
  url = {http://www.aclweb.org/anthology/W15-0512},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {94--103},
  author = {Yanase, Toshihiko and Miyoshi, Toshinori and Yanai, Kohsuke and Sato, Misa and Iwayama, Makoto and Niwa, Yoshiki and Reisert, Paul and Inui, Kentaro}
}

@inreference{_emotionstheorien_2014,
  langid = {german},
  title = {Emotionstheorien},
  url = {http://de.wikipedia.org/w/index.php?title=Emotionstheorien&oldid=132963400},
  abstract = {Emotionstheorien sind Ansätze zur Erklärung, was Emotionen sind, wodurch sie verursacht werden und wie sie sich auf das Verhalten von Lebewesen auswirken. Es gibt verschiedene Arten, Emotionstheorien zu kategorisieren:},
  booktitle = {Wikipedia},
  urldate = {2014-09-10},
  date = {2014-09-09T12:14:33Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WACWXAA3/index.html},
  note = {00000 
Page Version ID: 132963400}
}

@inproceedings{ghosh_analyzing_2014,
  location = {{Baltimore, Maryland}},
  title = {Analyzing {{Argumentative Discourse Units}} in {{Online Interactions}}},
  url = {http://www.aclweb.org/anthology/W14-2106},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {39--48},
  author = {Ghosh, Debanjan and Muresan, Smaranda and Wacholder, Nina and Aakhus, Mark and Mitsui, Matthew}
}

@inproceedings{peldszus_joint_2015,
  location = {{Lisbon, Portugal}},
  title = {Joint Prediction in {{MST}}-Style Discourse Parsing for Argumentation Mining},
  url = {http://aclweb.org/anthology/D15-1110},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-09},
  pages = {938--948},
  author = {Peldszus, Andreas and Stede, Manfred}
}

@inproceedings{gamallo_dependency-based_2012,
  title = {Dependency-Based Open Information Extraction},
  url = {http://dl.acm.org/citation.cfm?id=2389963},
  booktitle = {Proceedings of the {{Joint Workshop}} on {{Unsupervised}} and {{Semi}}-{{Supervised Learning}} in {{NLP}}},
  urldate = {2013-07-26},
  date = {2012},
  pages = {10--18},
  author = {Gamallo, Pablo and Garcia, Marcos and Fernández-Lanza, Santiago},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\p10-gamallo_Dependency-Based Open Information Extraction.pdf},
  note = {00047}
}

@inproceedings{banko_open_2007,
  title = {Open {{Information Extraction}} from the {{Web}}.},
  volume = {7},
  url = {http://www.aaai.org/Papers/IJCAI/2007/IJCAI07-429.pdf},
  booktitle = {{{IJCAI}}},
  urldate = {2013-07-26},
  date = {2007},
  pages = {2670--2676},
  author = {Banko, Michele and Cafarella, Michael J. and Soderland, Stephen and Broadhead, Matthew and Etzioni, Oren},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\IJCAI07-429_TextRunner.pdf},
  note = {01116}
}

@collection{psotka_intelligent_1988,
  location = {{Hillsdale, N.J}},
  title = {Intelligent Tutoring Systems: Lessons Learned},
  isbn = {0-8058-0023-9},
  shorttitle = {Intelligent Tutoring Systems},
  pagetotal = {552},
  publisher = {{L. Erlbaum Associates}},
  date = {1988},
  keywords = {Automation Congresses,Congresses,Intelligent tutoring systems,Military education,United States},
  editor = {Psotka, Joseph and Massey, L. Daniel and Mutter, Sharon A.},
  note = {00253}
}

@inproceedings{al_sallab_self_2011,
  title = {Self Learning Machines Using {{Deep Networks}}},
  isbn = {978-1-4577-1196-1 978-1-4577-1195-4 978-1-4577-1194-7},
  url = {http://ieeexplore.ieee.org/document/6089108/},
  doi = {10.1109/SoCPaR.2011.6089108},
  publisher = {{IEEE}},
  urldate = {2016-10-25},
  date = {2011-10},
  pages = {21-26},
  author = {Al Sallab, Ahmad A. and Rashwan, Mohsen A.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MG3GPFZS/53db85aa0cf2cfac9928ec6c.pdf}
}

@inproceedings{boltuzic_back_2014,
  location = {{Baltimore, Maryland}},
  title = {Back up Your {{Stance}}: {{Recognizing Arguments}} in {{Online Discussions}}},
  url = {http://www.aclweb.org/anthology/W14-2107},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {49--58},
  author = {Boltužić, Filip and Šnajder, Jan}
}

@inproceedings{rinott_show_2015,
  title = {Show {{Me Your Evidence}}–an {{Automatic Method}} for {{Context Dependent Evidence Detection}}},
  url = {http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP050.pdf},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{NLP}} ({{EMNLP}}), {{Lisbon}}, {{Portugal}}},
  urldate = {2016-12-01},
  date = {2015},
  pages = {17--21},
  author = {Rinott, Ruty and Dankin, Lena and Alzate, Carlos and Khapra, Mitesh M. and Aharoni, Ehud and Slonim, Noam},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/EJRHFEZK/Evidence2015.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/D6VMS9ZC/mlta_data.html}
}

@inproceedings{ibn_faiz_extracting_2014,
  location = {{Baltimore, Maryland}},
  title = {Extracting {{Higher Order Relations From Biomedical Text}}},
  url = {http://www.aclweb.org/anthology/W14-2114},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {100--101},
  author = {Ibn Faiz, Syeed and Mercer, Robert}
}

@inproceedings{afzal_modelling_2010,
  title = {Modelling {{Affect}} in {{Learning Environments}}-{{Motivation}} and {{Methods}}},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5573217},
  booktitle = {Advanced {{Learning Technologies}} ({{ICALT}}), 2010 {{IEEE}} 10th {{International Conference}} On},
  publisher = {{IEEE}},
  urldate = {2014-09-30},
  date = {2010},
  pages = {438--442},
  author = {Afzal, Shazia and Robinson, Peter},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/6NFUMWX5/icalt10.pdf},
  note = {00007}
}

@article{staff_boosting_????,
  title = {Boosting {{Bookmark Category Web Page Classification Accuracy}} Using {{Multiple Clustering Approaches}}},
  url = {https://secure.um.edu.mt/__data/assets/pdf_file/0006/51738/wict08_submission_3.pdf},
  urldate = {2016-08-18},
  author = {Staff, Chris},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/D834B3UF/wict08_submission_3.pdf},
  note = {00000}
}

@thesis{duvenaud_automatic_2014,
  title = {Automatic Model Construction with {{Gaussian}} Processes},
  url = {https://www.repository.cam.ac.uk/handle/1810/247281},
  institution = {{University of Cambridge}},
  urldate = {2016-10-25},
  date = {2014},
  author = {Duvenaud, David},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MPRET7NC/1402.5836.pdf}
}

@incollection{lehman_impact_2014,
  langid = {english},
  title = {Impact of {{Agent Role}} on {{Confusion Induction}} and {{Learning}}},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_6},
  abstract = {The presentation of contradictory information to trigger deeper processing and increase learning has been investigated in a variety of ways (e.g., conversational agents, worked examples). However, the impact of information source (e.g., expertise, gender) and the relationship between the contradicting sources (e.g., status level) has not been investigated to the same degree. We previously reported that confusion can successfully be induced and learning increased when contradictory information was presented by two conversational agents (tutor, peer student). In the present experiment we investigated contradictions posed by two peer student agents. Self-reports of confusion and learner responses to embedded forced-choice questions revealed that the contradictions still successfully induced confusion. There were, however, differences in the nature of confusion induction based on the inter-agent relationship (i.e., student-student vs. tutor-student). Learners performed better on transfer tasks when presented with contradictions compared to a no-contradiction control, but only when they were successfully confused.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {45-54},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,Intelligent tutoring systems,Multimedia Information Systems,Tutoring,User Interfaces and Human Computer Interaction,affect,animated pedagogical agents,confusion,contradiction,learning},
  author = {Lehman, Blair and Graesser, Arthur},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Q8JZJVJ3/978-3-319-07221-0_6.html},
  note = {00002}
}

@inproceedings{litman_itspoke_2004,
  title = {{{ITSPOKE}}: {{An}} Intelligent Tutoring Spoken Dialogue System},
  url = {http://dl.acm.org/citation.cfm?id=1614027},
  shorttitle = {{{ITSPOKE}}},
  booktitle = {Demonstration {{Papers}} at {{HLT}}-{{NAACL}} 2004},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2014-09-29},
  date = {2004},
  pages = {5--8},
  author = {Litman, Diane J. and Silliman, Scott},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZT36VRU5/Litman und Silliman - 2004 - ITSPOKE An intelligent tutoring spoken dialogue s.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/K6QB85MW/citation.html},
  note = {00218}
}

@inproceedings{bex_generalising_2014,
  title = {Generalising Argument Dialogue with the {{Dialogue Game Execution Platform}}},
  url = {http://dx.doi.org/10.3233/978-1-61499-436-7-141},
  doi = {10.3233/978-1-61499-436-7-141},
  booktitle = {Computational {{Models}} of {{Argument}} - {{Proceedings}} of {{COMMA}} 2014, {{Atholl Palace Hotel}}, {{Scottish Highlands}}, {{UK}}, {{September}} 9-12, 2014},
  date = {2014},
  pages = {141--152},
  author = {Bex, Floris and Lawrence, John and Reed, Chris}
}

@inproceedings{graves_titles_2014,
  location = {{Baltimore, Maryland}},
  title = {Titles {{That Announce Argumentative Claims}} in {{Biomedical Research Articles}}},
  url = {http://www.aclweb.org/anthology/W14-2113},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {98--99},
  author = {Graves, Heather and Graves, Roger and Mercer, Robert and Akter, Mahzereen}
}

@incollection{abbas_argument_2010,
  langid = {english},
  title = {Argument {{Mining}} from {{RADB}} and {{Its Usage}} in {{Arguing Agents}} and {{Intelligent Tutoring System}}},
  isbn = {978-3-642-14434-9 978-3-642-14435-6},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-14435-6_5},
  abstract = {Argumentation is an interdisciplinary research area that incorporates many fields such as artificial intelligence, multi-agent systems, and collaborative learning. In this chapter, we describe argument mining techniques from a structured argument database “RADB”, a sort of relational database we designed specially for organizing argument databases, and their usage in arguing agents and intelligent tutoring systems. The RADB repository depends on the Argumentation Interchange Format Ontology (AIF) using “Walton Theory” for argument analysis. It presents a novel approach that summarizes the argument data set into structured form “RADB” in order to (i) facilitate the data interoperability among various agents/humans/tools, (ii) provide the ability to freely navigate the repository by integrating the data mining techniques gathered in a classifier agent; mine the RADB repository and retrieve the most relevant arguments to the users’ queries, (iii) illustrate an agent-based learning environment outline, where the mining classifier agent and the RADB are incorporated together within an intelligent tutoring system (ITS). Such incorporation assists in (i) deepening the understanding of negotiation, decision making, and critical thinking, (ii) guiding the analysis process to refine the user’s underlying classification, and improving the analysis and the students’ intellectual process. Later in the chapter, we describe an effective usage of argument mining for arguing agents, which interact with each other in the Internet environment and argues about issues concerned, casting arguments and counter-arguments each other to reach an agreement. We illustrate how argument mining allows to strengthen arguing agent intelligence, resulting in expanding the main concern in formal argumentation frameworks that is to formalize methods in which the final statuses of arguments are to be decided semantically and/or dialectically. In both usages, we yield new forms of argument-based intelligence, which allows establishing one’s own argument by comparing diverse views and opinions and uncovering new leads, differently from simple refutation aiming at cutting down other parties.},
  number = {310},
  booktitle = {Innovations in {{Multi}}-{{Agent Systems}} and {{Applications}} - 1},
  series = {Studies in Computational Intelligence},
  publisher = {{Springer Berlin Heidelberg}},
  date = {2010},
  pages = {113--147},
  keywords = {Appl.Mathematics/Computational Methods of Engineering,Artificial Intelligence (incl. Robotics)},
  author = {Abbas, Safia and Sawamura, Hajime},
  editor = {Srinivasan, Dipti and Jain, Lakhmi C.}
}

@inproceedings{pour_impact_2010,
  title = {The Impact of System Feedback on Learners’ Affective and Physiological States},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-13388-6_31},
  booktitle = {Intelligent {{Tutoring Systems}}},
  publisher = {{Springer}},
  urldate = {2014-06-17},
  date = {2010},
  pages = {264--273},
  author = {Pour, Payam Aghaei and Hussain, M. Sazzad and AlZoubi, Omar and D’Mello, Sidney and Calvo, Rafael A.},
  note = {00041}
}

@inproceedings{christensen_semantic_2010,
  location = {{Stroudsburg, PA, USA}},
  title = {Semantic Role Labeling for Open Information Extraction},
  url = {http://dl.acm.org/citation.cfm?id=1866775.1866782},
  abstract = {Open Information Extraction is a recent paradigm for machine reading from arbitrary text. In contrast to existing techniques, which have used only shallow syntactic features, we investigate the use of semantic features (semantic roles) for the task of Open IE. We compare TextRunner (Banko et al., 2007), a state of the art open extractor, with our novel extractor SRL-IE, which is based on UIUC's SRL system (Punyakanok et al., 2008). We find that SRL-IE is robust to noisy heterogeneous Web data and outperforms TextRunner on extraction quality. On the other hand, TextRunner performs over 2 orders of magnitude faster and achieves good precision in high locality and high redundancy extractions. These observations enable the construction of hybrid extractors that output higher quality results than TextRunner and similar quality as SRL-IE in much less time.},
  booktitle = {Proceedings of the {{NAACL HLT}} 2010 {{First International Workshop}} on {{Formalisms}} and {{Methodology}} for {{Learning}} by {{Reading}}},
  series = {FAM-LbR '10},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2013-07-26},
  date = {2010},
  pages = {52--60},
  author = {Christensen, Janara and Mausam and Soderland, Stephen and Etzioni, Oren},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GFC6R4D2/Christensen et al. - 2010 - Semantic role labeling for open information extrac.pdf},
  note = {00039}
}

@article{fortmann_bewegungsresistente_2007,
  title = {Bewegungsresistente {{Verben}}},
  volume = {26},
  issn = {0721-9067, 1613-3706},
  url = {http://www.degruyter.com/view/j/zfsw.2007.26.issue-1/zfs.2007.009/zfs.2007.009.xml},
  doi = {10.1515/ZFS.2007.009},
  number = {1},
  journaltitle = {Zeitschrift für Sprachwissenschaft},
  urldate = {2017-04-03},
  date = {2007-01-19},
  pages = {1-40},
  author = {Fortmann, Christian},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WPJ7EH5V/zfs.2007.009.pdf}
}

@inproceedings{mochales_palau_study_2007,
  location = {{Amsterdam}},
  title = {Study on Sentence Relations in the Automatic Detection of Argumentation in Legal Cases},
  url = {https://lirias.kuleuven.be/handle/123456789/197361},
  booktitle = {Proceedings of {{JURIX}} 2007: The {{Twentieth Annual Conference}} on {{Legal Knowledge}} and {{Information Systems}}, {{JURIX}} 2007: The Twentieth Annual Conference on Legal Knowledge and Information Systems, {{Leiden}}, {{The Netherlands}}, 13-14 {{December}} 2007},
  publisher = {{IOS press}},
  date = {2007},
  pages = {89--98},
  author = {Mochales Palau, Raquel and Moens, Marie-Francine}
}

@article{anderson_cognitive_1995,
  title = {Cognitive Tutors: {{Lessons}} Learned},
  volume = {4},
  url = {http://www.tandfonline.com/doi/abs/10.1207/s15327809jls0402_2},
  shorttitle = {Cognitive Tutors},
  number = {2},
  journaltitle = {The journal of the learning sciences},
  urldate = {2014-09-29},
  date = {1995},
  pages = {167--207},
  author = {Anderson, John R. and Corbett, Albert T. and Koedinger, Kenneth R. and Pelletier, Ray},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/EA6KUH48/Anderson et al. - 1995 - Cognitive tutors Lessons learned.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/8QZ5W8FC/s15327809jls0402_2.html},
  note = {01864}
}

@article{graesser_autotutor_2008,
  title = {{{AutoTutor}}: {{Learning}} through Natural Language Dialogue That Adapts to the Cognitive and Affective States of the Learner},
  shorttitle = {{{AutoTutor}}},
  journaltitle = {Recent innovations in educational technology that facilitate student learning},
  date = {2008},
  pages = {95--125},
  author = {Graesser, A. C. and Rus, Vasile and D’Mello, S. K. and Jackson, G. Tanner and Robinson, D. H. and Schraw, G.},
  note = {00022}
}

@online{_buchkapitel_????,
  title = {Buchkapitel [{{PDF}}]: {{AutoTutor}} 2013: {{Conversation}}-{{Based Online Intelligent Tutoring System}} with {{Rich Media}} ({{Interactive Event}}) | {{E}}-{{Technik}}, {{Informatik}} + {{IT}} - {{Springer}} Für {{Professionals}}},
  url = {http://www.springerprofessional.de/4520198},
  shorttitle = {Buchkapitel [{{PDF}}]},
  abstract = {Aus dem eBook: Artificial Intelligence in Education von David Hutchison, Takeo Kanade, Josef Kittler, Jon M. Kleinberg, Friedemann Mattern, John C. Mitchell, Moni Naor, Oscar Nierstrasz, C. Pandu Rangan, Bernhard Steffen, Madhu Sudan, Demetri Terzopoulos, Doug Tygar, Moshe Y. Vardi, Gerhard Weikum, Randy Goebel, Jörg Siekmann, Wolfgang Wahlster, H. Chad Lane, Kalina Yacef, Jack Mostow, Philip Pavlik: AutoTuto 2013 is an advanced version of the intelligent tutoring system, proven to be effective in e},
  urldate = {2014-09-28},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/KXWK5KVK/186.html;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZN9BMEFK/4520198.html\;jsessionid=AE013C111EC57A92224FB5CA9B5EE3E6.html},
  note = {00000}
}

@collection{nkambou_advances_2010,
  location = {{Berlin}},
  title = {Advances in Intelligent Tutoring Systems},
  isbn = {978-3-642-14362-5},
  pagetotal = {508},
  number = {v. 308},
  series = {Studies in computational intelligence},
  publisher = {{Springer}},
  date = {2010},
  keywords = {Artificial intelligence,Educational applications,Intelligent tutoring systems},
  editor = {Nkambou, Roger and Bourdeau, Jacqueline and Mizoguchi, Riichiro},
  note = {00098}
}

@online{kendall_libguides_????,
  langid = {english},
  title = {{{LibGuides}}: {{PubMed}}, {{Web}} of {{Science}}, or {{Google Scholar}}? {{A}} behind-the-Scenes Guide for Life Scientists. : {{So}} Which Is Better: {{PubMed}}, {{Web}} of {{Science}}, or {{Google Scholar}}?},
  url = {http://libguides.lib.msu.edu/c.php?g=96972&p=627295},
  shorttitle = {{{LibGuides}}},
  urldate = {2016-09-09},
  author = {Kendall, Susan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/E3R8SC4N/pubmedvsgooglescholar.html},
  note = {00001}
}

@inproceedings{kiesel_shared_2015,
  location = {{Denver, CO}},
  title = {A {{Shared Task}} on {{Argumentation Mining}} in {{Newspaper Editorials}}},
  url = {http://www.aclweb.org/anthology/W15-0505},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {35--38},
  author = {Kiesel, Johannes and Al Khatib, Khalid and Hagen, Matthias and Stein, Benno}
}

@article{walton_argumentation_2016,
  title = {An {{Argumentation Interface}} for {{Expert Opinion Evidence}}},
  volume = {29},
  issn = {1467-9337},
  url = {http://dx.doi.org/10.1111/raju.12115},
  doi = {10.1111/raju.12115},
  number = {1},
  journaltitle = {Ratio Juris},
  date = {2016},
  pages = {59--82},
  author = {Walton, Douglas and Zhang, Nanning}
}

@inproceedings{banko_tradeoffs_2008,
  location = {{Columbus, Ohio}},
  title = {The {{Tradeoffs Between Open}} and {{Traditional Relation Extraction}}},
  url = {http://www.aclweb.org/anthology/P/P08/P08-1004},
  booktitle = {Proceedings of {{ACL}}-08: {{HLT}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2008-06},
  pages = {28--36},
  keywords = {relation extraction},
  author = {Banko, Michele and Etzioni, Oren},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZIWBCGPU/P08-1004.pdf}
}

@article{dmello_towards_2007,
  title = {Towards an Affect-Sensitive Autotutor},
  volume = {22},
  url = {http://www.memphis.edu/psychology/graesser/publications/documents/dmello_ieee_is07.pdf},
  number = {4},
  journaltitle = {IEEE Intelligent Systems},
  urldate = {2014-09-28},
  date = {2007},
  pages = {53--61},
  author = {D’Mello, Sidney and Picard, Rosalind and Graesser, Arthur},
  note = {00285}
}

@inproceedings{litman_predicting_2004,
  location = {{Stroudsburg, PA, USA}},
  title = {Predicting {{Student Emotions}} in {{Computer}}-Human {{Tutoring Dialogues}}},
  url = {http://dx.doi.org/10.3115/1218955.1219000},
  doi = {10.3115/1218955.1219000},
  abstract = {We examine the utility of speech and lexical features for predicting student emotions in computer-human spoken tutoring dialogues. We first annotate student turns for negative, neutral, positive and mixed emotions. We then extract acoustic-prosodic features from the speech signal, and lexical items from the transcribed or recognized speech. We compare the results of machine learning experiments using these features alone or in combination to predict various categorizations of the annotated student emotions. Our best results yield a 19-36\% relative improvement in error reduction over a baseline. Finally, we compare our results with emotion prediction in human-human tutoring dialogues.},
  booktitle = {Proceedings of the {{42Nd Annual Meeting}} on {{Association}} for {{Computational Linguistics}}},
  series = {ACL '04},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2014-09-28},
  date = {2004},
  author = {Litman, Diane J. and Forbes-Riley, Kate},
  note = {00180}
}

@inproceedings{carlson_toward_2010,
  title = {Toward an {{Architecture}} for {{Never}}-{{Ending Language Learning}}.},
  url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/download/1879/2201},
  booktitle = {{{AAAI}}},
  urldate = {2013-07-26},
  date = {2010},
  author = {Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka Jr, Estevam R. and Mitchell, Tom M.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\NELL_1879-8287-1-PB_Never-Ending Language Learning.pdf},
  note = {00763}
}

@online{_new_????,
  title = {New {{Perspectives}} on {{Affect}} and {{Learning Technologies}} - {{Springer}}},
  url = {http://link.springer.com/book/10.1007/978-1-4419-9625-1},
  urldate = {2014-09-30},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/NXPFHV9G/978-1-4419-9625-1.html},
  note = {00045}
}

@article{dmello_disequilibrium_2012,
  title = {Disequilibrium in the Mind, Disharmony in the Body},
  volume = {26},
  url = {http://www.tandfonline.com/doi/abs/10.1080/02699931.2011.575767},
  number = {2},
  journaltitle = {Cognition \& emotion},
  urldate = {2014-06-17},
  date = {2012},
  pages = {362--374},
  author = {D'Mello, Sidney and Dale, Rick and Graesser, Art},
  note = {00032}
}

@incollection{egilmez_extending_2013,
  langid = {english},
  title = {Extending {{Social Abstract Argumentation}} with {{Votes}} on {{Attacks}}},
  isbn = {978-3-642-54372-2 978-3-642-54373-9},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-54373-9_2},
  abstract = {Social abstract argumentation laid theoretical foundations for future online debating systems with formal backbones and semantics. The advantage of these envisioned new systems is their capability of formally justifying the social outcomes of their debates. Many recent extensions proposed for argumentation in general have addressed the issue that not all attacks between arguments are equal, especially in the eyes of the crowd. This work generalises social abstract argumentation to incorporate voting on attacks, inducing a social notion of attack strengths.},
  number = {8306},
  booktitle = {Theory and {{Applications}} of {{Formal Argumentation}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer Berlin Heidelberg}},
  date = {2013-08},
  pages = {16--31},
  keywords = {Artificial Intelligence (incl. Robotics),Theory of Computation},
  author = {Eğilmez, Sinan and Martins, João and Leite, João},
  editor = {Black, Elizabeth and Modgil, Sanjay and Oren, Nir}
}

@article{ekman_measuring_1976,
  langid = {english},
  title = {Measuring Facial Movement},
  volume = {1},
  issn = {0361-3496, 1573-3653},
  url = {http://link.springer.com/article/10.1007/BF01115465},
  doi = {10.1007/BF01115465},
  abstract = {A procedure has been developed for measuring visibly different facial movements. The Facial Action Code was derived from an analysis of the anatomical basis of facial movement. The method can be used to describe any facial movement (observed in photographs, motion picture film or videotape) in terms of anatomically based action units. The development of the method is explained, contrasting it to other methods of measuring facial behavior. An example of how facial behavior is measured is provided, and ideas about research applications are discussed.},
  number = {1},
  journaltitle = {Environmental psychology and nonverbal behavior},
  shortjournal = {J Nonverbal Behav},
  urldate = {2014-09-30},
  date = {1976-09-01},
  pages = {56-75},
  keywords = {Communication,Psychology of Personality,Social Psychology,Sociology},
  author = {Ekman, Paul and Friesen, Wallace V.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3U3EPUSR/BF01115465.html},
  note = {00593}
}

@book{sternefeld_syntax_2009-1,
  langid = {german},
  location = {{Tübingen}},
  title = {Syntax:: eine morphologisch motivierte generative Beschreibung des Deutschen. Bd. 2: [...]},
  edition = {3., überarb. Aufl},
  isbn = {978-3-86057-177-4},
  shorttitle = {Syntax},
  pagetotal = {479},
  number = {Bd. 31,2},
  series = {Stauffenburg-Linguistik},
  publisher = {{Stauffenburg}},
  date = {2009},
  author = {Sternefeld, Wolfgang},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/5BS6DK6I/Sternefeld_2009_Syntax.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/RWPQZJAQ/930387783.html},
  note = {OCLC: 426147853}
}

@article{pekrun_academic_2002,
  title = {Academic Emotions in Students' Self-Regulated Learning and Achievement: {{A}} Program of Qualitative and Quantitative Research},
  volume = {37},
  url = {http://www.tandfonline.com/doi/abs/10.1207/S15326985EP3702_4},
  shorttitle = {Academic Emotions in Students' Self-Regulated Learning and Achievement},
  number = {2},
  journaltitle = {Educational psychologist},
  urldate = {2014-09-30},
  date = {2002},
  pages = {91--105},
  author = {Pekrun, Reinhard and Goetz, Thomas and Titz, Wolfram and Perry, Raymond P.},
  note = {01636}
}

@book{picard_affective_2000,
  langid = {english},
  title = {Affective {{Computing}}},
  isbn = {978-0-262-66115-7},
  abstract = {The latest scientific findings indicate that emotions play an essential role in decision making, perception, learning, and more -- that is, they influence the very mechanisms of rational thinking. Not only too much, but too little emotion can impair decision making. According to Rosalind Picard, if we want computers to be genuinely intelligent and to interact naturally with us, we must give computers the ability to recognize, understand, even to have and express emotions.Part 1 of this book provides the intellectual framework for affective computing. It includes background on human emotions, requirements for emotionally intelligent computers, applications of affective computing, and moral and social questions raised by the technology. Part 2 discusses the design and construction of affective computers. Although this material is more technical than that in Part 1, the author has kept it less technical than typical scientific publications in order to make it accessible to newcomers. Topics in Part 2 include signal-based representations of emotions, human affect recognition as a pattern recognition and learning problem, recent and ongoing efforts to build models of emotion for synthesizing emotions in computers, and the new application area of affective wearable computers.},
  pagetotal = {308},
  publisher = {{MIT Press}},
  date = {2000},
  keywords = {Computers / Computer Science,Computers / Intelligence (AI) & Semantics,Computers / Virtual Worlds},
  author = {Picard, Rosalind W.},
  note = {06107}
}

@inproceedings{wu_open_2010,
  title = {Open Information Extraction Using {{Wikipedia}}},
  url = {http://dl.acm.org/citation.cfm?id=1858694},
  booktitle = {Proceedings of the 48th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  urldate = {2013-07-26},
  date = {2010},
  pages = {118--127},
  author = {Wu, Fei and Weld, Daniel S.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\Wu-acl10_WOE.pdf},
  note = {00326}
}

@inproceedings{sardianos_argument_2015,
  location = {{Denver, CO}},
  title = {Argument {{Extraction}} from {{News}}},
  url = {http://www.aclweb.org/anthology/W15-0508},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {56--66},
  author = {Sardianos, Christos and Katakis, Ioannis Manousos and Petasis, Georgios and Karkaletsis, Vangelis}
}

@inproceedings{cheng_entityrank_2007,
  title = {{{EntityRank}}: Searching Entities Directly and Holistically},
  url = {http://dl.acm.org/citation.cfm?id=1325898},
  shorttitle = {{{EntityRank}}},
  booktitle = {Proceedings of the 33rd International Conference on {{Very}} Large Data Bases},
  urldate = {2013-03-04},
  date = {2007},
  pages = {387--398},
  author = {Cheng, Tao and Yan, Xifeng and Chang, Kevin Chen-Chuan},
  file = {C:\\Users\\Arne\\Documents\\Studium\\11. Semester\\Text Analytics\\Entity Search\\10.1.1.78.1052(best).pdf},
  note = {00185}
}

@book{baroni_computational_2010,
  langid = {english},
  title = {Computational {{Models}} of {{Argument}}: {{Proceedings}} of {{COMMA}} 2010},
  isbn = {978-1-60750-618-8},
  shorttitle = {Computational {{Models}} of {{Argument}}},
  abstract = {Presents papers from the Third Conference on Computational Models of Argument, held in September 2010 in Desanzano del Garda, Italy. Providing a view of this important research field, this book is of interest to those involved in the use and development of artificial intelligence systems.},
  publisher = {{IOS Press}},
  date = {2010},
  keywords = {Computers / Intelligence (AI) & Semantics},
  author = {Baroni, Pietro and Cerutti, F. and Giacomin, M. and Simari, Guillermo R.}
}

@article{pesetsky_morphology_1985,
  eprinttype = {jstor},
  eprint = {4178430},
  title = {Morphology and {{Logical Form}}},
  volume = {16},
  issn = {0024-3892},
  number = {2},
  journaltitle = {Linguistic Inquiry},
  date = {1985},
  pages = {193-246},
  author = {Pesetsky, David}
}

@article{hickey_affective_2014,
  title = {The {{Affective Tutor}}},
  volume = {29},
  issn = {1937-4771},
  url = {http://dl.acm.org/citation.cfm?id=2602724.2602735},
  abstract = {In this paper we present our initial work on an application, The Affective Tutor, envisioned to help instructors keep all students in a large lecture class engaged and actively learning material related to the course. We have found, by asking for feedback after every class, that in a large class of over 50 students, a significant number of students will feel the class went too slow and another group will feel the class went too fast. One of the most challenging aspects of teaching a large class is to keep the entire class engaged in the course material. The Affective Tutor helps instructors to determine in real-time how students feel about the pace of the class. The tool also helps instructors to pin-point confusing topics, and to tackle the problem of keeping students engaged by providing a monitored back-channel that allows the bored students to help the confused students get back on track and into an engaged mode.},
  number = {6},
  journaltitle = {J. Comput. Sci. Coll.},
  urldate = {2014-09-28},
  date = {2014-06},
  pages = {50--56},
  author = {Hickey, Timothy J. and Tarimo, William T.},
  note = {00008}
}

@incollection{el_kaliouby_real-time_2005,
  title = {Real-Time Inference of Complex Mental States from Facial Expressions and Head Gestures},
  url = {http://link.springer.com/content/pdf/10.1007/0-387-27890-7_11.pdf},
  booktitle = {Real-Time Vision for Human-Computer Interaction},
  publisher = {{Springer}},
  urldate = {2014-10-01},
  date = {2005},
  pages = {181--200},
  author = {El Kaliouby, Rana and Robinson, Peter},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/PG7JWWRD/elKalioubyRTV4HCI05.pdf},
  note = {00273}
}

@article{graesser_autotutor_2004,
  langid = {english},
  title = {{{AutoTutor}}: {{A}} Tutor with Dialogue in Natural Language},
  volume = {36},
  issn = {0743-3808, 1532-5970},
  url = {http://link.springer.com/article/10.3758/BF03195563},
  doi = {10.3758/BF03195563},
  shorttitle = {{{AutoTutor}}},
  abstract = {AutoTutor is a learning environment that tutors students by holding a conversation in natural language. AutoTutor has been developed for Newtonian qualitative physics and computer literacy. Its design was inspired by explanation-based constructivist theories of learning, intelligent tutoring systems that adaptively respond to student knowledge, and empirical research on dialogue patterns in tutorial discourse. AutoTutor presents challenging problems (formulated as questions) from a curriculum script and then engages in mixed initiative dialogue that guides the student in building an answer. It provides the student with positive, neutral, or negative feedback on the student’s typed responses, pumps the student for more information, prompts the student to fill in missing words, gives hints, fills in missing information with assertions, identifies and corrects erroneous ideas, answers the student’s questions, and summarizes answers. AutoTutor has produced learning gains of approximately .70 sigma for deep levels of comprehension.},
  number = {2},
  journaltitle = {Behavior Research Methods, Instruments, \& Computers},
  shortjournal = {Behavior Research Methods, Instruments, \& Computers},
  urldate = {2014-09-28},
  date = {2004-05-01},
  pages = {180-192},
  keywords = {Cognitive Psychology},
  author = {Graesser, Arthur C. and Lu, Shulan and Jackson, George Tanner and Mitchell, Heather Hite and Ventura, Mathew and Olney, Andrew and Louwerse, Max M.},
  note = {00366}
}

@inreference{_ontologie_2013,
  langid = {german},
  title = {Ontologie (Informatik)},
  url = {http://de.wikipedia.org/w/index.php?title=Ontologie_(Informatik)&oldid=120441652},
  abstract = {Ontologien in der Informatik sind meist sprachlich gefasste und formal geordnete Darstellungen einer Menge von Begrifflichkeiten und der zwischen ihnen bestehenden Beziehungen in einem bestimmten Gegenstandsbereich. Sie werden dazu genutzt, „Wissen“ in digitalisierter und formaler Form zwischen Anwendungsprogrammen und Diensten auszutauschen. Wissen umfasst dabei sowohl Allgemeinwissen als auch Wissen über sehr spezielle Themengebiete und Vorgänge.},
  booktitle = {Wikipedia},
  urldate = {2013-07-29},
  date = {2013-07-11T12:08:51Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MEKQUGQK/index.html},
  note = {00000 
Page Version ID: 120441652}
}

@incollection{takhirov_integrated_2013,
  title = {An {{Integrated Approach}} for {{Large}}-{{Scale Relation Extraction}} from the {{Web}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-37401-2_18},
  booktitle = {Web {{Technologies}} and {{Applications}}},
  publisher = {{Springer}},
  urldate = {2013-07-26},
  date = {2013},
  pages = {163--175},
  keywords = {Data Mining and Knowledge Discovery,Database Management,Information Storage and Retrieval,Knowledge Bases,Multimedia Information Systems,Relation Extraction,Web Mining},
  author = {Takhirov, Naimdjon and Duchateau, Fabien and Aalberg, Trond and Sølvberg, Ingeborg},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\duchateau-apweb13_SPIDER.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/P2CVB5I2/978-3-642-37401-2_18.html},
  note = {00001}
}

@inproceedings{nguyen_extracting_2015,
  location = {{Denver, CO}},
  title = {Extracting {{Argument}} and {{Domain Words}} for {{Identifying Argument Components}} in {{Texts}}},
  url = {http://www.aclweb.org/anthology/W15-0503},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {22--28},
  author = {Nguyen, Huy and Litman, Diane}
}

@incollection{frasson_virtual_2014,
  langid = {english},
  title = {Virtual {{Environment}} for {{Monitoring Emotional Behaviour}} in {{Driving}}},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_10},
  abstract = {Emotions are an important behaviour of humans and may arise in driving situations. Uncontrolled emotions can lead to harmful effects. To control and reduce the negative impact of emotions, we have built a virtual driving environment in which we can capture and analyse emotions felt by the driver using EEG systems. By simulating specific emotional situations we can provoke these emotions and detect their types and intensity according to the driver. Then, in the environment, we generate corrective actions that are able to reduce the emotions. After a training period, the driver is able to correct the emotions by himself.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {75-83},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,Driving,EEG,Emotional state,Emotions,Multimedia Information Systems,Simulation,User Interfaces and Human Computer Interaction},
  author = {Frasson, Claude and Brosseau, Pierre Olivier and Tran, Thi Hong Dung},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DFFE7JIE/978-3-319-07221-0_10.html},
  note = {00002}
}

@online{_debating_2011,
  langid = {american},
  title = {Debating {{Technologies Datasets}}},
  url = {https://www.research.ibm.com/haifa/dept/vst/mlta_data.shtml},
  type = {CT002},
  urldate = {2016-12-01},
  date = {2011-05-17}
}

@inproceedings{hoffmann_learning_2010,
  title = {Learning 5000 Relational Extractors},
  url = {http://dl.acm.org/citation.cfm?id=1858711},
  booktitle = {Proceedings of the 48th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  urldate = {2013-07-26},
  date = {2010},
  pages = {286--295},
  author = {Hoffmann, Raphael and Zhang, Congle and Weld, Daniel S.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Distant supervision\\hoffmann-acl10.pdf},
  note = {00113}
}

@article{fabrizio_macagno_classifying_2015,
  title = {Classifying the {{Patterns}} of {{Natural Arguments}}},
  volume = {48},
  issn = {1527-2079},
  number = {1},
  journaltitle = {Philosophy and Rhetoric},
  date = {2015},
  pages = {26--53},
  author = {Fabrizio Macagno, Douglas Walton}
}

@inproceedings{green_towards_2014,
  location = {{Baltimore, Maryland}},
  title = {Towards {{Creation}} of a {{Corpus}} for {{Argumentation Mining}} the {{Biomedical Genetics Research Literature}}},
  url = {http://www.aclweb.org/anthology/W14-2102},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {11--18},
  author = {Green, Nancy}
}

@inproceedings{wyner_argument_2015,
  location = {{Denver, CO}},
  title = {Argument {{Discovery}} and {{Extraction}} with the {{Argument Workbench}}},
  url = {http://www.aclweb.org/anthology/W15-0510},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {78--83},
  author = {Wyner, Adam and Peters, Wim and Price, David}
}

@inproceedings{park_conditional_2015,
  location = {{Denver, CO}},
  title = {Conditional {{Random Fields}} for {{Identifying Appropriate Types}} of {{Support}} for {{Propositions}} in {{Online User Comments}}},
  url = {http://www.aclweb.org/anthology/W15-0506},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {39--44},
  author = {Park, Joonsuk and Katiyar, Arzoo and Yang, Bishan}
}

@article{koedinger_intelligent_1997,
  title = {Intelligent Tutoring Goes to School in the Big City},
  volume = {8},
  url = {http://telearn.archives-ouvertes.fr/hal-00197383/},
  journaltitle = {International Journal of Artificial Intelligence in Education (IJAIED)},
  urldate = {2014-09-28},
  date = {1997},
  pages = {30--43},
  author = {Koedinger, Kenneth R. and Anderson, John R. and Hadley, William H. and Mark, Mary A. and {others}},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FJ95TWQE/Koedinger-Anderson.pdf},
  note = {01192}
}

@inproceedings{lawrence_combining_2015,
  location = {{Denver, CO}},
  title = {Combining {{Argument Mining Techniques}}},
  url = {http://www.aclweb.org/anthology/W15-0516},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {127--136},
  author = {Lawrence, John and Reed, Chris}
}

@collection{berntson_handbook_2009,
  location = {{Hoboken, N.J}},
  title = {Handbook of Neuroscience for the Behavioral Sciences},
  isbn = {978-0-470-08355-0 978-0-470-08356-7 978-0-470-08357-4},
  pagetotal = {2},
  publisher = {{Wiley}},
  date = {2009},
  keywords = {Behavior,Mental Processes,Neuropsychology,Neurosciences,Psychophysiology,physiology},
  editor = {Berntson, Gary G. and Cacioppo, John T.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JGKA2PWP/1602.03218.pdf},
  note = {OCLC: ocn259902179}
}

@inproceedings{peldszus_towards_2014,
  location = {{Baltimore, Maryland}},
  title = {Towards Segment-Based Recognition of Argumentation Structure in Short Texts},
  url = {http://www.aclweb.org/anthology/W14-2112},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {88--97},
  author = {Peldszus, Andreas}
}

@article{baker_better_2010,
  langid = {english},
  title = {Better to Be Frustrated than Bored: {{The}} Incidence, Persistence, and Impact of Learners’ Cognitive–affective States during Interactions with Three Different Computer-Based Learning Environments},
  volume = {68},
  issn = {10715819},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581909001797},
  doi = {10.1016/j.ijhcs.2009.12.003},
  shorttitle = {Better to Be Frustrated than Bored},
  number = {4},
  journaltitle = {International Journal of Human-Computer Studies},
  urldate = {2014-06-17},
  date = {2010-04},
  pages = {223-241},
  author = {Baker, Ryan S.J.d. and D'Mello, Sidney K. and Rodrigo, Ma.Mercedes T. and Graesser, Arthur C.},
  note = {00293}
}

@article{joel_katzav_modelling_2008,
  title = {Modelling Argument Recognition and Reconstruction},
  issn = {0378-2166},
  doi = {10.1016/j.pragma.2007.07.004},
  journaltitle = {Journal of Pragmatics},
  date = {2008},
  author = {Joel Katzav, Chris Reed}
}

@inproceedings{punyakanok_semantic_2004,
  location = {{Stroudsburg, PA, USA}},
  title = {Semantic Role Labeling via Integer Linear Programming Inference},
  url = {http://dx.doi.org/10.3115/1220355.1220552},
  doi = {10.3115/1220355.1220552},
  abstract = {We present a system for the semantic role labeling task. The system combines a machine learning technique with an inference procedure based on integer linear programming that supports the incorporation of linguistic and structural constraints into the decision process. The system is tested on the data provided in CoNLL-2004 shared task on semantic role labeling and achieves very competitive results.},
  booktitle = {Proceedings of the 20th International Conference on {{Computational Linguistics}}},
  series = {COLING '04},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2013-07-31},
  date = {2004},
  author = {Punyakanok, Vasin and Roth, Dan and Yih, Wen-tau and Zimak, Dav},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DGZ9E5RC/Punyakanok et al. - 2004 - Semantic role labeling via integer linear programm.pdf},
  note = {00164}
}

@article{craig_affect_2004,
  langid = {english},
  title = {Affect and Learning: {{An}} Exploratory Look into the Role of Affect in Learning with {{AutoTutor}}},
  volume = {29},
  issn = {1358-1651},
  url = {http://www.tandfonline.com/doi/abs/10.1080/1358165042000283101},
  doi = {10.1080/1358165042000283101},
  shorttitle = {Affect and Learning},
  number = {3},
  journaltitle = {Journal of Educational Media},
  urldate = {2014-09-30},
  date = {2004-10},
  pages = {241-250},
  author = {Craig, Scotty and Graesser, Arthur and Sullins, Jeremiah and Gholson, Barry},
  note = {00408}
}

@article{erpenbeck_kompetenz_2002,
  title = {Kompetenz Und {{Performanz}} Im {{Bild}} Moderner {{Selbstorganisationstheorie}}},
  volume = {21},
  url = {http://www.forschungsnetzwerk.at/downloadpub/erpenbeck_03_4_2002.pdf},
  journaltitle = {Bundesinstitut für Berufsbildung (Hg.): Berufsbildung für eine globale Gesellschaft. Perspektiven im},
  urldate = {2016-07-27},
  date = {2002},
  pages = {1--12},
  author = {Erpenbeck, John},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GR53BF7T/erpenbeck_03_4_2002.pdf},
  note = {00010}
}

@inproceedings{smith_bootstrapping_2007,
  title = {Bootstrapping {{Feature}}-{{Rich Dependency Parsers}} with {{Entropic Priors}}.},
  url = {http://acl.ldc.upenn.edu/D/D07/D07-1070.pdf},
  booktitle = {{{EMNLP}}-{{CoNLL}}},
  urldate = {2013-07-26},
  date = {2007},
  pages = {667--677},
  author = {Smith, David A. and Eisner, Jason},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Parsing\\Dependency\\D07-1070_Bootstrapping Feature-Rich Dependency Parsers with Entropic Priors.pdf},
  note = {00024}
}

@article{kaiser_neural_2015,
  title = {Neural Gpus Learn Algorithms},
  url = {http://arxiv.org/abs/1511.08228},
  journaltitle = {arXiv preprint arXiv:1511.08228},
  urldate = {2016-10-25},
  date = {2015},
  author = {Kaiser, $\backslash$Lukasz and Sutskever, Ilya},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/IZ5IWJWZ/1511.08228.pdf}
}

@inreference{_affekt_2014,
  langid = {german},
  title = {Affekt},
  url = {http://de.wikipedia.org/w/index.php?title=Affekt&oldid=132980447},
  abstract = {Der Affekt (von lat. afficere: antun; in einen Zustand versetzen; mit etwas erfüllen, versehen) ist eine Gemütserregung (englisch: occurring emotion etwas, das einem passiert).[1] Sie hat eine Ausdrucksdimension, eine körperliche Dimension und eine motivationale Dimension. Ein Lächeln kann beispielsweise ein Ausdruck für den Affekt Sympathie sein, Erröten, im körperlichen Bereich, bezeichnend für den Affekt Scham und die Bereitschaft, mit der Faust auf den Tisch zu hauen, eine charakteristische Motivation aus dem Affekt Zorn heraus sein.[2]},
  booktitle = {Wikipedia},
  urldate = {2014-09-29},
  date = {2014-09-29T20:37:45Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GCWJK2QC/index.html;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/T56F653N/index.html;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Z5VW6XHX/index.html},
  note = {00003 
Page Version ID: 132980447}
}

@inproceedings{schneider_automated_2014,
  location = {{Baltimore, Maryland}},
  title = {Automated Argumentation Mining to the Rescue? {{Envisioning}} Argumentation and Decision-Making Support for Debates in Open Online Collaboration Communities},
  url = {http://www.aclweb.org/anthology/W14-2108},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {59--63},
  author = {Schneider, Jodi}
}

@online{_manuel_????,
  title = {Manuel {{Kountz}} - {{Deutschland}} | {{LinkedIn}}},
  url = {http://de.linkedin.com/pub/manuel-kountz/83/b62/65},
  urldate = {2014-03-27},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/RGV7J4JR/65.html},
  note = {00000}
}

@inproceedings{bamman_open_2015,
  location = {{Lisbon, Portugal}},
  title = {Open {{Extraction}} of {{Fine}}-{{Grained Political Statements}}},
  url = {http://aclweb.org/anthology/D15-1008},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-09},
  pages = {76--85},
  author = {Bamman, David and Smith, Noah A.}
}

@book{ekman_gesichtsausdruck_1988,
  title = {Gesichtsausdruck Und {{Gefühl}}: 20 {{Jahre Forschung}} von {{Paul Ekman}}},
  shorttitle = {Gesichtsausdruck Und {{Gefühl}}},
  publisher = {{Junfermann-Verlag}},
  date = {1988},
  author = {Ekman, Paul and von Salisch, Maria},
  options = {useprefix=true},
  note = {00188}
}

@inproceedings{brants_tiger_2002,
  title = {The {{TIGER}} Treebank},
  volume = {168},
  url = {http://www.coli.uni-saarland.de/publikationen/softcopies/Brants:2002:TT.pdf},
  booktitle = {Proceedings of the Workshop on Treebanks and Linguistic Theories},
  urldate = {2014-03-27},
  date = {2002},
  author = {Brants, Sabine and Dipper, Stefanie and Hansen, Silvia and Lezius, Wolfgang and Smith, George},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/S9K7QMNK/Brants2002TT.pdf},
  note = {00547}
}

@book{verheij_computational_2012,
  langid = {english},
  title = {Computational {{Models}} of {{Argument}}: {{Proceedings}} of {{COMMA}} 2012},
  isbn = {978-1-61499-110-6},
  shorttitle = {Computational {{Models}} of {{Argument}}},
  abstract = {The subject of argumentation has been studied since ancient times, but it has seen major innovations since the advent of the computer age. Software already exists which can create and evaluate arguments in high-stake situations, such as medical diagnosis and criminal investigation; formal systems can help us appreciate the role of the value judgments which underlie opposing positions; and it is even possible to enter into argumentative dialogues as if playing a computer game. This book presents the 28 full papers, 17 short papers and a number of system demonstrations, described in an extended abstract, from the 2012 biennial Computational Models of Argument (COMMA) conference, held in Vienna, Austria. Papers by the invited speakers Professor Trevor Bench-Capon, Professor Erik Krabbe and Professor Keith Stenning are also included. This year, for the first time, COMMA invited the submission of papers for an innovative applications track, and those which were accepted for presentation are included in this volume. Argumentation can be studied from many angles, including the artificial, natural and theoretical systems perspective.Presentations at the 2012 conference addressed the subject from these perspectives and many more.},
  publisher = {{IOS Press}},
  date = {2012},
  keywords = {Computers / Intelligence (AI) & Semantics},
  author = {Verheij, Bart and Szeider, Stefan and Woltran, Stefan}
}

@article{bex_argublogging_2014,
  title = {{{ArguBlogging}}: {{An}} Application for the {{Argument Web}}},
  volume = {25},
  issn = {1570-8268},
  url = {http://www.sciencedirect.com/science/article/pii/S1570826814000079},
  doi = {10.1016/j.websem.2014.02.002},
  shorttitle = {{{ArguBlogging}}},
  abstract = {In this paper, we present a software tool for ‘ArguBlogging’, which allows users to construct debate and discussions across blogs, linking existing and new online resources to form distributed, structured conversations. Arguments and counterarguments can be posed by giving opinions on one’s own blog and replying to other bloggers’ posts. The resulting argument structure is connected to the Argument Web, in which argumentative structures are made semantically explicit and machine-processable. We discuss the ArguBlogging tool and the underlying infrastructure and ontology of the Argument Web.},
  journaltitle = {Web Semantics: Science, Services and Agents on the World Wide Web},
  date = {2014-03},
  pages = {9--15},
  keywords = {Argumentation,Blogging,Opinions,Web Apps},
  author = {Bex, Floris and Snaith, Mark and Lawrence, John and Reed, Chris}
}

@collection{cardie_proceedings_2015-1,
  location = {{Denver, Colorado}},
  title = {Proceedings of the {{Second Workshop}} on {{Argumentation Mining}}},
  url = {http://aclweb.org/anthology/W15-05},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  editor = {Cardie, Claire}
}

@unpublished{neumann_open_2012,
  venue = {{DFKI}},
  title = {Open {{Domain Information Extraction}}},
  url = {http://www.dfki.de/~neumann/InformationExtractionLecture2011/sessions/10-openIE.pdf},
  date = {2012-01-27},
  author = {Neumann, Günter},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Fachsemester\\Informatik\\Text Mining\\Open IE\\Wu Weld Presentation_10-openIE.pdf},
  note = {00000}
}

@incollection{dweck_messages_2002,
  location = {{San Diego,  CA,  US}},
  title = {Messages That Motivate: {{How}} Praise Molds Students' Beliefs, Motivation, and Performance (in Surprising Ways)},
  isbn = {0-12-064455-X (Hardcover)},
  shorttitle = {Messages That Motivate},
  abstract = {Shows how the feedback teachers give to students can mold their beliefs about their intelligence and, in turn, their motivation and achievement. In discussing beliefs that play a key role in motivation, the author focuses on one particular kind of belief, namely, students' "theories" about their intelligence. Two of these theories are describe: the belief that intelligence is a fixed trait that cannot be developed vs the idea that intelligence is a malleable quality, a potential that can be cultivated. Then, the author explains how these theories of intelligence can be changed to increase motivation and achievement.},
  booktitle = {Improving Academic Achievement:  {{Impact}} of Psychological Factors on Education},
  publisher = {{Academic Press}},
  date = {2002},
  pages = {37-60},
  keywords = {*Academic Achievement,*Academic Achievement Motivation,*Intelligence,*Motivation,Student Attitudes},
  author = {Dweck, Carol S.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/S7SDV59X/2002-17014-003.html},
  note = {00235}
}

@inproceedings{walker_annotating_2014,
  location = {{Baltimore, Maryland}},
  title = {Annotating {{Patterns}} of {{Reasoning}} about {{Medical Theories}} of {{Causation}} in {{Vaccine Cases}}: {{Toward}} a {{Type System}} for {{Arguments}}},
  url = {http://www.aclweb.org/anthology/W14-2101},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {1--10},
  author = {Walker, Vern and Vazirova, Karina and Sanford, Cass}
}

@incollection{boekaerts_towards_2003,
  title = {Towards a Model That Integrates Motivation, Affect and Learning},
  volume = {173},
  number = {189},
  booktitle = {{{BJEP Monograph Series II}}, {{Number}} 2-{{Development}} and {{Motivation}}},
  publisher = {{British Psychological Society}},
  date = {2003},
  pages = {173--189},
  author = {Boekaerts, Monique},
  note = {00058}
}

@article{wyner_semi-automated_2012,
  title = {Semi-{{Automated Argumentative Analysis}} of {{Online Product Reviews}}.},
  volume = {245},
  journaltitle = {COMMA},
  date = {2012},
  pages = {43--50},
  author = {Wyner, Adam and Schneider, Jodi and Atkinson, Katie and Bench-Capon, Trevor JM}
}

@article{cabrio_combining_2012,
  title = {Combining {{Textual Entailment}} and {{Argumentation Theory}} for {{Supporting Online Debates Interactions}}},
  volume = {2},
  url = {http://aclanthology.info/papers/combining-textual-entailment-and-argumentation-theory-for-supporting-online-debates-interactions},
  journaltitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  date = {2012},
  pages = {208--212},
  author = {Cabrio, Elena and Villata, Serena}
}

@online{_syntax.._????,
  title = {Syntax.. 2},
  url = {http://hu-berlin.hosted.exlibrisgroup.com/primo_library/libweb/action/dlDisplay.do?vid=hub_ub&afterPDS=true&docId=HUB_UB_ALMA_DS21607931800002882},
  urldate = {2017-04-01},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/AFUKCX24/display.html}
}

@inreference{_lojban_2013,
  langid = {german},
  title = {Lojban},
  url = {http://de.wikipedia.org/w/index.php?title=Lojban&oldid=120754025},
  abstract = {Die Plansprache Lojban [ˈloʒban] (Sprachcode nach ISO 639-2: jbo) wurde 1987 von der Logical Language Group entwickelt. Sie basiert auf der ebenfalls künstlichen Sprache Loglan. Bei der Entwicklung wurde besonderer Wert darauf gelegt, eine benutzbare, möglichst umfassende und frei verfügbare Sprache zu schaffen. Der Wortschatz der Grundwörter ist aus Wortstämmen der sechs weltweit meistgesprochenen Sprachen nach einem bestimmten Algorithmus gebildet. Diese Ursprungssprachen sind Arabisch, Chinesisch, Englisch, Hindi, Russisch, Spanisch.},
  booktitle = {Wikipedia},
  urldate = {2013-07-24},
  date = {2013-07-23T22:23:21Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/AGRH5FRB/index.html},
  note = {00000 
Page Version ID: 120754025}
}

@article{barrett_experience_2007,
  title = {The {{Experience}} of {{Emotion}}},
  volume = {58},
  issn = {0066-4308},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1934613/},
  doi = {10.1146/annurev.psych.58.110405.085709},
  abstract = {Experiences of emotion are content-rich events that emerge at the level of psychological description, but must be causally constituted by neurobiological processes. This chapter outlines an emerging scientific agenda for understanding what these experiences feel like and how they arise. We review the available answers to what is felt (i.e., the content that makes up an experience of emotion) and how neurobiological processes instantiate these properties of experience. These answers are then integrated into a broad framework that describes, in psychological terms, how the experience of emotion emerges from more basic processes. We then discuss the role of such experiences in the economy of the mind and behavior.},
  journaltitle = {Annual review of psychology},
  shortjournal = {Annu Rev Psychol},
  urldate = {2014-09-29},
  date = {2007},
  pages = {373-403},
  author = {Barrett, Lisa Feldman and Mesquita, Batja and Ochsner, Kevin N. and Gross, James J.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JDCAW4WP/Barrett et al. - 2007 - The Experience of Emotion.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XCZDUFF5/Barrett et al. - 2007 - The Experience of Emotion.pdf},
  eprinttype = {pmid},
  eprint = {17002554},
  pmcid = {PMC1934613},
  note = {00791}
}

@inproceedings{bohnet_very_2010,
  title = {Very High Accuracy and Fast Dependency Parsing Is Not a Contradiction},
  url = {http://dl.acm.org/citation.cfm?id=1873792},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Computational Linguistics}}},
  urldate = {2013-07-26},
  date = {2010},
  pages = {89--97},
  author = {Bohnet, Bernd},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Parsing\\Dependency\\p89-bohnet.pdf},
  note = {00358}
}

@article{meyer_discovering_2002,
  title = {Discovering Emotion in Classroom Motivation Research},
  volume = {37},
  url = {http://www.tandfonline.com/doi/abs/10.1207/S15326985EP3702_5},
  number = {2},
  journaltitle = {Educational psychologist},
  urldate = {2014-06-17},
  date = {2002},
  pages = {107--114},
  author = {Meyer, Debra K. and Turner, Julianne C.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/INJ264QR/Meyer_Emotion in Classroom Motivation Research.pdf},
  note = {00392}
}

@inproceedings{strain_exploring_2012,
  title = {Exploring Relationships between Learners’ Affective States, Metacognitive Processes, and Learning Outcomes},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-30950-2_8},
  booktitle = {Intelligent {{Tutoring Systems}}},
  publisher = {{Springer}},
  urldate = {2014-09-29},
  date = {2012},
  pages = {59--64},
  author = {Strain, Amber Chauncey and Azevedo, Roger and D’Mello, Sidney},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZXK5CU74/strain-ff-its12.pdf},
  note = {00005}
}

@book{walton_argumentation_2008,
  langid = {english},
  location = {{Cambridge [u.a.]}},
  title = {Argumentation Schemes},
  edition = {1. publ},
  isbn = {978-0-521-89790-7},
  url = {http://www.loc.gov/catdir/enhancements/fy0809/2007045337-b.html},
  publisher = {{Cambridge Univ. Press}},
  date = {2008},
  keywords = {Argumentationstheorie},
  author = {Walton, Douglas N. and Reed, Chris and Macagno, Fabrizio},
  note = {Hier auch später erschienene, unveränderte Nachdrucke}
}

@book{_natural_0,
  langid = {english},
  title = {Natural {{Language Arguments}}: {{A Combined Approach}}.},
  url = {http://hal.inria.fr/hal-00724780},
  shorttitle = {Natural {{Language Arguments}}},
  abstract = {With the growing use of the Social Web, an increasing number of applications for exchanging opinions with other people are becoming available online. These applications are widely adopted with the consequence that the number of opinions about the debated issues increases. In order to cut in on a debate, the participants need first to evaluate the opinions in favour or against the debated issue. Argumentation theory proposes algorithms and semantics to evaluate the set of accepted arguments, given the conflicts among them. The main problem is how to automatically generate the arguments from the natural language formulation of the opinions used in these applications. Our paper addresses this problem by proposing and evaluating the use of natural language techniques to generate the arguments. In particular, we adopt the textual entailment approach, a generic framework for applied semantics, where linguistic objects are mapped by means of semantic inferences at a textual level. We couple textual entailment together with a Dung-like argumentation system which allows us to identify the arguments that are accepted in the considered online debate. The originality of the proposed framework lies in the following point: natural language debates are ana- lyzed and the arguments are automatically extracted.},
  date = {0000}
}

@book{lawler_using_1998,
  langid = {english},
  title = {Using {{Computers}} in {{Linguistics}}: {{A Practical Guide}}},
  isbn = {978-0-415-16792-5},
  shorttitle = {Using {{Computers}} in {{Linguistics}}},
  abstract = {Computing has had a dramatic impact on the discipline of linguistics and is shaping the way we conceptualize both linguistics and language. Using Computers in Linguistics provides a non-technical introduction to recent developments in linguistic computing and offers specific guidance to the linguist or language professional who wishes to take advantage of them. Divided into eight chapters, each of the expert contributors focus on a different aspect of the interaction of computing and linguistics looking either at computational resources: the Internet, software for fieldwork and teaching linguistics, Unix utilities, or at computational developments: the availability of electronic texts, new methodologies in natural language processing, the development of the CELLAR computing environment for linguistic analysis.},
  pagetotal = {628},
  publisher = {{Routledge}},
  date = {1998},
  keywords = {Language Arts & Disciplines / Linguistics / General},
  author = {Lawler, John M. and Dry, Hellen Aristar},
  note = {00056}
}

@article{walton_how_2011,
  title = {How to {{Refute}} an {{Argument Using Artificial Intelligence}}},
  date = {2011},
  author = {Walton, Douglas}
}

@incollection{fillmore_case_1968,
  location = {{London}},
  title = {The {{Case}} for {{Case}}},
  url = {http://pdf.thepdfportal.com/PDFFiles/123480.pdf},
  booktitle = {Universals in Linguistic Theory},
  publisher = {{Holt, Rinehart and Winston}},
  urldate = {2014-03-31},
  date = {1968},
  pages = {1-88},
  author = {Fillmore, Charles J.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BZX554XN/fillmore.pdf},
  note = {08717}
}

@inproceedings{carstens_enhancing_2013,
  location = {{New York, NY, USA}},
  title = {Enhancing {{Sentiment Extraction}} from {{Text}} by {{Means}} of {{Arguments}}},
  isbn = {978-1-4503-2332-1},
  url = {http://doi.acm.org/10.1145/2502069.2502073},
  doi = {10.1145/2502069.2502073},
  abstract = {Sentiment Analysis is concerned with (1) differentiating opinionated text from factual text and, in the case of opinionated text, (2) determine its polarity. With this paper, we address problem (1) and present A-SVM (Argument enhanced Support Vector Machines), a multimodal system that focuses on the discrimination of opinionated text from non-opinionated text with the help of (i) Support Vector Machines (SVM) and (ii) arguments, acquired by means of a user feedback mechanism, and used to improve the SVM classifications. We have used a prototype to investigate the validity of approaching Sentiment Analysis in this multi faceted manner by comparing straightforward Machine Learning techniques with our multimodal system architecture. All evaluations were executed using a purpose-built corpus of annotated text and A-SVM's classification performance was compared to that of SVM. The classification of a test set of approximately 4,500 n-grams yielded an increase in classification precision of 5.6\%.},
  booktitle = {Proceedings of the {{Second International Workshop}} on {{Issues}} of {{Sentiment Discovery}} and {{Opinion Mining}}},
  series = {WISDOM '13},
  publisher = {{ACM}},
  date = {2013},
  pages = {4:1--4:9},
  keywords = {A-SVM,Argumentation,sentiment analysis,support vector machines,user feedback},
  author = {Carstens, Lucas and Toni, Francesca}
}

@inproceedings{carstens_towards_2015,
  location = {{Denver, CO}},
  title = {Towards Relation Based {{Argumentation Mining}}},
  url = {http://www.aclweb.org/anthology/W15-0504},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {29--34},
  author = {Carstens, Lucas and Toni, Francesca}
}

@article{kast_wie_2007,
  title = {Wie Der {{Bauch}} Dem {{Kopf}} Beim {{Denken}} Hilft},
  url = {http://www.denkladen.de/docs/703980Rezm.pdf},
  journaltitle = {Die Kraft der Intuition. Frankfurt a./M},
  urldate = {2014-09-30},
  date = {2007},
  author = {Kast, Bas},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MCK7FDXH/703980Rezm.pdf},
  note = {00062}
}

@inproceedings{del_corro_clausie_2013,
  title = {{{ClausIE}}: Clause-Based Open Information Extraction},
  url = {http://dl.acm.org/citation.cfm?id=2488420},
  shorttitle = {{{ClausIE}}},
  booktitle = {Proceedings of the 22nd International Conference on {{World Wide Web}}},
  urldate = {2013-07-26},
  date = {2013},
  pages = {355--366},
  author = {Del Corro, Luciano and Gemulla, Rainer},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/48WDTS32/delcorro13clausie.pdf;C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\delcorro13clausie.pdf},
  note = {00082}
}

@book{bianka_trevisan_indicators_2014,
  langid = {english},
  title = {Indicators of {{Argument}}-Conclusion {{Relationships}}. {{An Approach}} for {{Argumentation Mining}} in {{German Discourses}}},
  url = {http://dx.doi.org/10.13140/2.1.3623.5044},
  publisher = {{Unpublished}},
  date = {2014},
  author = {{Bianka Trevisan} and {Eva-Maria Jakobs} and {Eva Dickmeis} and {Thomas Niehr}}
}

@book{meyer_einfuhrung_2001,
  langid = {Deutsch},
  location = {{Bern etc.}},
  title = {Einführung in die Emotionspsychologie, Bd.1, Die Emotionstheorien von Watson, James und Schachter},
  edition = {Auflage: 2., überarb. Aufl.},
  isbn = {978-3-456-83648-5},
  abstract = {Für die Neuauflage wurde der Band I der nun dreibändigen «Einführung in die Emotionspsychologie» vollständig überarbeitet. Im Gegensatz zu den vorhandenen deutschsprachigen Lehrbüchern zur Emotionspsychologie ist diese Einführung explizit theorieorientiert. Der Text wurde so gestaltet, dass er einerseits grundlegend genug ist, um auch für Anfänger verständlich zu sein, andererseits aber auch präzise genug, um Leserinnen und Leser auf die selbständige Lektüre der Fachliteratur vorzubereiten. Im einführenden Kapitel werden grundlegende Begriffe und Konzepte der Emotionspsychologie erläutert. In den drei nachfolgenden Kapiteln werden die klassisch-behavioristische Theorie der Emotionen und ihre Nachwirkungen (Kapitel 2), die Emotionstheorie von William James und neo-jamesianische Emotionstheorien (Kapitel 3) sowie kognitiv-physiologische Theorien der Emotionen (Kapitel 4) behandelt. In jedem Kapitel werden die neuesten einschlägigen Forschungsergebnisse berücksichtigt. Darüber schlagen die Autoren Brücken zur Klinischen Psychologie.},
  pagetotal = {236},
  publisher = {{Huber, Bern}},
  date = {2001-09-24},
  author = {Meyer, Wulf-Uwe and Reisenzein, Rainer and Schützwohl, Achim},
  note = {00000}
}

@incollection{vanlehn_architecture_2002,
  langid = {english},
  title = {The {{Architecture}} of {{Why2}}-{{Atlas}}: {{A Coach}} for {{Qualitative Physics Essay Writing}}},
  isbn = {978-3-540-43750-5 978-3-540-47987-1},
  url = {http://link.springer.com/chapter/10.1007/3-540-47987-2_20},
  shorttitle = {The {{Architecture}} of {{Why2}}-{{Atlas}}},
  abstract = {The Why2-Atlas system teaches qualitative physics by having students write paragraph-long explanations of simple mechanical phenomena. The tutor uses deep syntactic analysis and abductive theorem proving to convert the student’s essay to a proof. The proof formalizes not only what was said, but the likely beliefs behind what was said. This allows the tutor to uncover misconceptions as well as to detect missing correct parts of the explanation. If the tutor finds such a flaw in the essay, it conducts a dialogue intended to remedy the missing or misconceived beliefs, then asks the student to correct the essay. It often takes several iterations of essay correction and dialogue to get the student to produce an acceptable explanation. Pilot subjects have been run, and an evaluation is in progress. After explaining the research questions that the system addresses, the bulk of the paper describes the system’s architecture and operation.},
  number = {2363},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer Berlin Heidelberg}},
  urldate = {2014-09-28},
  date = {2002-01-01},
  pages = {158-167},
  keywords = {Artificial Intelligence (incl. Robotics),Computers and Education,Information Systems Applications (incl.Internet),Multimedia Information Systems,User Interfaces and Human Computer Interaction},
  author = {VanLehn, Kurt and Jordan, Pamela W. and Rosé, Carolyn P. and Bhembe, Dumisizwe and Böttner, Michael and Gaydos, Andy and Makatchev, Maxim and Pappuswamy, Umarani and Ringenberg, Michael and Roque, Antonio and Siler, Stephanie and Srivastava, Ramesh},
  editor = {Cerri, Stefano A. and Gouardères, Guy and Paraguaçu, Fàbio},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/E9NKEWVX/3-540-47987-2_20.html},
  note = {00221}
}

@article{kurach_neural_2015,
  title = {Neural Random-Access Machines},
  url = {http://arxiv.org/abs/1511.06392},
  journaltitle = {arXiv preprint arXiv:1511.06392},
  urldate = {2016-10-25},
  date = {2015},
  author = {Kurach, Karol and Andrychowicz, Marcin and Sutskever, Ilya},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ME56A78A/1511.06392.pdf}
}

@article{brosch_3_2008,
  title = {3 {{Plädoyer}} Für Das {{Komponenten}}-{{Prozess}}-{{Modell}} Als Theoretische {{Grundlage}} Der Experimentellen {{Emotionsforschung}}},
  url = {http://www.affective-sciences.ch/system/files/biblio/Brosch%26Scherer_2008_KPM.pdf},
  urldate = {2014-09-10},
  date = {2008},
  author = {Brosch, Tobias and Scherer, Klaus R.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/PWBDGKKG/Brosch&Scherer_2008_KPM.pdf},
  note = {00004}
}

@article{walton_artificial_????,
  title = {Some {{Artificial Intelligence Tools}} for {{Argument Evaluation}}: {{An Introduction}}},
  shorttitle = {Some {{Artificial Intelligence Tools}} for {{Argument Evaluation}}},
  journaltitle = {Argumentation},
  pages = {1--24},
  author = {Walton, Douglas}
}

@article{anderson_what_2001,
  title = {What Role Do Cognitive Architectures Play in Intelligent Tutoring Systems},
  url = {http://books.google.de/books?hl=de&lr=&id=wYm1vg4LU-wC&oi=fnd&pg=PA227&dq=Intelligent+tutoring+system+cognitive+states+-affect&ots=0nvlaWVHME&sig=gg0db-55KXMJ3tWayuHbmjZLPos},
  journaltitle = {Cognition \& Instruction: Twenty-five years of progress},
  urldate = {2014-09-29},
  date = {2001},
  pages = {227--262},
  author = {Anderson, John R. and Gluck, Kevin},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XCXNI4RE/Anderson und Gluck - 2001 - What role do cognitive architectures play in intel.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3MC35M9I/books.html},
  note = {00100}
}

@article{peldszus_argument_2013,
  title = {From {{Argument Diagrams}} to {{Argumentation Mining}} in {{Texts}}: {{A Survey}}},
  volume = {7},
  issn = {1557-3958},
  url = {http://www.ling.uni-potsdam.de/ peldszus/ijcini2013-preprint.pdf},
  doi = {10.4018/jcini.2013010101},
  shorttitle = {From {{Argument Diagrams}} to {{Argumentation Mining}} in {{Texts}}},
  abstract = {In this paper, the authors consider argument mining as the task of building a formal representation for an argumentative piece of text. Their goal is to provide a critical survey of the literature on both the resulting representations i.e., argument diagramming techniques and on the various aspects of the automatic analysis process. For representation, the authors also provide a synthesized proposal of a scheme that combines advantages from several of the earlier approaches; in addition, the authors discuss the relationship between representing argument structure and the rhetorical structure of texts in the sense of Mann and Thompsons 1988 RST. Then, for the argument mining problem, the authors also cover the literature on closely-related tasks that have been tackled in Computational Linguistics, because they think that these can contribute to more powerful argument mining systems than the first prototypes that were built in recent years. The paper concludes with the authors' suggestions for the major challenges that should be addressed in the field of argument mining.},
  number = {1},
  journaltitle = {International Journal of Cognitive Informatics and Natural Intelligence},
  date = {2013-01},
  pages = {1--31},
  keywords = {Annotation Scheme,Argument Diagram,Argumentation,Rhetorical Structure Theory,Theory of Argumentation Structure,argument mining},
  author = {Peldszus, Andreas and Stede, Manfred},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/5Q3DUCMX/From Argument Diagrams to Argumentation Mining in Texts A Survey.pdf},
  note = {http://dx.doi.org/10.4018/jcini.2013010101}
}

@inproceedings{reisert_computational_2015,
  location = {{Denver, CO}},
  title = {A {{Computational Approach}} for {{Generating Toulmin Model Argumentation}}},
  url = {http://www.aclweb.org/anthology/W15-0507},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {45--55},
  author = {Reisert, Paul and Inoue, Naoya and Okazaki, Naoaki and Inui, Kentaro}
}

@inproceedings{fader_identifying_2011,
  location = {{Stroudsburg, PA, USA}},
  title = {Identifying Relations for Open Information Extraction},
  isbn = {978-1-937284-11-4},
  url = {http://dl.acm.org/citation.cfm?id=2145432.2145596},
  abstract = {Open Information Extraction (IE) is the task of extracting assertions from massive corpora without requiring a pre-specified vocabulary. This paper shows that the output of state-of-the-art Open IE systems is rife with uninformative and incoherent extractions. To overcome these problems, we introduce two simple syntactic and lexical constraints on binary relations expressed by verbs. We implemented the constraints in the ReVerb Open IE system, which more than doubles the area under the precision-recall curve relative to previous extractors such as TextRunner and woepos. More than 30\% of ReVerb's extractions are at precision 0.8 or higher---compared to virtually none for earlier systems. The paper concludes with a detailed analysis of ReVerb's errors, suggesting directions for future work.},
  booktitle = {Proceedings of the {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  series = {EMNLP '11},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2013-07-29},
  date = {2011},
  pages = {1535--1545},
  author = {Fader, Anthony and Soderland, Stephen and Etzioni, Oren},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/93RWFCEZ/Fader et al. - 2011 - Identifying relations for open information extract.pdf},
  note = {00513}
}

@inproceedings{park_identifying_2014,
  location = {{Baltimore, Maryland}},
  title = {Identifying {{Appropriate Support}} for {{Propositions}} in {{Online User Comments}}},
  url = {http://www.aclweb.org/anthology/W14-2105},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {29--38},
  author = {Park, Joonsuk and Cardie, Claire}
}

@article{immordino-yang_we_2007,
  title = {We Feel, Therefore We Learn: {{The}} Relevance of Affective and Social Neuroscience to Education},
  volume = {1},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1751-228X.2007.00004.x/full},
  shorttitle = {We Feel, Therefore We Learn},
  number = {1},
  journaltitle = {Mind, brain, and education},
  urldate = {2014-09-30},
  date = {2007},
  pages = {3--10},
  author = {Immordino-Yang, Mary Helen and Damasio, Antonio},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/USQV44MS/j.1751-228X.2007.00004.x.pdf},
  note = {00570}
}

@inproceedings{das_semafor_2010,
  title = {{{SEMAFOR}} 1.0: {{Probabilistic}} Frame-Semantic Parsing},
  url = {http://dl.acm.org/citation.cfm?id=1858136},
  booktitle = {Human Language Technologies: {{The}} 2010 Annual Conference of the {{North American}} Chapter of the Association for Computational Linguistics},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2014-03-31},
  date = {2010},
  pages = {948--956},
  author = {Das, Dipanjan and Schneider, Nathan and Chen, Desai and Smith, Noah A.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/EZHTG5V6/das+schneider+chen+smith.tr10.pdf},
  note = {00000}
}

@inproceedings{peldszus_towards_2015,
  location = {{Denver, CO}},
  title = {Towards {{Detecting Counter}}-Considerations in {{Text}}},
  url = {http://www.aclweb.org/anthology/W15-0513},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {104--109},
  author = {Peldszus, Andreas and Stede, Manfred}
}

@article{d._hitchcock_pragma-dialectical_2011,
  title = {The Pragma-Dialectical Account of Argument Schemes},
  date = {2011},
  author = {D. Hitchcock, J. Wagemans}
}

@article{frijda_laws_1988,
  title = {The Laws of Emotion.},
  volume = {43},
  url = {http://psycnet.apa.org/journals/amp/43/5/349/},
  number = {5},
  journaltitle = {American psychologist},
  urldate = {2014-09-29},
  date = {1988},
  pages = {349},
  author = {Frijda, Nico H.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GR7J9VZ7/Laws of Emotion.pdf},
  note = {00733}
}

@inproceedings{surdeanu_ensemble_2010,
  title = {Ensemble Models for Dependency Parsing: Cheap and Good?},
  url = {http://dl.acm.org/citation.cfm?id=1858090},
  shorttitle = {Ensemble Models for Dependency Parsing},
  booktitle = {Human {{Language Technologies}}: {{The}} 2010 {{Annual Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  urldate = {2013-07-26},
  date = {2010},
  pages = {649--652},
  author = {Surdeanu, Mihai and Manning, Christopher D.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Parsing\\Dependency\\naacl10-parsing-surdeanu_Ensemble Models for Dependency Parsing.pdf},
  note = {00058}
}

@thesis{das_semi-supervised_2012,
  title = {Semi-{{Supervised}} and {{Latent}}-{{Variable Models}} of {{Natural Language Semantics}}},
  url = {http://www.lti.cs.cmu.edu/research/thesis/2012/cmulti12007.pdf},
  institution = {{University of Illinois}},
  urldate = {2014-03-31},
  date = {2012},
  author = {Das, Dipanjan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XQIFPJCQ/thesis.pdf},
  note = {00007}
}

@book{walton_argumentation_1996,
  langid = {english},
  location = {{Mahwah, N.J}},
  title = {Argumentation Schemes for Presumptive Reasoning},
  isbn = {0-8058-2071-X},
  series = {LEA titles in argumentation},
  publisher = {{Erlbaum}},
  date = {1996},
  keywords = {Argumentation,Hypothese,Präsupposition},
  author = {Walton, Douglas N.}
}

@article{piggott_purification_1976,
  langid = {english},
  title = {Purification of Multiple Forms of Adenosine Deaminase from Rabbit Intestine},
  volume = {429},
  issn = {0006-3002},
  abstract = {Two forms of adenosine deaminase (adenosine aminohydrolase, EC 3.5.4.4), differing in molecular size, have been purified and obtained in homogeneous form from rabbit intestine. The purification procedures involved extraction with acetate buffer, pH 5.5, precipitation and fractional reextraction with (NH4)2SO4, ion-exchange chromatography on DEAE-cellulose and gel filtration on Sephadex G-75 and Sephadex G-200. Gel filtrations analysis gave molecular weight estimates of 265 000 and 32 000 for the large and small deaminases respectively. The two enzymes forms had similar pH optima and pH stability ranges.},
  number = {2},
  journaltitle = {Biochimica Et Biophysica Acta},
  shortjournal = {Biochim. Biophys. Acta},
  date = {1976-04-08},
  pages = {600-607},
  keywords = {Adenosine Deaminase,Animals,Drug Stability,Hydrogen-Ion Concentration,Intestines,Isoenzymes,Kinetics,Molecular Weight,Nucleoside Deaminases,Rabbits},
  author = {Piggott, C. O. and Brady, T. G.},
  eprinttype = {pmid},
  eprint = {4139}
}

@article{liebeck_what_2016,
  title = {What to {{Do}} with an {{Airport}}? {{Mining Arguments}} in the {{German Online Participation Project Tempelhofer Feld}}},
  url = {http://www.aclweb.org/anthology/W/W16/W16-28.pdf#page=156},
  shorttitle = {What to {{Do}} with an {{Airport}}?},
  journaltitle = {ACL 2016},
  urldate = {2016-12-01},
  date = {2016},
  pages = {144},
  author = {Liebeck, Matthias and Esau, Katharina and Conrad, Stefan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZZPAFMWT/W16-2817.pdf}
}

@inproceedings{bilu_automatic_2015,
  location = {{Denver, CO}},
  title = {Automatic {{Claim Negation}}: {{Why}}, {{How}} and {{When}}},
  url = {http://www.aclweb.org/anthology/W15-0511},
  shorttitle = {Automatic {{Claim Negation}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {84--93},
  author = {Bilu, Yonatan and Hershcovich, Daniel and Slonim, Noam}
}

@incollection{blanchard_automated_2014,
  langid = {english},
  title = {Automated {{Physiological}}-{{Based Detection}} of {{Mind Wandering}} during {{Learning}}},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_7},
  abstract = {Unintentional lapses of attention, or mind wandering, are ubiquitous and detrimental during learning. Hence, automated methods that detect and combat mind wandering might be beneficial to learning. As an initial step in this direction, we propose to detect mind wandering by monitoring physiological measures of skin conductance and skin temperature. We conducted a study in which student’s physiology signals were measured while they learned topics in research methods from instructional texts. Momentary self-reports of mind wandering were collected with standard probe-based methods. We computed features from the physiological signals in windows leading up to the probes and trained supervised classification models to detect mind wandering. We obtained a kappa, a measurement of accuracy corrected for random guessing, of .22, signaling feasibility of detecting MW in a student-independent manner. Though modest, we consider this result to be an important step towards fully-automated unobtrusive detection of mind wandering during learning.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {55-60},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,Multimedia Information Systems,User Interfaces and Human Computer Interaction,machine learning,mind wandering,skin conductance,skin temperature},
  author = {Blanchard, Nathaniel and Bixler, Robert and Joyce, Tera and D’Mello, Sidney},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MK78US5V/978-3-319-07221-0_7.html},
  note = {00000}
}

@article{zaremba_reinforcement_2015,
  title = {Reinforcement Learning Neural {{Turing}} Machines},
  volume = {362},
  url = {https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf},
  journaltitle = {arXiv preprint arXiv:1505.00521},
  urldate = {2016-10-25},
  date = {2015},
  author = {Zaremba, Wojciech and Sutskever, Ilya},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3IQG59JD/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf}
}

@article{wells_using_2008,
  title = {Using Dialogical Argument as an Interface to Complex Debates},
  volume = {27},
  issn = {0278-6648},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4625357},
  doi = {10.1109/MPOT.2008.928452},
  number = {5},
  journaltitle = {IEEE Potentials},
  date = {2008},
  pages = {26--30},
  author = {Wells, Simon and Reed, Chris}
}

@inproceedings{houy_towards_2013,
  title = {Towards Automated Identification and Analysis of Argumentation Structures in the Decision Corpus of the {{German Federal Constitutional Court}}},
  url = {http://www.dfki.de/lt/publication_show.php?id=6833},
  doi = {10.1109/DEST.2013.6611332},
  abstract = {Argumentation is an essential task in every scientific discipline. The development of strong and convincing argumentation as well as the analysis of existing argumentation structures is important in the field of humanities, and especially in the field of jurisprudence. Judicial argumentation requires sophisticated intellectual effort and the knowledge of as much potentially relevant background information as possible. Considering that the fulfillment of this task is limited by the natural human information processing capacity, the field of digital humanities investigates how such information-intensive and time-consuming tasks can be supported by computers. Against the background of the ever-growing availability of different corpora of jurisdiction in Germany, a software prototype supporting automated identification, analysis and recommendation of argumentation structures in electronically available corpora of jurisdiction is currently developed in the project ARGUMENTUM. In this article, we present the basic concept for the preparation and processing of the decision corpus of the German Federal Constitutional Court which shall provide the basis for the future ARGUMENTUM prototype.},
  booktitle = {2013 7th {{IEEE International Conference}} on {{Digital Ecosystems}} and {{Technologies}} ({{DEST}})},
  date = {2013-07},
  pages = {72--77},
  keywords = {ARGUMENTUM,Argumentation mining,Cognition,Context,German federal constitutional court,Indexes,Law,NLP,Prototypes,Vectors,argument mining,argumentation structures analysis,automated identification,decision corpus,decision making,digital humanities,eHumanities,humanities,information-intensive tasks,judicial argumentation,jurisprudence,natural human information processing capacity,public administration,software prototype,text mining,time-consuming tasks},
  author = {Houy, C. and Niesen, T. and Fettke, P. and Loos, P.}
}

@inproceedings{jaques_predicting_2014,
  title = {Predicting {{Affect}} from {{Gaze Data}} during {{Interaction}} with an {{Intelligent Tutoring System}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_4},
  booktitle = {Intelligent {{Tutoring Systems}}},
  publisher = {{Springer}},
  urldate = {2014-09-29},
  date = {2014},
  pages = {29--38},
  author = {Jaques, Natasha and Conati, Cristina and Harley, Jason M. and Azevedo, Roger},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/PTZN49NR/ITS-Natasha-2014.pdf},
  note = {00000}
}

@article{graesser_intelligent_2001,
  title = {Intelligent Tutoring Systems with Conversational Dialogue},
  volume = {22},
  url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/1591},
  number = {4},
  journaltitle = {AI magazine},
  urldate = {2014-09-28},
  date = {2001},
  pages = {39},
  author = {Graesser, Arthur C. and VanLehn, Kurt and Rosé, Carolyn P. and Jordan, Pamela W. and Harter, Derek},
  note = {00000}
}

@article{corbett_intelligent_1997,
  title = {Intelligent Tutoring Systems},
  url = {http://act-r.psy.cmu.edu/wordpress/wp-content/uploads/2012/12/173Chapter_37_Intelligent_Tutoring_Systems.pdf},
  journaltitle = {Handbook of humancomputer interaction},
  urldate = {2014-09-28},
  date = {1997},
  pages = {849--874},
  author = {Corbett, Albert T. and Koedinger, Kenneth R. and Anderson, John R.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XQCHMX9X/173Chapter_37_Intelligent_Tutoring_Systems.pdf},
  note = {00000}
}

@article{devedzic_education_2004,
  title = {Education and the {{Semantic W}} Eb},
  volume = {14},
  url = {http://www.info2.uqam.ca/~nkambou/DIC9340/seances/seance2-3-4-5/Ontology/IJAIED2004.pdf},
  journaltitle = {International Journal of Artificial Intelligence in Education},
  urldate = {2014-09-29},
  date = {2004},
  pages = {39-65},
  author = {Devedzic, Vladan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/VM2S2UHD/IJAIED2004.pdf},
  note = {00000}
}

@inproceedings{song_applying_2014,
  location = {{Baltimore, Maryland}},
  title = {Applying {{Argumentation Schemes}} for {{Essay Scoring}}},
  url = {http://www.aclweb.org/anthology/W14-2110},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {69--78},
  author = {Song, Yi and Heilman, Michael and Beigman Klebanov, Beata and Deane, Paul}
}

@online{__????,
  url = {https://scholar.googleusercontent.com/scholar.bib?q=info:u-4SYjm81owJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWOA1kpCZ3dJGqOrQ9woHW4qLwYg9ANCa&scisf=4&ct=citation&cd=-1&hl=de},
  urldate = {2017-04-01},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HRVBEWR3/scholar.html}
}

@article{iyad_rahwan_representing_2011,
  title = {Representing and Classifying Arguments on the {{Semantic Web}}},
  volume = {26},
  issn = {1469-8005},
  doi = {10.1017/S0269888911000191},
  number = {04},
  journaltitle = {The Knowledge Engineering Review},
  date = {2011},
  pages = {487 -- 511},
  author = {Iyad Rahwan, Bita Banihashemi}
}

@incollection{lee_towards_2014,
  langid = {english},
  title = {Towards {{Automatically Detecting Whether Student Is}} in {{Flow}}},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_2},
  abstract = {Csikszentmihalyi’s flow theory states the components (e.g., balance between skill and challenge) that lead to an optimal state (referred to as flow state, or under flow experience) of intrinsic motivation and personal experience. Recent research has begun to validate the claims stated by the theory and extend the provided statements to the design of pedagogical interactions. To incorporate the theory in a design, automatic detector of flow is required. However, little attention has been drawn to this filed, and the detection of flow is currently still dominated by using surveys. Hence, within this paper, we present an automated detector which is able to identify the students that are in flow. This detector is developed using a step regression approach, with data collected from college students learning linear algebra from a step-based tutoring system.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {11-18},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,Educational Data Mining,Flow Theory,Intelligent Tutoring System,Multimedia Information Systems,Student Modeling,User Interfaces and Human Computer Interaction},
  author = {Lee, Po-Ming and Jheng, Sin-Yu and Hsiao, Tzu-Chien},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/9TQCVDF2/978-3-319-07221-0_2.html},
  note = {00000}
}

@inproceedings{yates_textrunner_2007,
  location = {{Stroudsburg, PA, USA}},
  title = {{{TextRunner}}: {{Open Information Extraction}} on the {{Web}}},
  url = {http://dl.acm.org/citation.cfm?id=1614164.1614177},
  shorttitle = {{{TextRunner}}},
  abstract = {Traditional information extraction systems have focused on satisfying precise, narrow, pre-specified requests from small, homogeneous corpora. In contrast, the TextRunner system demonstrates a new kind of information extraction, called Open Information Extraction (OIE), in which the system makes a single, data-driven pass over the entire corpus and extracts a large set of relational tuples, without requiring any human input. (Banko et al., 2007) TextRunner is a fully-implemented, highly scalable example of OIE. TextRunner's extractions are indexed, allowing a fast query mechanism.},
  booktitle = {Proceedings of {{Human Language Technologies}}: {{The Annual Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Demonstrations}}},
  series = {NAACL-Demonstrations '07},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2015-08-20},
  date = {2007},
  pages = {25--26},
  author = {Yates, Alexander and Cafarella, Michael and Banko, Michele and Etzioni, Oren and Broadhead, Matthew and Soderland, Stephen}
}

@inproceedings{schneider_dimensions_2012,
  location = {{Berlin, Heidelberg}},
  title = {Dimensions of {{Argumentation}} in {{Social Media}}},
  isbn = {978-3-642-33875-5},
  url = {http://dx.doi.org/10.1007/978-3-642-33876-2_4},
  doi = {10.1007/978-3-642-33876-2_4},
  abstract = {Mining social media for opinions is important to governments and businesses. Current approaches focus on sentiment and opinion detection. Yet, people also justify their views, giving arguments. Understanding arguments in social media would yield richer knowledge about the views of individuals and collectives. Extracting arguments from social media is difficult. Messages appear to lack indicators for argument, document structure, or inter-document relationships. In social media, lexical variety, alternative spellings, multiple languages, and alternative punctuation are common. Social media also encompasses numerous genres. These aspects can confound the extraction of well-formed knowledge bases of argument. We chart out the various aspects in order to isolate them for further analysis and processing.},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Knowledge Engineering}} and {{Knowledge Management}}},
  series = {EKAW'12},
  publisher = {{Springer-Verlag}},
  date = {2012},
  pages = {21--25},
  author = {Schneider, Jodi and Davis, Brian and Wyner, Adam}
}

@inproceedings{sobhani_argumentation_2015,
  location = {{Denver, CO}},
  title = {From {{Argumentation Mining}} to {{Stance Classification}}},
  url = {http://www.aclweb.org/anthology/W15-0509},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {67--77},
  author = {Sobhani, Parinaz and Inkpen, Diana and Matwin, Stan}
}

@article{ma_intelligent_2014,
  title = {Intelligent {{Tutoring Systems}} and {{Learning Outcomes}}: {{A Meta}}-{{Analysis}}},
  issn = {1939-2176(Electronic);0022-0663(Print)},
  doi = {10.1037/a0037123},
  shorttitle = {Intelligent {{Tutoring Systems}} and {{Learning Outcomes}}},
  abstract = {Intelligent Tutoring Systems (ITS) are computer programs that model learners’ psychological states to provide individualized instruction. They have been developed for diverse subject areas (e.g., algebra, medicine, law, reading) to help learners acquire domain-specific, cognitive and metacognitive knowledge. A meta-analysis was conducted on research that compared the outcomes from students learning from ITS to those learning from non-ITS learning environments. The meta-analysis examined how effect sizes varied with type of ITS, type of comparison treatment received by learners, type of learning outcome, whether knowledge to be learned was procedural or declarative, and other factors. After a search of major bibliographic databases, 107 effect sizes involving 14,321 participants were extracted and analyzed. The use of ITS was associated with greater achievement in comparison with teacher-led, large-group instruction (g = .42), non-ITS computer-based instruction (g = .57), and textbooks or workbooks (g = .35). There was no significant difference between learning from ITS and learning from individualized human tutoring (g = –.11) or small-group instruction (g = .05). Significant, positive mean effect sizes were found regardless of whether the ITS was used as the principal means of instruction, a supplement to teacher-led instruction, an integral component of teacher-led instruction, or an aid to homework. Significant, positive effect sizes were found at all levels of education, in almost all subject domains evaluated, and whether or not the ITS provided feedback or modeled student misconceptions. The claim that ITS are relatively effective tools for learning is consistent with our analysis of potential publication bias.},
  journaltitle = {Journal of Educational Psychology},
  date = {2014},
  pages = {No Pagination Specified},
  author = {Ma, Wenting and Adesope, Olusola O. and Nesbit, John C. and Liu, Qing},
  note = {00000}
}

@inproceedings{cheng_autotutor_2013,
  title = {{{AutoTutor}} 2013: {{Conversation}}-{{Based Online Intelligent Tutoring System}} with {{Rich Media}} ({{Interactive Event}})},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-39112-5_149},
  shorttitle = {{{AutoTutor}} 2013},
  booktitle = {Artificial {{Intelligence}} in {{Education}}},
  publisher = {{Springer}},
  urldate = {2014-10-01},
  date = {2013},
  pages = {930--931},
  author = {Cheng, Qinyu and Cheng, Keli and Li, Haiying and Cai, Zhiqiang and Hu, Xiangen and Graesser, Art},
  note = {00000}
}

@inproceedings{kirschner_linking_2015,
  location = {{Denver, CO}},
  title = {Linking the {{Thoughts}}: {{Analysis}} of {{Argumentation Structures}} in {{Scientific Publications}}},
  url = {http://www.aclweb.org/anthology/W15-0501},
  shorttitle = {Linking the {{Thoughts}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {1--11},
  author = {Kirschner, Christian and Eckle-Kohler, Judith and Gurevych, Iryna}
}

@article{walton_using_2012,
  title = {Using {{Argumentation Schemes}} for {{Argument Extraction}}: {{A Bottom}}-{{Up Method}}},
  volume = {6},
  issn = {1557-3958},
  url = {http://dx.doi.org/10.4018/jcini.2012070103},
  doi = {10.4018/jcini.2012070103},
  shorttitle = {Using {{Argumentation Schemes}} for {{Argument Extraction}}},
  abstract = {This paper surveys the state-of-the-art of argumentation schemes used as argument extraction techniques in cognitive informatics and uses examples to show how a series of connected problems needs to be solved to move these techniques forward to computational implementation. Some of the schemes considered are argument from expert opinion, practical reasoning, argument from negative consequences, fear appeal arguments, argument from commitment, argument from inconsistent commitments, and the circumstantial ad hominem argument. The paper shows how schemes need to be formed into clusters of sub-schemes work toward a classification system of schemes from the bottom up, and how identification conditions for each scheme can be helpful for argument extraction.},
  number = {3},
  journaltitle = {Int. J. Cogn. Inform. Nat. Intell.},
  date = {2012-07},
  pages = {33--61},
  keywords = {Carneades Argumentation System,Classifying Types of Arguments,Identifying Arguments in a Natural Language Text,argument mining},
  author = {Walton, Douglas}
}

@thesis{zablith_argdf_2007,
  title = {{{ArgDF}}: {{Arguments}} on the {{Semantic Web}}},
  institution = {{The British University in Dubai Jointly with The University of Edinburgh}},
  type = {Dissertation},
  date = {2007},
  author = {Zablith, Fouad}
}

@inproceedings{mochales_palau_creating_2009,
  location = {{Barcelona}},
  title = {Creating an Argumentation Corpus: Do Theories Apply to Real Arguments? {{A}} Case Study on the Legal Argumentation of the {{ECHR}}},
  url = {https://lirias.kuleuven.be/handle/123456789/426412},
  doi = {10.1145/1568234.1568238},
  booktitle = {Proceedings of the {{Twelfth International Conference}} on {{Artificial Intelligence}} and {{Law}} ({{ICAIL}} 2009), {{Twelfth}} International Conference on Artificial Intelligence and Law ({{ICAIL}} 2009)., {{Barcelona}}, {{Spain}}, 8-12 {{June}} 2009},
  publisher = {{ACM}},
  date = {2009},
  pages = {21--30},
  author = {Mochales Palau, Raquel and Ieven, Aagje}
}

@inproceedings{christensen_towards_2013,
  title = {Towards {{Coherent Multi}}-{{Document Summarization}}},
  url = {http://www.aclweb.org/anthology/N/N13/N13-1136.pdf},
  booktitle = {Proceedings of {{NAACL}}-{{HLT}}},
  urldate = {2013-07-26},
  date = {2013},
  pages = {1163--1173},
  author = {Christensen, Janara and Mausam, Stephen Soderland and Etzioni, Oren},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\christensen_naacl13_Towards Coherent Multi-Document Summarization.pdf},
  note = {00000}
}

@inproceedings{mochales_palau_study_2008,
  location = {{Amsterdam}},
  title = {Study on the Structure of Argumentation in Case Law},
  url = {https://lirias.kuleuven.be/handle/123456789/203100},
  booktitle = {Proceedings of {{JURIX}} 2008: The {{Twenty}}-First {{Annual Conference}} on {{Legal Knowledge}} and {{Information Systems}}, {{JURIX}} 2008: The Twenty-First Annual Conference on Legal Knowledge and Information Systems, {{Florence}}, {{Italy}}, 10-13 {{December}} 2008},
  publisher = {{IOS Press Amsterdam}},
  date = {2008},
  pages = {11--20},
  author = {Mochales Palau, Raquel and Moens, Marie-Francine}
}

@article{craig_emote_2008,
  langid = {english},
  title = {Emote Aloud during Learning with {{AutoTutor}}: {{Applying}} the {{Facial Action Coding System}} to Cognitive–affective States during Learning},
  volume = {22},
  issn = {0269-9931, 1464-0600},
  url = {http://www.tandfonline.com/doi/abs/10.1080/02699930701516759},
  doi = {10.1080/02699930701516759},
  shorttitle = {Emote Aloud during Learning with {{AutoTutor}}},
  number = {5},
  journaltitle = {Cognition \& Emotion},
  urldate = {2014-06-17},
  date = {2008-08},
  pages = {777-788},
  author = {Craig, Scotty D. and D'Mello, Sidney and Witherspoon, Amy and Graesser, Art},
  note = {00000}
}

@article{surdeanu_combination_2007,
  title = {Combination {{Strategies}} for {{Semantic Role Labeling}}.},
  volume = {29},
  url = {http://www.aaai.org/Papers/JAIR/Vol29/JAIR-2905.pdf},
  journaltitle = {J. Artif. Intell. Res.(JAIR)},
  urldate = {2013-07-31},
  date = {2007},
  pages = {105--151},
  author = {Surdeanu, Mihai and Màrquez, Lluís and Carreras, Xavier and Comas, Pere},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Fachsemester\\Informatik\\Text Mining\\Semantic Role Labeling\\JAIR-2905.pdf},
  note = {00000}
}

@inproceedings{kang_requirement_2014,
  location = {{Baltimore, Maryland}},
  title = {Requirement {{Mining}} in {{Technical Documents}}},
  url = {http://www.aclweb.org/anthology/W14-2118},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {108--109},
  author = {Kang, Juyeon and Saint-Dizier, Patrick}
}

@inproceedings{houngbo_automated_2014,
  location = {{Baltimore, Maryland}},
  title = {An Automated Method to Build a Corpus of Rhetorically-Classified Sentences in Biomedical Texts},
  url = {http://www.aclweb.org/anthology/W14-2103},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {19--23},
  author = {Houngbo, Hospice and Mercer, Robert}
}

@article{garcia_villalba_m.p_facets_2012,
  langid = {english},
  title = {Some Facets of Argument Mining for Opinion Analysis},
  volume = {245},
  issn = {0922-6389},
  number = {1},
  journaltitle = {Front. Artif. Intell. Appl. Frontiers in Artificial Intelligence and Applications},
  date = {2012},
  pages = {23--34},
  author = {{Garcia Villalba M.P} and {Saint-Dizier P}}
}

@article{haider_projective_1997,
  title = {Projective Economy},
  journaltitle = {German: Syntactic problems–problematic syntax, ed. Werner Abraham},
  date = {1997},
  pages = {83--103},
  author = {Haider, Hubert}
}

@article{teufel_summarizing_2002,
  title = {Summarizing {{Scientific Articles}}: {{Experiments}} with {{Relevance}} and {{Rhetorical Status}}},
  volume = {28},
  issn = {0891-2017},
  url = {http://dx.doi.org/10.1162/089120102762671936},
  doi = {10.1162/089120102762671936},
  shorttitle = {Summarizing {{Scientific Articles}}},
  abstract = {In this article we propose a strategy for the summarization of scientific articles that concentrates on the rhetorical status of statements in an article: Material for summaries is selected in such a way that summaries can highlight the new contribution of the source article and situate it with respect to earlier work.},
  number = {4},
  journaltitle = {Computational Linguistics},
  date = {2002-12},
  pages = {409--445},
  author = {Teufel, Simone and Moens, Marc}
}

@article{graves_neural_2014,
  title = {Neural Turing Machines},
  url = {http://arxiv.org/abs/1410.5401},
  journaltitle = {arXiv preprint arXiv:1410.5401},
  urldate = {2016-10-25},
  date = {2014},
  author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/IZJM7FE2/1410.5401v2.pdf}
}

@article{daniel_information_1995,
  title = {Information Function of Empathic Emotion: {{Learning}} That We Value the Other's Welfare},
  volume = {68},
  issn = {1939-1315(Electronic);0022-3514(Print)},
  doi = {10.1037/0022-3514.68.2.300},
  shorttitle = {Information Function of Empathic Emotion},
  abstract = {Empathic feelings arise when a person values another's welfare and perceives the other to be in need. As a result, level of empathic response can be used to infer how much one values the welfare of a person in need. Four experiments were conducted to test these ideas. Experiments 1 and 2 revealed that a similarity manipulation led to increased valuing of a similar person's welfare and, in turn, to increased empathy when this person was in need. Experiments 3 and 4 revealed that direct manipulations of empathy (perspective-taking instructions, or false physiological arousal feedback) led to increased empathy and, in turn, to increased valuing of the welfare of the person in need. Once induced, this valuing was a relatively stable disposition; it remained even after empathy had declined.},
  number = {2},
  journaltitle = {Journal of Personality and Social Psychology},
  date = {1995},
  pages = {300-313},
  keywords = {*Biofeedback,*Empathy,*Experimental Instructions,*Feedback,Social Comparison},
  author = {Daniel, C. and Turk, Cynthia L. and Shaw, Laura L. and Klein, Tricia R.},
  note = {00000}
}

@inproceedings{aharoni_benchmark_2014,
  location = {{Baltimore, Maryland}},
  title = {A {{Benchmark Dataset}} for {{Automatic Detection}} of {{Claims}} and {{Evidence}} in the {{Context}} of {{Controversial Topics}}},
  url = {http://www.aclweb.org/anthology/W14-2109},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {64--68},
  author = {Aharoni, Ehud and Polnarov, Anatoly and Lavee, Tamar and Hershcovich, Daniel and Levy, Ran and Rinott, Ruty and Gutfreund, Dan and Slonim, Noam},
  note = {https://www.research.ibm.com/haifa/dept/vst/mlta\_benchmark.shtml}
}

@incollection{mochales_palau_automatic_2009,
  location = {{Amsterdam}},
  title = {Automatic Argumentation Detection and Its Role in Law and the Semantic Web},
  url = {https://lirias.kuleuven.be/handle/123456789/197362},
  publisher = {{IOS press}},
  date = {2009},
  author = {Mochales Palau, Raquel and Moens, Marie-Francine},
  editor = {Breuker, Joost and Casanovas, Pompeu and Klein, Michel and Francesconi, Enrico}
}

@article{afzal_evaluating_2007,
  title = {Evaluating Learner Experience from Affective Cues},
  url = {http://www.di.uniba.it/intint/DC-ACII07/Afzal.pdf},
  abstract = {Learning with computers is typically self-paced. Appraisal of the learner’s experience is therefore crucial for making machine-learner interactions ‘truly intelligent’ and ins
tinctive. As a significant aspect of Affective Learning, affect recognition need
s to be considered in light of its implications and appliance to computer
based learning environments. Drawing on this motivation, I propose to investigate the potential of using facial expression analysis to model affect in learning as a means for evaluating learner state.},
  journaltitle = {Affective Computing},
  urldate = {2014-09-30},
  date = {2007},
  author = {Afzal, Shazia},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ECCMWEIV/Afzal.pdf},
  note = {00000}
}

@incollection{mcquiggan_early_2007,
  title = {Early Prediction of Student Frustration},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-74889-2_61},
  booktitle = {Affective {{Computing}} and {{Intelligent Interaction}}},
  publisher = {{Springer}},
  urldate = {2014-06-17},
  date = {2007},
  pages = {698--709},
  author = {Mcquiggan, Scott W. and Lee, Sunyoung and Lester, James C.},
  note = {00000}
}

@inproceedings{stab_annotating_2014,
  langid = {english},
  location = {{Dublin, Ireland}},
  title = {Annotating {{Argument Components}} and {{Relations}} in {{Persuasive Essays}}},
  url = {http://anthology.aclweb.org/C/C14/C14-1142.pdf},
  abstract = {In this paper, we present a novel approach to model arguments, their components and relations in persuasive essays in English. We propose an annotation scheme that includes the annotation of claims and premises as well as support and attack relations for capturing the structure of argumentative discourse. We further conduct a manual annotation study with three annotators on 90 persuasive essays. The obtained inter-rater agreement of αU = 0.72 for argument components and α = 0.81 for argumentative relations indicates that the proposed annotation scheme successfully guides annotators to substantial agreement. The final corpus and the annotation guidelines are freely available to encourage future research in argument recognition.},
  booktitle = {Proceedings of the 25th {{International Conference}} on {{Computational Linguistics}} ({{COLING}} 2014)},
  publisher = {{Dublin City University and Association for Computational Linguistics}},
  date = {2014-08},
  pages = {1501--1510},
  author = {Stab, Christian and Gurevych, Iryna},
  editor = {Tsujii, Junichi and Hajic, Jan}
}

@report{_importance_????,
  title = {{{THE IMPORTANCE OF SYNTACTIC PARSING AND INFERENCE IN SEMANTIC ROLE LABEL}}},
  url = {http://www.coli.uni-saarland.de/courses/comsem-11/material/peter_stahl-punyakanok.pdf},
  note = {00000}
}

@incollection{mills_quit_2014,
  langid = {english},
  title = {To {{Quit}} or {{Not}} to {{Quit}}: {{Predicting Future Behavioral Disengagement}} from {{Reading Patterns}}},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_3},
  shorttitle = {To {{Quit}} or {{Not}} to {{Quit}}},
  abstract = {This research predicted behavioral disengagement using quitting behaviors while learning from instructional texts. Supervised machine learning algorithms were used to predict if students would quit an upcoming text by analyzing reading behaviors observed in previous texts. Behavioral disengagement (quitting) at any point during the text was predicted with an accuracy of 76.5\% (48\% above chance), before students even began engaging with the text. We also predicted if a student would quit reading on the first page of a text or continue reading past the first page with an accuracy of 88.5\% (29\% above chance), as well as if students would quit sometime after the first page with an accuracy of 81.4\% (51\% greater than chance). Both actual quits and predicted quits were significantly related to learning, which provides some evidence for the predictive validity of our model. Implications and future work related to ITSs are also discussed.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {19-28},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,ITSs,Multimedia Information Systems,User Interfaces and Human Computer Interaction,affect detection,disengagement,engagement,reading},
  author = {Mills, Caitlin and Bosch, Nigel and Graesser, Art and D’Mello, Sidney},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/86QKB35K/978-3-319-07221-0_3.html},
  note = {00000}
}

@article{walton_intelligent_2016,
  title = {Intelligent {{Practical Reasoning}} for {{Autonomous Agents}}: {{An Introduction}}},
  volume = {8},
  number = {1},
  journaltitle = {Review of European Studies},
  date = {2016},
  pages = {1},
  author = {Walton, Douglas}
}

@inproceedings{ong_ontology-based_2014,
  location = {{Baltimore, Maryland}},
  title = {Ontology-{{Based Argument Mining}} and {{Automatic Essay Scoring}}},
  url = {http://www.aclweb.org/anthology/W14-2104},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {24--28},
  author = {Ong, Nathan and Litman, Diane and Brusilovsky, Alexandra}
}

@article{wells_domain_2012,
  langid = {english},
  title = {A Domain Specific Language for Describing Diverse Systems of Dialogue},
  volume = {10},
  issn = {15708683},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1570868312000602},
  doi = {10.1016/j.jal.2012.09.001},
  number = {4},
  journaltitle = {Journal of Applied Logic},
  date = {2012-12},
  pages = {309--329},
  author = {Wells, S. and Reed, C.A.}
}

@inproceedings{cardie_proceedings_2015,
  location = {{Denver, CO}},
  title = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  url = {http://www.aclweb.org/anthology/W15-05},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  editor = {Cardie, Claire}
}

@inproceedings{oraby_and_2015,
  location = {{Denver, CO}},
  title = {And {{That}}'s {{A Fact}}: {{Distinguishing Factual}} and {{Emotional Argumentation}} in {{Online Dialogue}}},
  url = {http://www.aclweb.org/anthology/W15-0515},
  shorttitle = {And {{That}}'s {{A Fact}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {116--126},
  author = {Oraby, Shereen and Reed, Lena and Compton, Ryan and Riloff, Ellen and Walker, Marilyn and Whittaker, Steve}
}

@inproceedings{sidney_integrating_2005,
  title = {Integrating Affect Sensors in an Intelligent Tutoring System},
  url = {http://141.225.218.248/web-homeroot/graesser/publications/AddPapers/iui-ai-05.pdf},
  booktitle = {Affective {{Interactions}}: {{The Computer}} in the {{Affective Loop Workshop}} At},
  urldate = {2014-06-17},
  date = {2005},
  pages = {7--13},
  author = {Sidney, K. Dmello and Craig, Scotty D. and Gholson, Barry and Franklin, Stan and Picard, Rosalind and Graesser, Arthur C.},
  note = {00000}
}

@inproceedings{surdeanu_multi-instance_2012,
  title = {Multi-Instance Multi-Label Learning for Relation Extraction},
  url = {http://dl.acm.org/citation.cfm?id=2391003},
  booktitle = {Proceedings of the 2012 {{Joint Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and {{Computational Natural Language Learning}}},
  urldate = {2013-07-26},
  date = {2012},
  pages = {455--465},
  author = {Surdeanu, Mihai and Tibshirani, Julie and Nallapati, Ramesh and Manning, Christopher D.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Distant supervision\\p455-surdeanu.pdf},
  note = {00000}
}

@collection{green_proceedings_2014,
  location = {{Baltimore, Maryland}},
  title = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  url = {http://www.aclweb.org/anthology/W14-21},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  editor = {Green, Nancy and Ashley, Kevin and Litman, Diane and Reed, Chris and Walker, Vern}
}

@inproceedings{mochales_palau_argumentation_2009,
  location = {{New York}},
  title = {Argumentation Mining: The Detection, Classification and Structure of Arguments in Text},
  url = {https://lirias.kuleuven.be/handle/123456789/234784},
  booktitle = {Proceedings of the {{Twelfth International Conference}} on {{Artificial Intelligence}} and {{Law}} ({{ICAIL}} 2009), {{Twelfth}} International Conference on Artificial Intelligence and Law ({{ICAIL}} 2009), {{Barcelona}}, {{Spain}}, 8-12 {{June}} 2009},
  publisher = {{ACM}},
  date = {2009},
  pages = {98--109},
  author = {Mochales Palau, Raquel and Moens, Marie-Francine}
}

@inproceedings{buckingham_shum_cohere_2008,
  location = {{Toulouse, France}},
  title = {Cohere: {{Towards Web}} 2.0 {{Argumentation}}},
  isbn = {978-1-58603-859-5},
  url = {http://www.irit.fr/comma08/accepted.html},
  shorttitle = {Cohere},
  abstract = {Students, researchers and professional analysts lack effective tools to make personal and collective sense of problems while working in distributed teams. Central to this work is the process of sharing–and contesting–interpretations via different forms of argument. How does the 'Web 2.0' paradigm challenge us to deliver useful, usable tools for online argumentation? This paper reviews the current state of the art in Web Argumentation, describes key features of the Web 2.0 orientation, and identifies some of the tensions that must be negotiated in bringing these worlds together. It then describes how these design principles are interpreted in Cohere, a web tool for social bookmarking, idea-linking, and argument visualization.},
  publisher = {{IOS Press}},
  date = {2008-05},
  pages = {97--108},
  author = {Buckingham Shum, Simon}
}

@article{chomsky_lectures_1981,
  title = {Lectures on {{Government}} and {{Binding}}, {{Foris}}, {{Dordrecht}}},
  journaltitle = {ChomskyLectures on Government and Binding1981},
  date = {1981},
  author = {Chomsky, Noam}
}

@book{ruppenhofer_framenet_2006,
  title = {{{FrameNet II}}: {{Extended}} Theory and Practice},
  url = {http://framenet2.icsi.berkeley.edu/docs/r1.5/book.pdf},
  shorttitle = {{{FrameNet II}}},
  urldate = {2014-03-26},
  date = {2006},
  author = {Ruppenhofer, Josef and Ellsworth, Michael and Petruck, Miriam RL and Johnson, Christopher R. and Scheffczyk, Jan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3VFHVSUV/book.pdf},
  note = {00000}
}

@article{etzioni_open_2008,
  title = {Open {{Information Extraction}} from the {{Web}}},
  volume = {51},
  issn = {0001-0782},
  url = {http://doi.acm.org/10.1145/1409360.1409378},
  doi = {10.1145/1409360.1409378},
  abstract = {Targeted IE methods are transforming into open-ended techniques.},
  number = {12},
  journaltitle = {Commun. ACM},
  urldate = {2014-07-12},
  date = {2008-12},
  pages = {68--74},
  author = {Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S.}
}

@article{fabrizio_macagno_implicatures_2013,
  title = {Implicatures as {{Forms}} of {{Argument}}},
  doi = {10.1007/978-3-319-01011-3_9},
  date = {2013},
  pages = {203--224},
  author = {Fabrizio Macagno, Douglas Walton}
}

@online{_syntax-begleitblatt.pdf_????,
  title = {Syntax-{{Begleitblatt}}.Pdf},
  url = {https://www.uni-frankfurt.de/59466459/Syntax-Begleitblatt.pdf},
  urldate = {2016-07-28},
  note = {00000}
}

@article{krause_anwendung_1992,
  langid = {german},
  title = {Anwendung der Affektforschung auf die psychoanalytisch-psychotherapeutische Praxis},
  volume = {8},
  issn = {0178-7667},
  url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=5572209},
  number = {3},
  journaltitle = {Forum der Psychoanalyse},
  urldate = {2014-09-29},
  date = {1992},
  pages = {238-253},
  keywords = {Afecto afectividad,Affect affectivity,Affect affectivité,Diagnosis,Diagnostic,Diagnóstico,Hombre,Homme,Human,Investigación científica,Personalidad,Personality,Personnalité,Proceso terapéutico,Processus thérapeutique,Psicoanálisis,Psychanalyse,Psychoanalysis,Recherche scientifique,Scientific research,Therapeutic process},
  author = {Krause, R. and Steimer-Krause, E. and Ullrich, B.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/K3BIPKSI/cat.inist.fr.html},
  note = {00000}
}

@book{sternefeld_syntax_2006,
  location = {{Tübingen}},
  title = {Syntax: Eine Morphologisch Motivierte Generative {{Beschreibung}} Des {{Deutschen}}},
  isbn = {978-3-86057-779-0 978-3-86057-790-5},
  shorttitle = {Syntax},
  pagetotal = {2},
  number = {Bd. 31},
  series = {Stauffenburg Linguistik},
  publisher = {{Stauffenburg}},
  date = {2006},
  keywords = {German language,Morphology,Syntax},
  author = {Sternefeld, Wolfgang}
}

@inreference{_named-entity_2013,
  langid = {english},
  title = {Named-Entity Recognition},
  url = {http://en.wikipedia.org/w/index.php?title=Named-entity_recognition&oldid=565171592},
  abstract = {Named-entity recognition (NER) (also known as entity identification and entity extraction) is a subtask of information extraction that seeks to locate and classify atomic elements in text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.},
  booktitle = {Wikipedia, the Free Encyclopedia},
  urldate = {2013-07-29},
  date = {2013-07-21T10:43:16Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/4RDGBAG7/index.html},
  note = {00000 
Page Version ID: 565171592}
}

@inproceedings{johansson_lth_2007,
  title = {{{LTH}}: Semantic Structure Extraction Using Nonprojective Dependency Trees},
  url = {http://dl.acm.org/citation.cfm?id=1621522},
  shorttitle = {{{LTH}}},
  booktitle = {Proceedings of the 4th {{International Workshop}} on {{Semantic Evaluations}}},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2014-03-31},
  date = {2007},
  pages = {227--230},
  author = {Johansson, Richard and Nugues, Pierre},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GS2HNRVT/S07-1048.pdf},
  note = {00000}
}

@inproceedings{dmello_modeling_2007,
  title = {Modeling and {{Scaffolding Affective Experiences}} to {{Impact Learning}}},
  url = {http://www.researchgate.net/publication/221297651_Modeling_and_Scaffolding_Affective_Experiences_to_Impact_Learning/file/d912f50d0ba76d67d8.pdf#page=3},
  booktitle = {{{WORKSHOP ON MODELING AND SCAFFOLDING AFFECTIVE EXPERIENCES TO IMPACT LEARNING}}},
  urldate = {2014-09-30},
  date = {2007},
  author = {D’MELLO, Sidney and Craig, Scotty and El Kaliouby, Rana and Alsmeyer, Madeline and Rebolledo-Mendez, Genaro},
  note = {00000}
}

@book{lazarus_emotion_1991,
  location = {{New York,  NY,  US}},
  title = {Emotion and Adaptation},
  volume = {xiii},
  isbn = {0-19-506994-3 (Hardcover)},
  abstract = {The work provides a complete theory of emotional processes, explaining how different emotions are elicited and expressed, and how the emotional range of individuals develops over their lifetime. The author's approach puts emotion in a central role as a complex, patterned, organic reaction to both daily events and long-term efforts on the part of the individual to survive and flourish. . . . After defining emotion and discussing issues of classification and measurement, Lazarus turns to the topics of motivation, cognition, and causality as key concepts in this theory. Next, he looks at individual emotions, both negative and positive, and examines how they are generated. Then he reviews individual emotional development and the social influences that shape it. Finally, he considers the long-term consequences of emotion on physical health and well-being, and the treatment and prevention of emotional dysfunction. As a comprehensive treatment of the emotions, the book will interest students, clinicians, and researchers involved in personality, social and clinical psychology, as well as cognitive and developmental psychology. It may also be used as a supplemental textbook in courses on the psychology of adjustment, emotion, and motivation.},
  pagetotal = {557},
  publisher = {{Oxford University Press}},
  date = {1991},
  keywords = {*Adaptability (Personality),*Emotional Development,*Emotions,Emotionality (Personality)},
  author = {Lazarus, Richard S.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/7SS5CJQ2/1991-98760-000.html},
  note = {00000}
}

@article{zinsmeister_chancen_2011,
  title = {Chancen Und {{Probleme}} Der {{Nutzung}} von {{Korpora}}, {{Taggern}} Und Anderen {{Sprachressourcen}} in {{Seminaren}}},
  volume = {26},
  url = {http://kops.uni-konstanz.de/handle/123456789/16648},
  number = {1},
  journaltitle = {Journal for Language Technology and Computational Linguistics},
  urldate = {2016-07-28},
  date = {2011},
  pages = {67--79},
  author = {Zinsmeister, Heike},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BSN78KS6/6.pdf},
  note = {00000}
}

@inproceedings{kim_overview_2011,
  title = {Overview of {{BioNLP}} Shared Task 2011},
  url = {http://dl.acm.org/citation.cfm?id=2107692},
  booktitle = {Proceedings of the {{BioNLP Shared Task}} 2011 {{Workshop}}},
  urldate = {2013-08-27},
  date = {2011},
  pages = {1--6},
  author = {Kim, Jin-Dong and Pyysalo, Sampo and Ohta, Tomoko and Bossy, Robert and Nguyen, Ngan and Tsujii, Jun'ichi},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HJTIC5KE/W11-1801.pdf},
  note = {00000}
}

@article{graesser_using_2007,
  title = {Using {{LSA}} in {{AutoTutor}}: {{Learning}} through Mixed Initiative Dialogue in Natural Language},
  url = {http://books.google.com/books?hl=de&lr=&id=JbzCzPvzpmQC&oi=fnd&pg=PA243&dq=graesser+Using+LSA+in+AutoTutor:+Learning+through+mixed+-+initiative+dia+logue+in+natural+language&ots=aMG0I_QZLL&sig=3N7siCNQwgyi09JZT41Nz8C9llU},
  shorttitle = {Using {{LSA}} in {{AutoTutor}}},
  journaltitle = {Handbook of latent semantic analysis},
  urldate = {2014-10-01},
  date = {2007},
  pages = {243--262},
  author = {Graesser, A. C. and Penumatsa, Phanni and Ventura, Matthew and Cai, Zhiqiang and Hu, Xiangen},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/RTUPFEWV/books.html},
  note = {00000}
}

@book{carver_cognition_2013,
  langid = {english},
  title = {Cognition and {{Instruction}}: {{Twenty}}-Five {{Years}} of {{Progress}}},
  isbn = {978-1-135-64899-2},
  shorttitle = {Cognition and {{Instruction}}},
  abstract = {This volume is based on papers presented at the 30th Carnegie Mellon Symposium on Cognition. This particular symposium was conceived in reference to the 1974 symposium entitled Cognition and Instruction. In the 25 years since that symposium, reciprocal relationships have been forged between psychology and education, research and practice, and laboratory and classroom learning contexts. Synergistic advances in theories, empirical findings, and instructional practice have been facilitated by the establishment of new interdisciplinary journals, teacher education courses, funding initiatives, and research institutes. So, with all of this activity, where is the field of cognition and instruction? How much progress has been made in 25 years? What remains to be done? This volume proposes and illustrates some exciting and challenging answers to these questions.   Chapters in this volume describe advances and challenges in four areas, including development and instruction, teachers and instructional strategies, tools for learning from instruction, and social contexts of instruction and learning. Detailed analyses of tasks, subjects' knowledge and processes, and the changes in performance over time have led to new understanding of learners' representations, their use of multiple strategies, and the important role of metacognitive processes. New methods for assessing and tracking the development and elaboration of knowledge structures and processing strategies have yielded new conceptualizations of the process of change. Detailed cognitive analysis of expert teachers, as well as a direct focus on enhancing teachers' cognitive models of learners and use of effective instructional strategies, are other areas that have seen tremendous growth and refinement in the past 25 years. Similarly, the strong impact of curriculum materials and activities based on a thorough cognitive analysis of the task has been extended to the use of technological tools for learning, such as intelligent tutors and complex computer based instructional interfaces. Both the shift to conducting a significant portion of the cognition and instruction research in real classrooms and the increased collaboration between academics and educators have brought the role of the social context to center stage.},
  pagetotal = {540},
  publisher = {{Psychology Press}},
  date = {2013-06-17},
  keywords = {EDUCATION / Educational Psychology,Psychology / Cognitive Psychology & Cognition,Psychology / Developmental / Child},
  author = {Carver, Sharon M. and Klahr, David},
  note = {00000}
}

@article{gangemi_frame-based_2014,
  title = {Frame-{{Based Detection}} of {{Opinion Holders}} and {{Topics}}: {{A Model}} and a {{Tool}}},
  volume = {9},
  issn = {1556-603X},
  doi = {10.1109/MCI.2013.2291688},
  shorttitle = {Frame-{{Based Detection}} of {{Opinion Holders}} and {{Topics}}},
  abstract = {Sentilo is a model and a tool to detect holders and topics of opinion sentences. Sentilo implements an approach based on the neo-Davidsonian assumption that events and situations are the primary entities for contextualizing opinions, which makes it able to distinguish holders, main topics, and sub-topics of an opinion. It uses a heuristic graph mining approach that relies on FRED, a machine reader for the Semantic Web that leverages Natural Language Processing (NLP) and Knowledge Representation (KR) components jointly with cognitively-inspired frames. The evaluation results are excellent for holder detection (F1: 95\%), very good for subtopic detection (F1: 78\%), and good for topic detection (F1: 68\%).},
  number = {1},
  journaltitle = {IEEE Computational Intelligence Magazine},
  date = {2014-02},
  pages = {20-30},
  keywords = {Computational modeling,FRED,Feature extraction,KR components,NLP,OWL,Semantics,Sentilo,Syntactics,cognition,cognitively-inspired frames,data mining,frame-based detection,graph theory,heuristic graph mining approach,knowledge representation,knowledge representation components,machine reader,natural language processing,neo-Davidsonian assumption,opinion holders,opinion sentences,semantic Web,sentiment analysis,subtopic detection,topic detection},
  author = {Gangemi, A. and Presutti, V. and Reforgiato Recupero, D.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/VWMA6JAQ/login.html},
  note = {00000}
}

@inproceedings{wang_empathic_2006,
  title = {Empathic Tutoring Software Agents Using Real-Time Eye Tracking},
  url = {http://dl.acm.org/citation.cfm?id=1117346},
  booktitle = {Proceedings of the 2006 Symposium on {{Eye}} Tracking Research \& Applications},
  publisher = {{ACM}},
  urldate = {2014-09-29},
  date = {2006},
  pages = {73--78},
  author = {Wang, Hua and Chignell, Mark and Ishizuka, Mitsuru},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/48S7KW43/citation.html},
  note = {00000}
}

@inproceedings{mcquiggan_diagnosing_2006,
  title = {Diagnosing Self-Efficacy in Intelligent Tutoring Systems: {{An}} Empirical Study},
  url = {http://link.springer.com/chapter/10.1007/11774303_56},
  shorttitle = {Diagnosing Self-Efficacy in Intelligent Tutoring Systems},
  booktitle = {Intelligent {{Tutoring Systems}}},
  publisher = {{Springer}},
  urldate = {2014-06-17},
  date = {2006},
  pages = {565--574},
  author = {McQuiggan, Scott W. and Lester, James C.},
  note = {00000}
}

@article{nwana_intelligent_1990,
  langid = {english},
  title = {Intelligent Tutoring Systems: An Overview},
  volume = {4},
  issn = {0269-2821, 1573-7462},
  url = {http://link.springer.com/article/10.1007/BF00168958},
  doi = {10.1007/BF00168958},
  shorttitle = {Intelligent Tutoring Systems},
  abstract = {This is a non-expert overview of Intelligent Tutoring Systems (ITSs), a way in which Artificial Intelligence (AI) techniques are being applied to education. It introduces ITSs and the motivation for them. It looks at its history: its evolution from Computer-Assisted Instruction (CAI). After looking at the structure of a ‘typical’ ITS, the paper further examines and discusses some other architectures. Several classic ITSs are reviewed, mainly due to their historical significance or because they best demonstrate some of the principles of intelligent tutoring. A reasonably representative list of ITSs is also provided in order to provide a better appreciation of this vibrant field as well as reveal the scope of existing tutors. The paper concludes, perhaps more appropriately, with some of the author's viewpoints on a couple of controversial issues in the intelligent tutoring domain.},
  number = {4},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artif Intell Rev},
  urldate = {2014-09-28},
  date = {1990-12-01},
  pages = {251-277},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Science; general,Nonlinear Dynamics; Complex Systems; Chaos; Neural Networks},
  author = {Nwana, Hyacinth S.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/VUF8G23K/Intelligent Tutoring Systems.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WSRH4S67/BF00168958.html},
  note = {00000}
}

@inproceedings{nguyen_context-aware_2016,
  location = {{Berlin, Germany}},
  title = {Context-Aware {{Argumentative Relation Mining}}},
  url = {http://www.aclweb.org/anthology/P16-1107},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  publisher = {{Association for Computational Linguistics}},
  date = {2016-08},
  pages = {1127--1137},
  author = {Nguyen, Huy and Litman, Diane}
}

@article{copestake_minimal_2005,
  langid = {english},
  title = {Minimal {{Recursion Semantics}}: {{An Introduction}}},
  volume = {3},
  issn = {1570-7075, 1572-8706},
  url = {http://link.springer.com/10.1007/s11168-006-6327-9},
  doi = {10.1007/s11168-006-6327-9},
  shorttitle = {Minimal {{Recursion Semantics}}},
  number = {2-3},
  journaltitle = {Research on Language and Computation},
  urldate = {2016-06-29},
  date = {2005-07},
  pages = {281-332},
  author = {Copestake, Ann and Flickinger, Dan and Pollard, Carl and Sag, Ivan A.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BEHUNJKA/copestake.pdf}
}

@inproceedings{burchardt_salsa_2006,
  title = {The {{SALSA}} Corpus: A {{German}} Corpus Resource for Lexical Semantics},
  url = {http://www.cl.uni-heidelberg.de/~frank/papers/lrec06_burchardt_salsa.pdf},
  shorttitle = {The {{SALSA}} Corpus},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}-2006)},
  urldate = {2014-03-25},
  date = {2006},
  author = {Burchardt, Aljoscha and Erk, Katrin and Frank, Anette and Kowalski, Andrea and Padó, Sebastian and Pinkal, Manfred},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/6CQA3S9W/lrec06_burchardt_salsa.pdf},
  note = {00000}
}

@inproceedings{schmitz_open_2012,
  title = {Open Language Learning for Information Extraction},
  url = {http://dl.acm.org/citation.cfm?id=2391009},
  booktitle = {Proceedings of the 2012 {{Joint Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and {{Computational Natural Language Learning}}},
  urldate = {2013-07-26},
  date = {2012},
  pages = {523--534},
  author = {Schmitz, Michael and Bart, Robert and Soderland, Stephen and Mausam and Etzioni, Oren},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\tmpbtEE_q_OLLIE.pdf},
  note = {00000}
}

@inproceedings{green_identifying_2015,
  location = {{Denver, CO}},
  title = {Identifying {{Argumentation Schemes}} in {{Genetics Research Articles}}},
  url = {http://www.aclweb.org/anthology/W15-0502},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-06},
  pages = {12--21},
  author = {Green, Nancy}
}

@online{_distant-supervision_????,
  title = {Distant-{{Supervision Learning Algorithm}} - {{GM}}-{{RKB}}},
  url = {http://www.gabormelli.com/RKB/Distant-Supervision_Learning_Algorithm},
  urldate = {2016-10-05},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/NH7R286W/Distant-Supervision_Learning_Algorithm.html}
}

@article{mikolov_efficient_2013,
  title = {Efficient Estimation of Word Representations in Vector Space},
  url = {http://arxiv.org/abs/1301.3781},
  journaltitle = {arXiv preprint arXiv:1301.3781},
  urldate = {2016-12-12},
  date = {2013},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/CXTSWM34/1301.3781v3.pdf}
}

@inproceedings{tiedemann_building_2009,
  title = {Building a Large Machine-Aligned Parallel Treebank},
  url = {http://ufal.ms.mff.cuni.cz/pedt2.0/publications/Proceedings_TLT8.pdf#page=209},
  booktitle = {Eighth {{International Workshop}} on {{Treebanks}} and {{Linguistic Theories}}},
  urldate = {2013-11-05},
  date = {2009},
  pages = {197},
  author = {Tiedemann, Jörg and Kotzé, Gideon},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/7GGRG9HF/download.pdf},
  note = {00000}
}

@article{asakura_mechanical_1975,
  langid = {english},
  title = {Mechanical Precipitation of Hemoglobin Köln},
  volume = {412},
  issn = {0006-3002},
  abstract = {Hb Köln (beta 98 Val leads to Met) was found to precipitate rapidly during mechanical shaking. The rate of precipitation of Hb Köln is 5-6 times faster than that of Hb S. The kinetics of precipitation of the patient's hemolysate, which is a mixture of Hb Köln and Hb A, showed a biphasic curve indicating that Hb Köln precipitates independently from Hb A. The instability of Hb Köln may be attributed to the conformational change in the vicinity of heme. The mechanical shaking may be used as a new method for detection and quantitation of hemoglobin Köln and other unstable hemoglobins.},
  number = {2},
  journaltitle = {Biochimica Et Biophysica Acta},
  shortjournal = {Biochim. Biophys. Acta},
  date = {1975-12-15},
  pages = {197-201},
  keywords = {Chemical Precipitation,Germany; West,Hemoglobin; Sickle,Hemoglobins; Abnormal,Humans,Hydrogen-Ion Concentration,Methionine,Osmolar Concentration,Temperature,Valine},
  author = {Asakura, T. and Adachi, K. and Shapiro, M. and Friedman, S. and Schwartz, E.},
  eprinttype = {pmid},
  eprint = {83}
}

@inproceedings{rooney_applying_2012,
  title = {Applying Kernel Methods to Argumentation Mining},
  url = {http://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS12/paper/view/4366},
  booktitle = {Twenty-{{Fifth International FLAIRS Conference}}},
  date = {2012},
  author = {Rooney, Niall and Wang, Hui and Browne, Fiona}
}

@inproceedings{paquette_sensor-free_2014,
  title = {Sensor-{{Free Affect Detection}} for a {{Simulation}}-{{Based Science Inquiry Learning Environment}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_1},
  booktitle = {Intelligent {{Tutoring Systems}}},
  publisher = {{Springer}},
  urldate = {2014-09-29},
  date = {2014},
  pages = {1--10},
  author = {Paquette, Luc and Baker, Ryan SJD and Sao Pedro, Michael A. and Gobert, Janice D. and Rossi, Lisa and Nakama, Adam and Kauffman-Rogoff, Zakkai},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/UJ3IR8X3/ITS2014Paquetteetal.pdf},
  note = {00000}
}

@inproceedings{eduardo_blanco_causal_2008,
  langid = {english},
  location = {{Marrakech, Morocco}},
  title = {Causal {{Relation Extraction}}},
  isbn = {2-9517408-4-0},
  booktitle = {Proceedings of the {{Sixth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'08)},
  publisher = {{European Language Resources Association (ELRA)}},
  date = {2008},
  author = {Eduardo Blanco, Nuria Castell and Moldovan, Dan},
  editor = {Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Daniel Tapias},
  note = {http://www.lrec-conf.org/proceedings/lrec2008/}
}

@article{brezina_selection_1975,
  langid = {english},
  title = {Selection of Chlortetracycline-Resistant Strain of {{Coxiella}} Burnetii},
  volume = {19},
  issn = {0001-723X},
  number = {6},
  journaltitle = {Acta Virologica},
  shortjournal = {Acta Virol.},
  date = {1975-11},
  pages = {496},
  keywords = {Animals,Chick Embryo,Chlortetracycline,Coxiella,Drug Resistance; Microbial,Female,Vitelline Membrane},
  author = {Brezina, R. and Schramek, S. and Kazár, J.},
  eprinttype = {pmid},
  eprint = {1997}
}

@article{dmello_multimodal_2010,
  title = {Multimodal Semi-Automated Affect Detection from Conversational Cues, Gross Body Language, and Facial Features},
  volume = {20},
  url = {http://link.springer.com/article/10.1007/s11257-010-9074-4},
  number = {2},
  journaltitle = {User Modeling and User-Adapted Interaction},
  urldate = {2014-06-17},
  date = {2010},
  pages = {147--187},
  author = {D’Mello, Sidney K. and Graesser, Arthur},
  note = {00000}
}

@article{schwenk_continuous_2007,
  langid = {english},
  title = {Continuous Space Language Models},
  volume = {21},
  issn = {08852308},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0885230806000325},
  doi = {10.1016/j.csl.2006.09.003},
  number = {3},
  journaltitle = {Computer Speech \& Language},
  urldate = {2016-09-26},
  date = {2007-07},
  pages = {492-518},
  author = {Schwenk, Holger},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FFI8TPWP/sdarticle.pdf}
}

@article{walton_building_2012,
  langid = {english},
  title = {Building a {{System}} for {{Finding Objections}} to an {{Argument}}},
  volume = {26},
  issn = {0920-427X},
  url = {http://dx.doi.org/10.1007/s10503-012-9261-z},
  doi = {10.1007/s10503-012-9261-z},
  number = {3},
  journaltitle = {Argumentation},
  date = {2012},
  pages = {369--391},
  keywords = {Argument from inconsistent commitment,Argument invention,Argument visualization tools,Argumentation schemes,Critical questions,Proleptic argumentation,Rebuttal,Refutation},
  author = {Walton, Douglas}
}

@inproceedings{etzioni_web-scale_2004,
  location = {{New York, NY, USA}},
  title = {Web-Scale Information Extraction in Knowitall: (Preliminary Results)},
  isbn = {1-58113-844-X},
  url = {http://doi.acm.org/10.1145/988672.988687},
  doi = {10.1145/988672.988687},
  shorttitle = {Web-Scale Information Extraction in Knowitall},
  abstract = {Manually querying search engines in order to accumulate a large bodyof factual information is a tedious, error-prone process of piecemealsearch. Search engines retrieve and rank potentially relevantdocuments for human perusal, but do not extract facts, assessconfidence, or fuse information from multiple documents. This paperintroduces KnowItAll, a system that aims to automate the tedious process ofextracting large collections of facts from the web in an autonomous,domain-independent, and scalable manner.The paper describes preliminary experiments in which an instance of KnowItAll, running for four days on a single machine, was able to automatically extract 54,753 facts. KnowItAll associates a probability with each fact enabling it to trade off precision and recall. The paper analyzes KnowItAll's architecture and reports on lessons learned for the design of large-scale information extraction systems.},
  booktitle = {Proceedings of the 13th International Conference on {{World Wide Web}}},
  series = {WWW '04},
  publisher = {{ACM}},
  urldate = {2013-07-26},
  date = {2004},
  pages = {100--110},
  keywords = {information extraction,mutual information,pmi,search},
  author = {Etzioni, Oren and Cafarella, Michael and Downey, Doug and Kok, Stanley and Popescu, Ana-Maria and Shaked, Tal and Soderland, Stephen and Weld, Daniel S. and Yates, Alexander},
  note = {00000}
}

@online{duchi_adaptive_????,
  title = {Adaptive {{Subgradient Methods}} for {{Online Learning}} and {{Stochastic Optimization}}},
  url = {http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf},
  urldate = {2016-12-05},
  author = {Duchi, John and Hazan, Elad and Singer, Yoram}
}

@inproceedings{burchardt_fate_2008,
  title = {{{FATE}}: A {{FrameNet}}-{{Annotated Corpus}} for {{Textual Entailment}}.},
  url = {http://www.cs.brandeis.edu/~marc/misc/proceedings/lrec-2008/pdf/143_paper.pdf},
  shorttitle = {{{FATE}}},
  booktitle = {{{LREC}}},
  urldate = {2014-03-26},
  date = {2008},
  author = {Burchardt, Aljoscha and Pennacchiotti, Marco},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/SD38NDEN/143_paper.pdf},
  note = {00000}
}

@article{dmello_autotutor_2012,
  langid = {english},
  title = {{{AutoTutor}} and Affective Autotutor: {{Learning}} by Talking with Cognitively and Emotionally Intelligent Computers That Talk Back},
  volume = {2},
  issn = {21606455},
  url = {http://dl.acm.org/citation.cfm?doid=2395123.2395128},
  doi = {10.1145/2395123.2395128},
  shorttitle = {{{AutoTutor}} and Affective Autotutor},
  number = {4},
  journaltitle = {ACM Transactions on Interactive Intelligent Systems},
  urldate = {2014-06-17},
  date = {2012-12-01},
  pages = {1-39},
  author = {D'mello, Sidney and Graesser, Art},
  note = {00026}
}

@article{martin_influence_2003,
  langid = {english},
  title = {The Influence of Gender on Mood Effects in Advertising},
  volume = {20},
  issn = {0742-6046, 1520-6793},
  url = {http://doi.wiley.com/10.1002/mar.10070},
  doi = {10.1002/mar.10070},
  number = {3},
  journaltitle = {Psychology and Marketing},
  urldate = {2014-09-30},
  date = {2003-03},
  pages = {249-273},
  author = {Martin, Brett A. S.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/E5BX3WSA/Martin-2003.pdf},
  note = {00057}
}

@thesis{white_pattern-based_2010,
  langid = {english},
  location = {{United States – Colorado}},
  title = {Pattern-Based Extraction of Argumentation from the Scientific Literature},
  url = {http://search.proquest.com/docview/501674530/abstract/C75577A4FBA14858PQ/1?accountid=11004},
  abstract = {As the number of publications in the biomedical field continues its exponential increase, techniques for automatically summarizing information from this body of literature have become more diverse. In addition, the targets of summarization have become more subtle; initial work focused on extracting the factual assertions from full-text papers, while recent interest has shifted to recovering statements involving certainty, like speculations and agreements or disagreements with other research. Scientific writing is rife with such argumentation, and the premises, evidence, conjectures, objections and rebuttals that writers use to persuade the reader represent a rich vein of expert knowledge for summarization. However, recovering these presents substantial challenges as well: processing natural language leads to ambiguity; arguments are made implicitly instead of explicitly; and arguments are nested into complex structures. Agreement, disagreement, and conjecture are often expressed in highly scripted ways in scientific writing, and this feature makes these arguments recoverable by pattern-based search. Here, I present the PARROT software; it recognizes claims pertaining to scientific methods, cognition, discourse, negation, causation, and modality and uses discourse cues to combine these claims recursively into larger rhetorical structures to recover the shape of the arguments made in a scientific publication, which uses OpenDMAP patterns in combination with a Protégé ontology. PARROT outperforms an SVM classifier in identifying statements of support and conflict at the sentence level. Additionally, PARROT adapts to graphical representation of the arguments it finds, which makes it an valuable tool for summarizing the reasoning behind scientists' conclusions and identifying areas of consensus and contention.},
  institution = {{University of Colorado at Boulder}},
  type = {Ph.D.},
  date = {2010},
  keywords = {Applied sciences,Argumentation,Concept,Language,Pattern,Pattern-based extraction,Speculation,literature and linguistics},
  author = {White, Elizabeth K.}
}

@article{mcclelland_parallel_1986,
  title = {Parallel Distributed Processing},
  volume = {2},
  url = {http://www.researchgate.net/publication/229091444_Explorations_in_Parallel_Distributed_Processing_A_Handbook_of_Models_Programs_and_Exercises/file/60b7d51cad74438a64.pdf},
  journaltitle = {Explorations in the microstructure of cognition},
  urldate = {2014-10-01},
  date = {1986},
  author = {McClelland, James L. and Rumelhart, David E. and Group, PDP Research and {others}},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WB7VETQ2/McClelland et al. - 1986 - Parallel distributed processing.pdf},
  note = {14125}
}

@online{_1301.3781v3.pdf_????,
  title = {1301.3781v3.Pdf},
  url = {https://arxiv.org/pdf/1301.3781v3.pdf},
  urldate = {2016-12-12}
}

@book{sternefeld_syntax_2015,
  langid = {german},
  location = {{Tübingen}},
  title = {Syntax:: eine morphologisch motivierte generative Beschreibung des Deutschen. Band 1: [...]},
  edition = {4., überarbeitete Auflage},
  isbn = {978-3-86057-176-7},
  shorttitle = {Syntax},
  pagetotal = {477},
  number = {Band 31,1},
  series = {Stauffenburg-Linguistik},
  publisher = {{Stauffenburg Verlag}},
  date = {2015},
  keywords = {German language,Morphology,Syntax},
  author = {Sternefeld, Wolfgang},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZPE4H5TH/612162551.html},
  note = {OCLC: 945727954}
}

@article{theobald_10_2013,
  title = {10 Years of Probabilistic Querying-What Next?},
  url = {https://lirias.kuleuven.be/handle/123456789/403578},
  journaltitle = {Lecture Notes in Computer Science},
  urldate = {2013-07-26},
  date = {2013},
  author = {Theobald, Martin and De Raedt, Luc and Dylla, Maximilian and Kimmig, Angelika and Miliaraki, Iris},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\theobald-adbis13_10 Years of Probabilistic Querying.pdf}
}

@online{_freebase_????,
  title = {Freebase},
  url = {http://www.freebase.com},
  urldate = {2013-07-29}
}

@article{etzioni_unsupervised_2005,
  title = {Unsupervised Named-Entity Extraction from the {{Web}}: {{An}} Experimental Study},
  volume = {165},
  issn = {0004-3702},
  url = {http://www.sciencedirect.com/science/article/pii/S0004370205000366},
  doi = {10.1016/j.artint.2005.03.001},
  shorttitle = {Unsupervised Named-Entity Extraction from the {{Web}}},
  abstract = {The KnowItAll system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an unsupervised, domain-independent, and scalable manner. The paper presents an overview of KnowItAll's novel architecture and design principles, emphasizing its distinctive ability to extract information without any hand-labeled training examples. In its first major run, KnowItAll extracted over 50,000 class instances, but suggested a challenge: How can we improve KnowItAll's recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Pattern Learning learns domain-specific extraction rules, which enable additional extractions. Subclass Extraction automatically identifies sub-classes in order to boost recall (e.g., “chemist” and “biologist” are identified as sub-classes of “scientist”). List Extraction locates lists of class instances, learns a “wrapper” for each list, and extracts elements of each list. Since each method bootstraps from KnowItAll's domain-independent methods, the methods also obviate hand-labeled training examples. The paper reports on experiments, focused on building lists of named entities, that measure the relative efficacy of each method and demonstrate their synergy. In concert, our methods gave KnowItAll a 4-fold to 8-fold increase in recall at precision of 0.90, and discovered over 10,000 cities missing from the Tipster Gazetteer.},
  number = {1},
  journaltitle = {Artificial Intelligence},
  urldate = {2014-07-12},
  date = {2005-06},
  pages = {91--134},
  keywords = {Pointwise mutual information,Unsupervised,information extraction,question answering},
  author = {Etzioni, Oren and Cafarella, Michael and Downey, Doug and Popescu, Ana-Maria and Shaked, Tal and Soderland, Stephen and Weld, Daniel S. and Yates, Alexander},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BIRQM44G/1-s2.0-S0004370205000366-main.pdf}
}

@article{moreno_case_2001,
  title = {The Case for Social Agency in Computer-Based Teaching: {{Do}} Students Learn More Deeply When They Interact with Animated Pedagogical Agents?},
  volume = {19},
  url = {http://www.tandfonline.com/doi/abs/10.1207/S1532690XCI1902_02},
  shorttitle = {The Case for Social Agency in Computer-Based Teaching},
  number = {2},
  journaltitle = {Cognition and Instruction},
  urldate = {2014-09-29},
  date = {2001},
  pages = {177--213},
  author = {Moreno, Roxana and Mayer, Richard E. and Spires, Hiller A. and Lester, James C.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/RFFFFEQK/Moreno et al. - 2001 - The case for social agency in computer-based teach.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WHTVSSBW/S1532690XCI1902_02.html}
}

@book{walton_argument_1996,
  langid = {english},
  location = {{Toronto [u.a.]}},
  title = {Argument Structure: A Pragmatic Theory},
  isbn = {0-8020-0768-6},
  shorttitle = {Argument Structure},
  series = {Toronto studies in philosophy},
  publisher = {{Univ. of Toronto Press}},
  date = {1996},
  keywords = {Argument,Logik},
  author = {Walton, Douglas N.}
}

@article{grosse_integrating_????,
  title = {Integrating Argumentation and Sentiment Analysis for Mining Opinions from {{Twitter}}},
  journaltitle = {AI Communications},
  author = {Grosse, Kathrin and González, María P and Chesñevar, Carlos I and Maguitman, Ana G}
}

@online{_emotive_????,
  title = {Emotive {{Computing Group}}},
  url = {http://141.225.218.248/web-cslwebroot/emotion/index4.htm},
  urldate = {2014-09-30},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/4XCTCG47/Russellemotion_slide_2004.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/7HXP3DQA/Russellemotion_slide.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MAAJXMHM/index4.html;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/RWW9NHM5/index4.html},
  note = {00000}
}

@inproceedings{akbik_kraken_2012,
  title = {Kraken: {{N}}-Ary Facts in Open Information Extraction},
  url = {http://dl.acm.org/citation.cfm?id=2391210},
  shorttitle = {Kraken},
  booktitle = {Proceedings of the {{Joint Workshop}} on {{Automatic Knowledge Base Construction}} and {{Web}}-Scale {{Knowledge Extraction}}},
  urldate = {2013-07-26},
  date = {2012},
  pages = {52--56},
  author = {Akbik, Alan and Löser, Alexander},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Open IE\\p52-akbik_Kraken.pdf}
}

@article{reed_structured_2014,
  langid = {english},
  title = {Structured {{Arguments}} and {{Their Aggregation}}: {{A Reply}} to {{Selinger}}},
  volume = {28},
  issn = {0920-427X},
  url = {http://dx.doi.org/10.1007/s10503-014-9327-1},
  doi = {10.1007/s10503-014-9327-1},
  number = {3},
  journaltitle = {Argumentation},
  date = {2014},
  pages = {395--399},
  keywords = {Aggregation,Artificial intelligence,Structured argumentation},
  author = {Reed, Chris}
}

@inproceedings{feng_classifying_2011,
  location = {{Stroudsburg, PA, USA}},
  title = {Classifying {{Arguments}} by {{Scheme}}},
  isbn = {978-1-932432-87-9},
  url = {http://dl.acm.org/citation.cfm?id=2002472.2002597},
  abstract = {Argumentation schemes are structures or templates for various kinds of arguments. Given the text of an argument with premises and conclusion identified, we classify it as an instance of one of five common schemes, using features specific to each scheme. We achieve accuracies of 63–91\% in one-against-others classification and 80–94\% in pairwise classification (baseline = 50\% in both cases).},
  booktitle = {Proceedings of the 49th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}} - {{Volume}} 1},
  series = {HLT '11},
  publisher = {{Association for Computational Linguistics}},
  date = {2011},
  pages = {987--996},
  author = {Feng, Vanessa Wei and Hirst, Graeme}
}

@inproceedings{paulheim_discoverability_2013,
  title = {Discoverability of {{SPARQL Endpoints}} in {{Linked Open Data}}.},
  url = {http://iswc2013.semanticweb.org/sites/default/files/iswc_poster_17.pdf},
  booktitle = {International {{Semantic Web Conference}} ({{Posters}} \& {{Demos}})},
  urldate = {2015-05-04},
  date = {2013},
  pages = {245--248},
  author = {Paulheim, Heiko and Hertling, Sven},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/VQSBKVKG/iswc2013_poster.pdf},
  note = {00008}
}

@book{ekman_facial_1978,
  title = {Facial Action Coding System: {{A}} Technique for the Measurement of Facial Movement. {{Palo Alto}}},
  shorttitle = {Facial Action Coding System},
  publisher = {{CA: Consulting Psychologists Press}},
  date = {1978},
  author = {Ekman, Paul and Friesen, Wallace V.},
  note = {00453}
}

@article{goldberg_word2vec_2014,
  title = {Word2vec {{Explained}}: Deriving {{Mikolov}} et Al.'s Negative-Sampling Word-Embedding Method},
  url = {http://arxiv.org/abs/1402.3722},
  shorttitle = {Word2vec {{Explained}}},
  journaltitle = {arXiv preprint arXiv:1402.3722},
  urldate = {2016-12-12},
  date = {2014},
  author = {Goldberg, Yoav and Levy, Omer},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WS4KVBR4/1402.3722v1.pdf}
}

@inreference{_maximum-likelihood-methode_2013,
  langid = {german},
  title = {Maximum-Likelihood-Methode},
  url = {http://de.wikipedia.org/w/index.php?title=Maximum-Likelihood-Methode&oldid=114948262},
  abstract = {Die Maximum-Likelihood-Methode (von engl. maximale Wahrscheinlichkeit) bezeichnet in der Statistik ein parametrisches Schätzverfahren. Dabei wird vereinfacht so vorgegangen, dass derjenige Parameter als Schätzung ausgewählt wird, gemäß dessen Verteilung die Realisierung der beobachteten Daten am plausibelsten erscheint.},
  booktitle = {Wikipedia},
  urldate = {2013-03-05},
  date = {2013-03-04T10:46:22Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/N5U25UTZ/index.html},
  note = {Page Version ID: 114948262}
}

@inproceedings{habernal_argumentation_2014,
  location = {{Bertinoro, Italy}},
  title = {Argumentation {{Mining}} on the {{Web}} from {{Information Seeking Perspective}}},
  url = {https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2014/argumentation-on-the-web-final-preprint.pdf},
  abstract = {In this paper, we argue that an annotation scheme for argumentation mining is a function of the task requirements and the corpus properties. There is no one-size-fits-all argumentation theory to be applied to realistic data on the Web. In two annotation studies, we experiment with 80 German newspaper editorials from the Web and about one thousand English documents from forums, comments, and blogs. Our example topics are taken from the educational domain. To formalize the problem of annotating arguments, in the first case, we apply a Claim-Premise scheme, and in the second case, we modify Toulmin's scheme. We find that the choice of the argument components to be annotated strongly depends on the register, the length of the document, and inherently on the literary devices and structures used for expressing argumentation. We hope that these findings will facilitate the creation of reliably annotated argumentation corpora for a wide range of tasks and corpus types and will help to bridge the gap between argumentation theories and actual application needs.},
  booktitle = {Proceedings of the {{Workshop}} on {{Frontiers}} and {{Connections}} between {{Argumentation Theory}} and {{Natural Language Processing}}},
  publisher = {{CEUR-WS}},
  date = {2014-07},
  pages = {26--39},
  author = {Habernal, Ivan and Eckle-Kohler, Judith and Gurevych, Iryna},
  editor = {Cabrio, Elena and Villata, Serena and Wyner, Adam}
}

@article{damianou_feature_????,
  title = {Feature Representation with {{Deep Gaussian}} Processes},
  url = {http://ml.dcs.shef.ac.uk/gpss/gpfe14/talks/gpss_deepGPs.pdf},
  urldate = {2016-10-25},
  author = {Damianou, Andreas},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/NMXD7GJP/gpss_deepGPs.pdf}
}

@inproceedings{trevisan_indicators_2014,
  location = {{Baltimore, Maryland}},
  title = {Indicators of {{Argument}}-Conclusion {{Relationships}}. {{An Approach}} for {{Argumentation Mining}} in {{German Discourses}}},
  url = {http://www.aclweb.org/anthology/W14-2116},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {104--105},
  author = {Trevisan, Bianka and Dickmeis, Eva and Jakobs, Eva-Maria and Niehr, Thomas}
}

@article{buchholz_system_1953,
  title = {The {{System Design}} of the {{IBM Type}} 701 {{Computer}}},
  volume = {41},
  issn = {0096-8390},
  doi = {10.1109/JRPROC.1953.274300},
  abstract = {In designing any new piece of equipment a choice has to be made from a number of alternatives. Rather than just enumerating the features incorporated in the IBM Type 701 Computer, an attempt is made to record the reasons for their choice. Emphasis is given to the features which are believed to be new. These include improved arithmetic and logical facilities, as well as the methods developed for controlling the extensive input and output equipment directly from the stored program.},
  number = {10},
  journaltitle = {Proceedings of the IRE},
  date = {1953},
  pages = {1262-1275},
  keywords = {Appraisal,Arithmetic,Buildings,Centralized control,Concurrent computing,Data engineering,Design engineering,Large-scale systems,Logic,Writing},
  author = {Buchholz, W.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FHJRXTA4/login.html}
}

@book{piaget_origins_1952,
  location = {{New York,  NY,  US}},
  title = {The Origins of Intelligence in Children},
  abstract = {This work, a second edition of which has very kindly been requested, was followed by La Construction du réel chez l'enfant and was to have been completed by a study of the genesis of imitation in the child. The latter piece of research, whose publication we have postponed because it is so closely connected with the analysis of play and representational symbolism, appeared in 1945, inserted in a third work, La formation du symbole chez l'enfant. Together these three works form one entity dedicated to the beginnings of intelligence, that is to say, to the various manifestations of sensorimotor intelligence and to the most elementary forms of expression. The theses developed in this volume, which concern in particular the formation of the sensorimotor schemata and the mechanism of mental assimilation, have given rise to much discussion which pleases us and prompts us to thank both our opponents and our sympathizers for their kind interest in our work.},
  pagetotal = {419},
  publisher = {{W W Norton \& Co}},
  date = {1952},
  keywords = {*Cognitive Development,*Intelligence,Assimilation (Cognitive Process),Childhood Play Development,Imitation (Learning),Nonverbal Communication,Perceptual Motor Development,Symbolism},
  author = {Piaget, Jean and Cook, Margaret},
  note = {10479}
}

@inproceedings{riedel_relation_2013,
  title = {Relation {{Extraction}} with {{Matrix Factorization}} and {{Universal Schemas}}},
  url = {http://www.newdesign.aclweb.org/anthology-new/N/N13/N13-1008.pdf},
  booktitle = {Proceedings of {{NAACL}}-{{HLT}}},
  urldate = {2013-07-26},
  date = {2013},
  pages = {74--84},
  author = {Riedel, Sebastian and Yao, Limin and McCallum, Andrew and Marlin, Benjamin M.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\N13-1008_Relation Extraction with Matrix Factorization and Universal Schemas.pdf}
}

@thesis{mochales_palau_automatic_2011,
  title = {Automatic {{Detection}} and {{Classification}} of {{Argumentation}} in a {{Legal Case}} ({{Automatische}} Detectie En Classificatie van de Argumentatie in Een Juridische Zaak)},
  url = {https://lirias.kuleuven.be/handle/123456789/305094},
  institution = {{Faculty of Engineering Science}},
  date = {2011-07},
  author = {Mochales Palau, Raquel},
  note = {Moens, Marie-Francine and De Schreye, Daniel (supervisors)}
}

@report{de_marneffe_stanford_2008,
  location = {{Stanford University}},
  title = {Stanford Typed Dependencies Manual},
  url = {http://nlp.stanford.edu/downloads/dependencies_manual.pdf},
  urldate = {2013-07-30},
  date = {2008},
  author = {De Marneffe, Marie-Catherine and Manning, Christopher D.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Fachsemester\\Informatik\\Text Mining\\Parsing\\Dependency\\stanford_dependencies_manual.pdf}
}

@online{_camus_????,
  title = {Camus: {{Das Ideal}} Der {{Einfachheit}}. {{Eine Biographie}}: {{Amazon}}.de: {{Iris Radisch}}: {{Bücher}}},
  url = {http://www.amazon.de/Camus-Ideal-Einfachheit-Eine-Biographie/dp/3499628015/ref=tmm_pap_swatch_0?_encoding=UTF8&sr=&qid=},
  urldate = {2015-05-04},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/7682HRB9/ref=tmm_pap_swatch_0.html},
  note = {00000}
}

@article{marquez_semantic_2008,
  title = {Semantic Role Labeling: An Introduction to the Special Issue},
  volume = {34},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/coli.2008.34.2.145},
  shorttitle = {Semantic Role Labeling},
  number = {2},
  journaltitle = {Computational linguistics},
  urldate = {2013-07-26},
  date = {2008},
  pages = {145--159},
  author = {Màrquez, Lluís and Carreras, Xavier and Litkowski, Kenneth C. and Stevenson, Suzanne},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Semantic Role Labeling\\coli.2008.34.2.145.pdf}
}

@article{mochales_palau_argumentation_2011,
  title = {Argumentation Mining},
  volume = {19},
  url = {https://lirias.kuleuven.be/handle/123456789/291845},
  number = {1},
  journaltitle = {Artificial Intelligence and Law},
  date = {2011},
  pages = {1--22},
  author = {Mochales Palau, Raquel and Moens, Marie-Francine}
}

@inproceedings{mcdonald_non-projective_2005,
  title = {Non-Projective Dependency Parsing Using Spanning Tree Algorithms},
  url = {http://dl.acm.org/citation.cfm?id=1220641},
  booktitle = {Proceedings of the Conference on {{Human Language Technology}} and {{Empirical Methods}} in {{Natural Language Processing}}},
  urldate = {2013-07-26},
  date = {2005},
  pages = {523--530},
  author = {McDonald, Ryan and Pereira, Fernando and Ribarov, Kiril and Haji$\backslash$vc, Jan},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Parsing\\Dependency\\H05-1066_Non-projective Dependency Parsing using Spanning Tree Algorithms.pdf}
}

@inproceedings{lawrence_mining_2014,
  location = {{Baltimore, Maryland}},
  title = {Mining {{Arguments From}} 19th {{Century Philosophical Texts Using Topic Based Modelling}}},
  url = {http://www.aclweb.org/anthology/W14-2111},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {79--87},
  author = {Lawrence, John and Reed, Chris and Allen, Colin and McAlister, Simon and Ravenscroft, Andrew}
}

@book{joel_ctrl_2013,
  langid = {english},
  title = {Ctrl Alt Delete: Reboot Your Business. Reboot Your Life. Your Future Depends on It},
  isbn = {978-1-4555-2330-6 1-4555-2330-5},
  shorttitle = {Ctrl Alt Delete},
  publisher = {{Business Plus}},
  date = {2013},
  author = {Joel, Mitch}
}

@article{nadeau_survey_2007,
  title = {A Survey of Named Entity Recognition and Classification},
  volume = {30},
  url = {http://www.ingentaconnect.com/content/jbp/li/2007/00000030/00000001/art00002},
  number = {1},
  journaltitle = {Lingvisticae Investigationes},
  urldate = {2013-09-04},
  date = {2007},
  pages = {3--26},
  author = {Nadeau, David and Sekine, Satoshi},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BSXER7WQ/li07.pdf}
}

@article{walker_framework_2011,
  langid = {english},
  title = {A Framework for the Extraction and Modeling of Fact-Finding Reasoning from Legal Decisions: Lessons from the {{Vaccine}}/{{Injury Project Corpus}}},
  volume = {19},
  issn = {0924-8463},
  doi = {10.1007/s10506-011-9115-2},
  shorttitle = {A Framework for the Extraction and Modeling of Fact-Finding Reasoning from Legal Decisions},
  abstract = {This article describes the Vaccine/Injury Project Corpus, a collection of legal decisions awarding or denying compensation for health injuries allegedly due to vaccinations, together with models of the logical structure of the reasoning of the factfinders in those cases. This unique corpus provides useful data for formal and informal logic theory, for natural-language research in linguistics, and for artificial intelligence research. More importantly, the article discusses lessons learned from developing protocols for manually extracting the logical structure and generating the logic models. It identifies sub-tasks in the extraction process, discusses challenges to automation, and provides insights into possible solutions for automation. In particular, the framework and strategies developed here, together with the corpus data, should allow “top–down” and contextual approaches to automation, which can supplement “bottom-up” linguistic approaches. Illustrations throughout the article use examples drawn from the Corpus.},
  number = {4},
  journaltitle = {Artificial Intelligence and Law},
  date = {2011},
  pages = {291--331},
  keywords = {Argumentation mining,Automation,Legal evidence,Legal rule,Logic schema,Vaccines},
  author = {Walker, Vern and Carie, Nathaniel and DeWitt, Courtney and Lesh, Eric}
}

@article{gerrig_psychologie_2008,
  title = {Psychologie (18. {{Aufl}}.)},
  journaltitle = {München: Person Studium},
  date = {2008},
  author = {Gerrig, Richard J. and Zimbardo, Philip G.},
  note = {00039}
}

@inproceedings{eckle-kohler_role_2015,
  location = {{Lisbon, Portugal}},
  title = {On the {{Role}} of {{Discourse Markers}} for {{Discriminating Claims}} and {{Premises}} in {{Argumentative Discourse}}},
  url = {http://aclweb.org/anthology/D15-1267},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-09},
  pages = {2236--2242},
  author = {Eckle-Kohler, Judith and Kluge, Roland and Gurevych, Iryna}
}

@book{_syntax.._2009,
  langid = {german},
  title = {Syntax.. 2},
  edition = {3., überarb. Aufl.},
  isbn = {978-3-86057-177-4},
  abstract = {Verantwortlichkeit: Wolfgang Sternefeld},
  pagetotal = {xii},
  series = {BV013738446 31,2},
  date = {2009}
}

@book{_syntax.._2009-1,
  langid = {german},
  title = {Syntax.. 2},
  edition = {3., überarb. Aufl.},
  isbn = {978-3-86057-177-4},
  abstract = {Verantwortlichkeit: Wolfgang Sternefeld},
  pagetotal = {xii},
  series = {BV013738446 31,2},
  date = {2009}
}

@inproceedings{yao_structured_2011,
  title = {Structured Relation Discovery Using Generative Models},
  url = {http://dl.acm.org/citation.cfm?id=2145587},
  booktitle = {Proceedings of the {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  urldate = {2013-07-26},
  date = {2011},
  pages = {1456--1466},
  author = {Yao, Limin and Haghighi, Aria and Riedel, Sebastian and McCallum, Andrew},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\unsuprel-emnlp11_Structured Relation Discovery using Generative Models.pdf}
}

@book{sternefeld_syntax_2009,
  langid = {german},
  location = {{Tübingen}},
  title = {Syntax: eine morphologisch motivierte generative Beschreibung des Deutschen. Bd. 2},
  edition = {3., überarb. Aufl},
  isbn = {978-3-86057-177-4},
  shorttitle = {Syntax},
  pagetotal = {479},
  number = {Bd. 31,2},
  series = {Stauffenburg-Linguistik},
  publisher = {{Stauffenburg}},
  date = {2009},
  author = {Sternefeld, Wolfgang},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/H2R5DF46/Sternefeld_2009_Syntax.pdf},
  note = {OCLC: 426147853}
}

@inproceedings{baker_berkeley_1998,
  title = {The Berkeley Framenet Project},
  url = {http://dl.acm.org/citation.cfm?id=980860},
  booktitle = {Proceedings of the 36th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and 17th {{International Conference}} on {{Computational Linguistics}}-{{Volume}} 1},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2014-03-26},
  date = {1998},
  pages = {86--90},
  author = {Baker, Collin F. and Fillmore, Charles J. and Lowe, John B.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/A3P8QEWX/p86-baker.pdf}
}

@incollection{girotto_tool_2014,
  langid = {english},
  title = {A {{Tool}} for {{Integrating Log}} and {{Video Data}} for {{Exploratory Analysis}} and {{Model Generation}}},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-07221-0_9},
  abstract = {Analysis of students’ log data to understand their process as they solve problems is an essential part of educational technology research. Models of correct and buggy student behavior can be generated from this log data and used as a basis for intelligent feedback. Another important technique for understanding problem-solving process is video protocol analysis, but historically, this has not been well integrated with log data. In this paper, we describe a tool to 1) facilitate the annotation of log data with information from video data, and 2) automatically generate models of student problem-solving process that include both video and log data. We demonstrate the utility of the tool with analysis of student use of a teachable robot system for geometry.},
  number = {8474},
  booktitle = {Intelligent {{Tutoring Systems}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  urldate = {2014-09-29},
  date = {2014-01-01},
  pages = {69-74},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computers and Education,Document Preparation and Text Processing,Multimedia Information Systems,User Interfaces and Human Computer Interaction,cognitive modeling,intelligent tutor,log analysis tool},
  author = {Girotto, Victor and Thomas, Elissa and Lozano, Cecil and Muldner, Kasia and Burleson, Winslow and Walker, Erin},
  editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/86784J9K/978-3-319-07221-0_9.html}
}

@article{gildea_automatic_2002,
  title = {Automatic Labeling of Semantic Roles},
  volume = {28},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/089120102760275983},
  number = {3},
  journaltitle = {Computational linguistics},
  urldate = {2013-07-26},
  date = {2002},
  pages = {245--288},
  author = {Gildea, Daniel and Jurafsky, Daniel},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Semantic Role Labeling\\gildea-cl02.pdf}
}

@article{kulik_[combined_1975,
  langid = {russian},
  title = {[Combined effects of hypoxia and hypercapnia on the functional state of the respiratory center]},
  volume = {79},
  issn = {0365-9615},
  abstract = {Experiments were conducted on cats under nembutal anesthesia; a study was made of pulse activity of bulbar respiratory neurons, electrical activity of the diaphragm and of the intercostal muscles; pO2, pCO2, pH, arterial blood oxygen saturation were determined in combined action of hypoxia and hypercapnia. When hypoxic gaseous mixture was given for respiration the developing hypocapnia disturbed the discharge rhythmic activity of the respiratory neurons, the respiration acquiring a pathological character of the Cheyne--Stokes type. After addition to the hypoxic gaseous mixture of 2\% CO2 the gaseous composition of the arterial blood approached the initial values; this addition prevented the development of hypercapnia and disturbances of rhythmic discharge activity of the respiratory neurons. Addition of 5\% CO2 to the hypoxic gaseous mixture produced a negative effect: at first it intensified and then depressed the pulse activity of the respiratory neurons, caused metabolic and respiratory acidosis, and promoted asphyxia.},
  number = {4},
  journaltitle = {Biulleten' Eksperimental'noi Biologii I Meditsiny},
  shortjournal = {Biull Eksp Biol Med},
  date = {1975-04},
  pages = {39-43},
  keywords = {Animals,Carbon Dioxide,Cats,Cheyne-Stokes Respiration,Diaphragm,Electrophysiology,Hydrogen-Ion Concentration,Hypercapnia,Hypoxia,Intercostal Muscles,Neurons,Oxygen,Respiratory Center},
  author = {Kulik, A. M. and Kondrat'eva, L. N.},
  eprinttype = {pmid},
  eprint = {103}
}

@article{leising_toronto_2009,
  title = {The {{Toronto Alexithymia Scale}} ({{TAS}}-20): {{A}} Measure of General Psychological Distress},
  volume = {43},
  issn = {0092-6566},
  url = {http://www.sciencedirect.com/science/article/pii/S0092656609000828},
  doi = {10.1016/j.jrp.2009.03.009},
  shorttitle = {The {{Toronto Alexithymia Scale}} ({{TAS}}-20)},
  abstract = {The Toronto Alexithymia Scale (Bagby, R. M., Parker, J. D. A., \&amp; Taylor, G. J. (1994). The twenty-item Toronto Alexithymia Scale-I. Item selection and cross-validation of the factor structure. Journal of Psychosomatic Research, 38, 23–32.) is the most commonly used measure of Alexithymia (= difficulties identifying and describing one’s own feelings). Sixty-three persons (34 psychiatric inpatients, 29 healthy controls) first filled in the TAS-20 and were then interviewed about their interpersonal relationships. Two raters coded the emotional experiences that the participants reported during these interviews. Contrary to expectations, participants with higher TAS-20 scores reported more emotions (particularly negative ones), and more different emotions, questioning the validity of the TAS-20 as a measure of Alexithymia. Based on correlation patterns and a joint factor analysis with two well-established measures of psychopathology, it is concluded that the TAS-20 assesses a general psychological distress factor.},
  number = {4},
  journaltitle = {Journal of Research in Personality},
  shortjournal = {Journal of Research in Personality},
  urldate = {2013-03-04},
  date = {2009-08},
  pages = {707-710},
  keywords = {Alexithymia,Emotions,Experience,Expressivity,Rating,TAS-20,Validity},
  author = {Leising, Daniel and Grande, Tilman and Faber, Rainer},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/7C7DU5W2/Leising et al. - 2009 - The Toronto Alexithymia Scale (TAS-20) A measure .html}
}

@article{wenger_artificial_1987,
  title = {Artificial Intelligence and Tutoring Systems},
  url = {http://www.info2.uqam.ca/~nkambou/DIC9340/seances/seance2-3-4-5/Ontology/IJAIED2004.pdf},
  urldate = {2014-09-29},
  date = {1987},
  author = {Wenger, Etienne}
}

@article{skipper_hydrolysis_1976,
  langid = {english},
  title = {Hydrolysis of a Chloro-s-Triazine Herbicide},
  volume = {24},
  issn = {0021-8561},
  number = {1},
  journaltitle = {Journal of Agricultural and Food Chemistry},
  shortjournal = {J. Agric. Food Chem.},
  year = {1976 Jan-Feb},
  pages = {126-129},
  keywords = {Atrazine,Chemical Phenomena,Chemistry,Hydrogen-Ion Concentration,Hydrolysis,Pesticide Residues,Spectrophotometry; Infrared},
  author = {Skipper, H. D. and Volk, V. V. and Frech, R.},
  eprinttype = {pmid},
  eprint = {1430}
}

@article{den_besten_ergative_1985,
  title = {The Ergative Hypothesis and Free Word Order in {{Dutch}} and {{German}}},
  volume = {21},
  journaltitle = {Studies in German grammar},
  date = {1985},
  pages = {23--64},
  author = {Den Besten, Hans}
}

@inproceedings{mintz_distant_2009,
  title = {Distant Supervision for Relation Extraction without Labeled Data},
  url = {http://dl.acm.org/citation.cfm?id=1690287},
  booktitle = {Proceedings of the {{Joint Conference}} of the 47th {{Annual Meeting}} of the {{ACL}} and the 4th {{International Joint Conference}} on {{Natural Language Processing}} of the {{AFNLP}}: {{Volume}} 2-{{Volume}} 2},
  urldate = {2013-07-26},
  date = {2009},
  pages = {1003--1011},
  author = {Mintz, Mike and Bills, Steven and Snow, Rion and Jurafsky, Dan},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Distant supervision\\mintz_Distant supervision for relation extraction without labeled data.pdf}
}

@inproceedings{rehbein_adding_2012,
  title = {Adding Nominal Spice to {{SALSA}}-Frame-Semantic Annotation of {{German}} Nouns and Verbs},
  url = {http://www.academia.edu/download/30881859/proceedings.pdf#page=89},
  booktitle = {Proceedings of the 11th {{Conference}} on {{Natural Language Processing}} ({{KONVENS}}’12)},
  urldate = {2014-03-25},
  date = {2012},
  pages = {89--97},
  author = {Rehbein, Ines and Ruppenhofer, Joseph and Sporleder, Caroline and Pinkal, Manfred},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/VMTXF229/14_rehbein12o.pdf}
}

@inproceedings{mochales_palau_acila_2007,
  title = {{{ACILA}} - {{Automatic}} Detection of Arguments in Legal Cases},
  url = {https://lirias.kuleuven.be/handle/123456789/146815},
  booktitle = {Proceedings of the {{Workshop}} on {{Semantic Web Technology}} for {{Law}}, {{Workshop}} on {{Semantic Web Technology}} for {{Law}}, {{Stanford}}, {{CA}}, {{USA}}, {{June}} 16, 2007},
  date = {2007},
  pages = {5--9},
  author = {Mochales Palau, Raquel and Moens, Marie-Francine}
}

@inproceedings{eichler_teg-rep_2016,
  title = {{{TEG}}-{{REP}}: {{A}} Corpus of {{Textual Entailment Graphs}} Based on {{Relation Extraction Patterns}}},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Language Resources}} and {{Evaluation}}},
  publisher = {{European Language Resources Association}},
  date = {2016},
  author = {Eichler, Kathrin and Xu, Feiyu and Uszkoreit, Hans and Hennig, Leonhard and Krause, Sebastian},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JIGTVIRT/176_Paper.pdf}
}

@inproceedings{sridhar_joint_2015,
  location = {{Beijing, China}},
  title = {Joint {{Models}} of {{Disagreement}} and {{Stance}} in {{Online Debate}}},
  url = {http://www.aclweb.org/anthology/P15-1012},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-07},
  pages = {116--125},
  author = {Sridhar, Dhanya and Foulds, James and Huang, Bert and Getoor, Lise and Walker, Marilyn}
}

@inproceedings{winkels_experiments_2013,
  location = {{New York, NY, USA}},
  title = {Experiments in {{Automated Support}} for {{Argument Reconstruction}}},
  isbn = {978-1-4503-2080-1},
  url = {http://doi.acm.org/10.1145/2514601.2514633},
  doi = {10.1145/2514601.2514633},
  abstract = {This paper describes the outcomes of experiments in automated support for argument reconstruction from natural language texts. We investigated several possibilities to support a manual process by using natural language processing, from classifying pieces of text as either argumentative or non-argumentative to clustering text fragments in the hope that these clusters would contain similar arguments. Results are diverse, but also show that we cannot come a long way without an extensive pre-tagged corpus.},
  booktitle = {Proceedings of the {{Fourteenth International Conference}} on {{Artificial Intelligence}} and {{Law}}},
  series = {ICAIL '13},
  publisher = {{ACM}},
  date = {2013},
  pages = {232--236},
  keywords = {argument mining,clustering,policy modelling},
  author = {Winkels, Radboud and Douw, Jochem and Veldhoen, Sara}
}

@article{wolpert_stacked_1992,
  title = {Stacked Generalization},
  volume = {5},
  url = {http://www.sciencedirect.com/science/article/pii/S0893608005800231},
  number = {2},
  journaltitle = {Neural networks},
  urldate = {2013-07-26},
  date = {1992},
  pages = {241--259},
  author = {Wolpert, David H.},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Wolpert1992_stacked_generalization.pdf}
}

@inproceedings{ritter_latent_2010,
  title = {A Latent Dirichlet Allocation Method for Selectional Preferences},
  url = {http://dl.acm.org/citation.cfm?id=1858725},
  booktitle = {Proceedings of the 48th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  urldate = {2013-07-26},
  date = {2010},
  pages = {424--434},
  author = {Ritter, Alan and Etzioni, Oren},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\acl-2010-ritter_A Latent Dirichlet Allocation method for Selectional Preferences.pdf}
}

@inproceedings{salakhutdinov_learning_2007,
  title = {Learning a {{Nonlinear Embedding}} by {{Preserving Class Neighbourhood Structure}}.},
  url = {http://www.jmlr.org/proceedings/papers/v2/salakhutdinov07a/salakhutdinov07a.pdf},
  booktitle = {{{AISTATS}}},
  urldate = {2016-10-25},
  date = {2007},
  pages = {412--419},
  author = {Salakhutdinov, Ruslan and Hinton, Geoffrey E.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/PU9M4RMB/AISTATS07_SalakhutdinovH.pdf}
}

@inreference{_virtuoso_2015,
  langid = {english},
  title = {Virtuoso {{Universal Server}}},
  url = {http://en.wikipedia.org/w/index.php?title=Virtuoso_Universal_Server&oldid=655236450},
  abstract = {Virtuoso Universal Server is a middleware and database engine hybrid that combines the functionality of a traditional RDBMS, ORDBMS, virtual database, RDF, XML, free-text, web application server and file server functionality in a single system. Rather than have dedicated servers for each of the aforementioned functionality realms, Virtuoso is a "universal server"; it enables a single multithreaded server process that implements multiple protocols. The open source edition of Virtuoso Universal Server is also known as OpenLink Virtuoso. The software has been developed by OpenLink Software with Kingsley Uyi Idehen and Orri Erling as the chief software architects.},
  booktitle = {Wikipedia, the Free Encyclopedia},
  urldate = {2015-05-04},
  date = {2015-04-06T20:07:25Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/PC2W8RWI/index.html},
  note = {00000 
Page Version ID: 655236450}
}

@inproceedings{arroyo_emotion_2009,
  title = {Emotion {{Sensors Go To School}}.},
  volume = {200},
  url = {http://centerforknowledgecommunication.com/publications/recentPubsandAwards/2009/AIED%20SENSORS%20CameraReady.pdf},
  booktitle = {{{AIED}}},
  urldate = {2014-06-17},
  date = {2009},
  pages = {17--24},
  author = {Arroyo, Ivon and Cooper, David G. and Burleson, Winslow and Woolf, Beverly Park and Muldner, Kasia and Christopherson, Robert},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/B3ET2R25/2009_emotion sensors go to school AIED SENSORS CameraReady.pdf},
  note = {00169}
}

@inproceedings{stab_argumentation_2014,
  location = {{Bertinoro, Italy}},
  title = {Argumentation {{Mining}} in {{Persuasive Essays}} and {{Scientific Articles}} from the {{Discourse Structure Perspective}}},
  url = {https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2014/FrontiersArg2014_PrePrint.pdf},
  abstract = {In this paper, we analyze and discuss approaches to argumentation mining from the discourse structure perspective. We chose persuasive essays and scientific articles as our example domains. By analyzing several example arguments and providing an overview of previous work on argumentation mining, we derive important tasks that are currently not addressed by existing argumentation mining systems, most importantly, the identification of argumentation structures. We discuss the relation of this task to automated discourse analysis and describe preliminary results of two annotation studies focusing on the annotation of argumentation structure. Based on our findings, we derive three challenges for encouraging future research on argumentation mining.},
  booktitle = {Proceedings of the {{Workshop}} on {{Frontiers}} and {{Connections}} between {{Argumentation Theory}} and {{Natural Language Processing}}},
  publisher = {{CEUR-WS}},
  date = {2014-07},
  pages = {40--49},
  author = {Stab, Christian and Kirschner, Christian and Eckle-Kohler, Judith and {Iryna Gurevych}},
  editor = {Cabrio, Elena and Villata, Serena and Wyner, Adam}
}

@article{steenbergen-hu_meta-analysis_2013,
  title = {A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on {{K}}–12 Students’ Mathematical Learning},
  volume = {105},
  issn = {1939-2176(Electronic);0022-0663(Print)},
  doi = {10.1037/a0032447},
  abstract = {In this study, we meta-analyzed empirical research of the effectiveness of intelligent tutoring systems (ITS) on K–12 students’ mathematical learning. A total of 26 reports containing 34 independent samples met study inclusion criteria. The reports appeared between 1997 and 2010. The majority of included studies compared the effectiveness of ITS with that of regular classroom instruction. A few studies compared ITS with human tutoring or homework practices. Among the major findings are (a) overall, ITS had no negative and perhaps a small positive effect on K–12 students’ mathematical learning, as indicated by the average effect sizes ranging from g = 0.01 to g = 0.09, and (b) on the basis of the few studies that compared ITS with homework or human tutoring, the effectiveness of ITS appeared to be small to modest. Moderator analyses revealed 2 findings of practical importance. First, the effects of ITS appeared to be greater when the interventions lasted for less than a school year than when they lasted for 1 school year or longer. Second, the effectiveness of ITS for helping students drawn from the general population was greater than for helping low achievers. This finding draws attentions to the issue of whether computerized learning might contribute to the achievement gap between students with different achievement levels and aptitudes.},
  number = {4},
  journaltitle = {Journal of Educational Psychology},
  date = {2013},
  pages = {970-987},
  keywords = {*Academic Achievement,*Intelligent Tutoring Systems,*Learning,*Mathematics Education,Tutoring},
  author = {Steenbergen-Hu, Saiying and Cooper, Harris}
}

@inproceedings{che_multilingual_2009,
  title = {Multilingual Dependency-Based Syntactic and Semantic Parsing},
  url = {http://dl.acm.org/citation.cfm?id=1596417},
  booktitle = {Proceedings of the {{Thirteenth Conference}} on {{Computational Natural Language Learning}}: {{Shared Task}}},
  urldate = {2013-07-26},
  date = {2009},
  pages = {49--54},
  author = {Che, Wanxiang and Li, Zhenghua and Li, Yongqiang and Guo, Yuhang and Qin, Bing and Liu, Ting},
  file = {C:\\Users\\Arne\\Dropbox\\Uni\\10. Semester\\Informatik\\Text Mining\\Semantic Role Labeling\\15_conll09st.pdf}
}

@inproceedings{levy_dependency-based_2014,
  title = {Dependency-{{Based Word Embeddings}}.},
  url = {http://www.aclweb.org/anthology/P14-2050.pdf},
  booktitle = {{{ACL}} (2)},
  urldate = {2016-12-06},
  date = {2014},
  pages = {302--308},
  author = {Levy, Omer and Goldberg, Yoav},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FG3V87WP/P14-2050.pdf}
}

@article{oder_xmax_struktur_????,
  title = {Struktur von {{Phrasen}}},
  url = {http://home.uni-leipzig.de/muellerg/mu604.pdf},
  urldate = {2016-07-27},
  author = {oder Xmax, X. P.},
  options = {useprefix=true},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/6ZN6D34D/mu135.pdf},
  note = {00000}
}

@inproceedings{hernandez_a._survey_2014,
  location = {{Baltimore, Maryland}},
  title = {Survey in Sentiment, Polarity and Function Analysis of Citation},
  url = {http://www.aclweb.org/anthology/W14-2115},
  booktitle = {Proceedings of the {{First Workshop}} on {{Argumentation Mining}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-06},
  pages = {102--103},
  author = {Hernández A., Myriam and Gómez, José M.}
}

@online{_details_????,
  title = {Details: {{UKP}}},
  url = {https://www.ukp.tu-darmstadt.de/publications/details/?no_cache=1&tx_dppublications_pi1%5Bpublication%5D=10236&tx_dppublications_pi1%5Baction%5D=show&tx_dppublications_pi1%5Bcontroller%5D=Publication&cHash=2c6877d9b5479e42772e11df225f839d#dp_publications-single},
  urldate = {2017-04-25},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/X3657U5P/details.html}
}

@thesis{beinborn_predicting_2016,
  title = {Predicting and {{Manipulating}} the {{Difficulty}} of {{Text}}-{{Completion Exercises}} for {{Language Learning}}},
  url = {http://tuprints.ulb.tu-darmstadt.de/5647},
  institution = {{Technische Universität Darmstadt}},
  urldate = {2017-04-25},
  date = {2016},
  author = {Beinborn, Lisa Marina},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/TQBMUFN6/DissertationBeinborn_publishedVersion_September20_online.pdf}
}

@online{gurevych_linked_2016,
  langid = {english},
  title = {Linked {{Lexical Knowledge Bases}}: {{Foundations}} and {{Applications}}},
  url = {http://www.morganclaypool.com/doi/10.2200/S00717ED1V01Y201605HLT034},
  shorttitle = {Linked {{Lexical Knowledge Bases}}},
  abstract = {Abstract This book conveys the fundamentals of Linked Lexical Knowledge Bases (LLKB) and sheds light on their different aspects from various perspectives, focusing on their construction and use in natural language processing (NLP). It characterizes a wide range of both expert-based and collaboratively constructed lexical knowledge bases. Only basic familiarity with NLP is required and this book has been written for both students and researchers in NLP and related fields who are interested in knowledge-based approaches to language analysis and their applications. Lexical Knowledge Bases (LKBs) are indispensable in many areas of natural language processing, as they encode human knowledge of language in machine readable form, and as such, they are required as a reference when machines attempt to interpret natural language in accordance with human perception. In recent years, numerous research efforts have led to the insight that to make the best use of available knowledge, the orchestrated exploitation of di...},
  type = {other},
  urldate = {2017-04-25},
  date = {2016-07-19},
  author = {Gurevych, Iryna and Eckle-Kohler, Judith and Matuschek, Michael},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JMAWREAU/S00717ED1V01Y201605HLT034.html}
}

@article{habernal_what_????,
  title = {What Makes a Convincing Argument? {{Empirical}} Analysis and Detecting Attributes of Convincingness in {{Web}} Argumentation},
  url = {https://www.aclweb.org/anthology/D16-1129},
  shorttitle = {What Makes a Convincing Argument?},
  urldate = {2017-04-25},
  keywords = {Argument},
  author = {Habernal, Ivan and Gurevych, Iryna},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JIAZ78MW/emnlp2016-habernal-gurevych-camera-ready.pdf}
}

@inproceedings{eger_neural_2017-1,
  location = {{Vancouver, Canada}},
  title = {Neural {{End}}-to-{{End Learning}} for {{Computational Argumentation Mining}}},
  volume = {Volume 1: Long Papers},
  abstract = {We investigate neural techniques for end-to-end computational argumentation mining (AM). We frame AM both as a token-based dependency parsing and as a token-based sequence tagging problem, including a multi-task learning setup. Contrary to models that operate on the argument component level, we find that framing AM as dependency parsing leads to subpar performance results. In contrast, less complex (local) tagging models based on BiLSTMs perform robustly across classification scenarios, being able to catch long-range dependencies inherent to the AM problem. Moreover, we find that jointly learning ‘natural’ subtasks, in a multi-task learning setup, improves performance.$<$/div$>$},
  booktitle = {Proceedings of the 55th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{ACL}} 2017)},
  publisher = {{Association for Computational Linguistics}},
  date = {2017-08},
  pages = {(to appear)},
  author = {Eger, Steffen and Daxenberger, Johannes and Gurevych, Iryna},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JTTRI9UI/acl_arg_min_frame2017_4.pdf}
}

@inproceedings{wachsmuth_argumentation_2017,
  location = {{Vancouver, Canada}},
  title = {Argumentation {{Quality Assessment}}: {{Theory}} vs. {{Practice}}},
  volume = {Volume 2: Short Papers},
  abstract = {Argumentation quality is viewed differently in argumentation theory and in practical assessment approaches. This paper studies to what extent the views match empirically. We find that most observations on quality phrased spontaneously are in fact adequately represented by theory. Even more, relative comparisons of arguments in practice correlate with absolute quality ratings based on theory. Our results clarify how the two views can learn from each other.},
  booktitle = {Proceedings of the 55th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{ACL}} 2017)},
  publisher = {{Association for Computational Linguistics}},
  date = {2017-08},
  pages = {(to appear)},
  author = {Wachsmuth, Henning and Naderi, Nona and Habernal, Ivan and Hou, Yufang and Hirst, Graeme and Gurevych, Iryna and Stein, Benno},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/8N4GZVHD/acl17-argumentation-quality-final.pdf}
}

@online{_spacy_????,
  title = {{{spaCy}}},
  url = {https://spacy.io/index},
  abstract = {spaCy is a free open-source library featuring state-of-the-art speed and accuracy and a powerful Python API.},
  urldate = {2017-06-12},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BFFHGS49/spacy.io.html}
}

@online{_distributed_????,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}} - {{MikolovSutskeverChenCorradoDean2013}}.Pdf},
  url = {http://web2.cs.columbia.edu/~blei/seminar/2016_discrete_data/readings/MikolovSutskeverChenCorradoDean2013.pdf},
  urldate = {2017-06-12}
}

@inproceedings{misra_measuring_2016,
  title = {Measuring the {{Similarity}} of {{Sentential Arguments}} in {{Dialog}}},
  url = {http://www.aclweb.org/anthology/W/W16/W16-36.pdf#page=294},
  booktitle = {17th {{Annual Meeting}} of the {{Special Interest Group}} on {{Discourse}} and {{Dialogue}}},
  urldate = {2017-06-12},
  date = {2016},
  pages = {276},
  author = {Misra, Amita and Ecker, Brian and Walker, Marilyn A.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/5ZZB3CS6/f4e94c69c3288b0cbb30538fe45be9e8e3b5.pdf}
}

@inproceedings{boltuzic_identifying_2015,
  title = {Identifying Prominent Arguments in Online Debates Using Semantic Textual Similarity},
  url = {http://www.aclweb.org/anthology/W/W15/W15-05.pdf#page=122},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  urldate = {2017-06-12},
  date = {2015},
  pages = {110--115},
  author = {Boltuzic, Filip and Šnajder, Jan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/34WGTDIF/7f7fd9287c4021e1c22b0df92d0809e6a5d8.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FW2VZNJ8/7f7fd9287c4021e1c22b0df92d0809e6a5d8.pdf}
}

@inproceedings{pennington_glove_2014,
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  booktitle = {{{EMNLP}}},
  date = {2014},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/IHIC6EBK/glove.pdf}
}

@article{hochreiter_long_1997,
  title = {Long {{Short}}-{{Term Memory}}},
  volume = {9 8},
  journaltitle = {Neural computation},
  date = {1997},
  pages = {1735-80},
  keywords = {lstm},
  author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/F7HHKIZS/0b063db113fe44b1a4ec97c1eeff7a5c4669.pdf}
}

@book{workshop_on_wireless_traffic_measurements_and_modeling_papers_2005,
  langid = {english},
  location = {{Berkeley, CA}},
  title = {Papers Presented at the {{Workshop}} on {{Wireless Traffic Measurements}} and {{Modeling}}: {{June}} 5, 2005, {{Seattle}}, {{WA}}, {{USA}}},
  isbn = {978-1-931971-33-1},
  url = {http://portal.acm.org/toc.cfm?id=1072430},
  shorttitle = {Papers Presented at the {{Workshop}} on {{Wireless Traffic Measurements}} and {{Modeling}}},
  publisher = {{USENIX Association}},
  urldate = {2017-06-12},
  date = {2005},
  author = {{Workshop on Wireless Traffic Measurements and Modeling} and {USENIX Association} and {ACM SIGMOBILE} and {ACM Special Interest Group in Operating Systems} and {ACM Digital Library}},
  note = {OCLC: 83296063}
}

@inproceedings{abadi_tensorflow_2016,
  title = {{{TensorFlow}}: {{A}} System for Large-Scale Machine Learning},
  booktitle = {{{OSDI}}},
  date = {2016},
  keywords = {tensorflow},
  author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek Gordon and Steiner, Benoit and Tucker, Paul A. and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zhang, Xiaoqiang},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/P44H673P/fa180728932959997a4768411ff9136aac81.pdf}
}

@article{looks_deep_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1702.02181},
  primaryClass = {cs, stat},
  title = {Deep {{Learning}} with {{Dynamic Computation Graphs}}},
  url = {http://arxiv.org/abs/1702.02181},
  abstract = {Neural networks that compute over graph structures are a natural fit for problems in a variety of domains, including natural language (parse trees) and cheminformatics (molecular graphs). However, since the computation graph has a different shape and size for every input, such networks do not directly support batched training or inference. They are also difficult to implement in popular deep learning libraries, which are based on static data-flow graphs. We introduce a technique called dynamic batching, which not only batches together operations between different input graphs of dissimilar shape, but also between different nodes within a single input graph. The technique allows us to create static graphs, using popular libraries, that emulate dynamic computation graphs of arbitrary shape and size. We further present a high-level library of compositional blocks that simplifies the creation of dynamic graph models. Using the library, we demonstrate concise and batch-wise parallel implementations for a variety of models from the literature.},
  urldate = {2017-06-12},
  date = {2017-02-07},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning,Statistics - Machine Learning,Tensorflow Fold},
  author = {Looks, Moshe and Herreshoff, Marcello and Hutchins, DeLesley and Norvig, Peter},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/9VXK6I7J/Looks et al_2017_Deep Learning with Dynamic Computation Graphs.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/AA2E64N9/1702.html}
}

@inproceedings{marelli_sick_2014,
  title = {A {{SICK}} Cure for the Evaluation of Compositional Distributional Semantic Models.},
  url = {http://clic.cimec.unitn.it/marco/publications/marelli-etal-sick-lrec2014.pdf},
  booktitle = {{{LREC}}},
  urldate = {2017-06-12},
  date = {2014},
  pages = {216--223},
  author = {Marelli, Marco and Menini, Stefano and Baroni, Marco and Bentivogli, Luisa and Bernardi, Raffaella and Zamparelli, Roberto},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/RW36VE6Z/marelli-etal-sick-lrec2014.pdf}
}

@inproceedings{ganitkevitch_ppdb_2013,
  title = {{{PPDB}}: {{The Paraphrase Database}}.},
  url = {http://www.aclweb.org/anthology/N13-1#page=796},
  shorttitle = {{{PPDB}}},
  booktitle = {{{HLT}}-{{NAACL}}},
  urldate = {2017-06-12},
  date = {2013},
  pages = {758--764},
  author = {Ganitkevitch, Juri and Van Durme, Benjamin and Callison-Burch, Chris},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/I392T8XG/ppdb-naacl-2013.pdf}
}

@inproceedings{dolan_automatically_2005,
  title = {Automatically Constructing a Corpus of Sentential Paraphrases},
  url = {https://pdfs.semanticscholar.org/4753/54f10798f110d34792b6d88f31d6d5cb099e.pdf},
  booktitle = {Proc. of {{IWP}}},
  urldate = {2017-06-12},
  date = {2005},
  author = {Dolan, William B. and Brockett, Chris},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/D4UGW22M/da6d1238b2efdf7a483f0201baff65ceeb6b.pdf}
}

@article{vila_relational_2015,
  langid = {english},
  title = {Relational Paraphrase Acquisition from {{Wikipedia}}: {{The WRPA}} Method and Corpus},
  volume = {21},
  issn = {1351-3249, 1469-8110},
  url = {http://www.journals.cambridge.org/abstract_S1351324913000235},
  doi = {10.1017/S1351324913000235},
  shorttitle = {Relational Paraphrase Acquisition from {{Wikipedia}}},
  number = {03},
  journaltitle = {Natural Language Engineering},
  urldate = {2017-06-12},
  date = {2015-05},
  pages = {355-389},
  author = {Vila, M. and Rodr?Guez, H. and Mart?, M. A.}
}

@article{neubig_dynet_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1701.03980},
  primaryClass = {cs, stat},
  title = {{{DyNet}}: {{The Dynamic Neural Network Toolkit}}},
  url = {http://arxiv.org/abs/1701.03980},
  shorttitle = {{{DyNet}}},
  abstract = {We describe DyNet, a toolkit for implementing neural network models based on dynamic declaration of network structure. In the static declaration strategy that is used in toolkits like Theano, CNTK, and TensorFlow, the user first defines a computation graph (a symbolic representation of the computation), and then examples are fed into an engine that executes this computation and computes its derivatives. In DyNet's dynamic declaration strategy, computation graph construction is mostly transparent, being implicitly constructed by executing procedural code that computes the network outputs, and the user is free to use different network structures for each input. Dynamic declaration thus facilitates the implementation of more complicated network architectures, and DyNet is specifically designed to allow users to implement their models in a way that is idiomatic in their preferred programming language (C++ or Python). One challenge with dynamic declaration is that because the symbolic computation graph is defined anew for every training example, its construction must have low overhead. To achieve this, DyNet has an optimized C++ backend and lightweight graph representation. Experiments show that DyNet's speeds are faster than or comparable with static declaration toolkits, and significantly faster than Chainer, another dynamic declaration toolkit. DyNet is released open-source under the Apache 2.0 license and available at http://github.com/clab/dynet.},
  urldate = {2017-06-12},
  date = {2017-01-14},
  keywords = {Statistics - Machine Learning,Computer Science - Computation and Language,Computer Science - Mathematical Software},
  author = {Neubig, Graham and Dyer, Chris and Goldberg, Yoav and Matthews, Austin and Ammar, Waleed and Anastasopoulos, Antonios and Ballesteros, Miguel and Chiang, David and Clothiaux, Daniel and Cohn, Trevor and Duh, Kevin and Faruqui, Manaal and Gan, Cynthia and Garrette, Dan and Ji, Yangfeng and Kong, Lingpeng and Kuncoro, Adhiguna and Kumar, Gaurav and Malaviya, Chaitanya and Michel, Paul and Oda, Yusuke and Richardson, Matthew and Saphra, Naomi and Swayamdipta, Swabha and Yin, Pengcheng},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/M9ZM42CI/1701.html}
}

@article{tai_improved_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1503.00075},
  primaryClass = {cs},
  title = {Improved {{Semantic Representations From Tree}}-{{Structured Long Short}}-{{Term Memory Networks}}},
  url = {http://arxiv.org/abs/1503.00075},
  abstract = {Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).},
  urldate = {2017-06-12},
  date = {2015-02-28},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language,Computer Science - Artificial Intelligence,TreeLSTM},
  author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3K24EZX2/Tai et al_2015_Improved Semantic Representations From Tree-Structured Long Short-Term Memory.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/J6P8A3JW/1503.html}
}

@book{_head-driven_????,
  title = {Head-{{Driven Phrase Structure Grammar}}},
  url = {http://www.press.uchicago.edu/ucp/books/book/chicago/H/bo3618318.html},
  abstract = {This book presents the most complete exposition of the theory of head-driven phrase structure grammar (HPSG), introduced in the authors' Information-Based Syntax and Semantics. HPSG provides an integration of key ideas from the various disciplines of cognitive science, drawing on results from diverse approaches to syntactic theory, situation semantics, data type theory, and knowledge representation. The result is a conception of grammar as a set of declarative and order-independent constraints, a conception well suited to modelling human language processing. This self-contained volume demonstrates the applicability of the HPSG approach to a wide range of empirical problems, including a number which have occupied center-stage within syntactic theory for well over twenty years: the control of "understood" subjects, long-distance dependencies conventionally treated in terms of wh-movement, and syntactic constraints on the relationship between various kinds of pronouns and their antecedents. The authors make clear how their approach compares with and improves upon approaches undertaken in other frameworks, including in particular the government-binding theory of Noam Chomsky.},
  urldate = {2017-06-13},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/8J8PCVBX/bo3618318.html}
}

@article{muller_unifying_2013,
  title = {Unifying Everything: {{Some}} Remarks on Simpler Syntax, Construction Grammar, Minimalism, and {{HPSG}}},
  volume = {89},
  url = {https://muse.jhu.edu/article/532708/summary},
  shorttitle = {Unifying Everything},
  number = {4},
  journaltitle = {Language},
  urldate = {2017-06-13},
  date = {2013},
  pages = {920--950},
  author = {Müller, Stefan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/CKUCJS86/unifying-everything.pdf}
}

@article{m?ller_unifying_2013,
  langid = {english},
  title = {Unifying Everything: {{Some}} Remarks on Simpler Syntax, Construction Grammar, Minimalism, and {{HPSG}}},
  volume = {89},
  issn = {1535-0665},
  url = {http://muse.jhu.edu/content/crossref/journals/language/v089/89.4.muller.html},
  doi = {10.1353/lan.2013.0061},
  shorttitle = {Unifying Everything},
  number = {4},
  journaltitle = {Language},
  urldate = {2017-06-13},
  date = {2013},
  pages = {920-950},
  author = {M?ller, Stefan}
}

@article{levine_head-driven_2006,
  title = {Head-Driven Phrase Structure Grammar},
  volume = {5},
  journaltitle = {Encyclopedia of language and linguistics},
  date = {2006},
  pages = {237--52},
  author = {Levine, Robert D and Meurers, W Detmar},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WIM3QUJ5/ell2-hpsg.pdf}
}

@book{pollard_head-driven_1994,
  title = {Head-Driven Phrase Structure Grammar},
  publisher = {{University of Chicago Press}},
  date = {1994},
  author = {Pollard, Carl and Sag, Ivan A}
}

@article{schakel_measuring_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1508.02297},
  primaryClass = {cs},
  title = {Measuring {{Word Significance}} Using {{Distributed Representations}} of {{Words}}},
  url = {http://arxiv.org/abs/1508.02297},
  abstract = {Distributed representations of words as real-valued vectors in a relatively low-dimensional space aim at extracting syntactic and semantic features from large text corpora. A recently introduced neural network, named word2vec (Mikolov et al., 2013a; Mikolov et al., 2013b), was shown to encode semantic information in the direction of the word vectors. In this brief report, it is proposed to use the length of the vectors, together with the term frequency, as measure of word significance in a corpus. Experimental evidence using a domain-specific corpus of abstracts is presented to support this proposal. A useful visualization technique for text corpora emerges, where words are mapped onto a two-dimensional plane and automatically ranked by significance.},
  urldate = {2017-06-14},
  date = {2015-08-10},
  keywords = {Computer Science - Computation and Language},
  author = {Schakel, Adriaan M. J. and Wilson, Benjamin J.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BK54QMCR/Schakel_Wilson_2015_Measuring Word Significance using Distributed Representations of Words.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/R2CU5BKN/1508.html}
}

@inproceedings{bengio_curriculum_2009,
  title = {Curriculum Learning},
  url = {http://dl.acm.org/citation.cfm?id=1553380},
  booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
  publisher = {{ACM}},
  urldate = {2017-06-14},
  date = {2009},
  pages = {41--48},
  author = {Bengio, Yoshua and Louradour, Jérôme and Collobert, Ronan and Weston, Jason},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/M5BIAQB3/2009_curriculum_icml.pdf}
}

@article{shrivastava_learning_2016,
  title = {Learning from {{Simulated}} and {{Unsupervised Images}} through {{Adversarial Training}}},
  url = {https://arxiv.org/abs/1612.07828},
  journaltitle = {arXiv preprint arXiv:1612.07828},
  urldate = {2017-06-14},
  date = {2016},
  author = {Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Josh and Wang, Wenda and Webb, Russ},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/52XI7FN6/1612.07828v1.pdf}
}

@article{srivastava_dropout_2014,
  title = {Dropout: {{A}} Simple Way to Prevent Neural Networks from Overfitting},
  volume = {15},
  url = {http://www.jmlr.org/papers/volume15/srivastava14a.old/source/srivastava14a.pdf},
  shorttitle = {Dropout},
  number = {1},
  journaltitle = {The Journal of Machine Learning Research},
  urldate = {2017-06-14},
  date = {2014},
  pages = {1929--1958},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/5728IB6K/srivastava14a.pdf}
}

@inproceedings{hasan_why_2014,
  title = {Why Are {{You Taking}} This {{Stance}}? {{Identifying}} and {{Classifying Reasons}} in {{Ideological Debates}}.},
  url = {http://www.aclweb.org/old_anthology/D/D14/D14-1083.pdf},
  shorttitle = {Why Are {{You Taking}} This {{Stance}}?},
  booktitle = {{{EMNLP}}},
  urldate = {2017-06-15},
  date = {2014},
  pages = {751--762},
  author = {Hasan, Kazi Saidul and Ng, Vincent},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DW6UDQ5V/1a5add960025b6923309cafacac4927e580c.pdf}
}

@article{zhuang_neobility_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.05465},
  primaryClass = {cs},
  title = {Neobility at {{SemEval}}-2017 {{Task}} 1: {{An Attention}}-Based {{Sentence Similarity Model}}},
  url = {http://arxiv.org/abs/1703.05465},
  shorttitle = {Neobility at {{SemEval}}-2017 {{Task}} 1},
  abstract = {This paper describes a neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task. Our system employs an attention-based recurrent neural network model that optimizes the sentence similarity. In this paper, we describe our participation in the multilingual STS task which measures similarity across English, Spanish, and Arabic.},
  urldate = {2017-06-20},
  date = {2017-03-15},
  keywords = {Computer Science - Computation and Language},
  author = {Zhuang, Wenli and Chang, Ernie},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/VSW7NUKP/Zhuang_Chang_2017_Neobility at SemEval-2017 Task 1.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/6XG2G27T/1703.html}
}

@article{agirre_semeval-2016_2016,
  title = {Semeval-2016 Task 1: {{Semantic}} Textual Similarity, Monolingual and Cross-Lingual Evaluation},
  url = {http://www.aclweb.org/anthology/S16-1081},
  shorttitle = {Semeval-2016 Task 1},
  journaltitle = {Proceedings of SemEval},
  urldate = {2017-06-20},
  date = {2016},
  pages = {497--511},
  author = {Agirre, Eneko and Banea, Carmen and Cer, Daniel and Diab, Mona and Gonzalez-Agirre, Aitor and Mihalcea, Rada and Rigau, German and Wiebe, Janyce},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MVWQHS7D/5b6054aa6fd4b46f87cd632668aaf8a91db6.pdf}
}

@article{tian_ecnu_2016,
  title = {{{ECNU}} at {{SemEval}}-2016 {{Task}} 1: {{Leveraging}} Word Embedding from Macro and Micro Views to Boost Performance for Semantic Textual Similarity},
  url = {http://www.anthology.aclweb.org/S/S16/S16-1094.pdf},
  shorttitle = {{{ECNU}} at {{SemEval}}-2016 {{Task}} 1},
  journaltitle = {Proceedings of SemEval},
  urldate = {2017-06-20},
  date = {2016},
  pages = {621--627},
  author = {Tian, Junfeng and Lan, Man},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JR9PCJRQ/4b75a5221c90ddae003cf7a3576a7a303730.pdf}
}

@inproceedings{uszkoreit_common_2017,
  location = {{Valencia, Spain}},
  title = {Common {{Round}}: {{Application}} of {{Language Technologies}} to {{Large}}-{{Scale Web Debates}}},
  url = {http://aclweb.org/anthology/E17-3002},
  abstract = {Web debates play an important role in enabling broad participation of constituencies in social, political and economic decision-taking. However, it is challenging to organize, structure, and navigate a vast number of diverse argumentations and comments collected from many participants over a long time period. In this paper we demonstrate Common Round, a next generation platform for large-scale web debates, which provides functions for eliciting the semantic content and structures from the contributions of participants. In particular, Common Round applies language technologies for the extraction of semantic essence from textual input, aggregation of the formulated opinions and arguments. The platform also provides a cross-lingual access to debates using machine translation.},
  booktitle = {Proceedings of the {{Software Demonstrations}} of the 15th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2017-04},
  pages = {5--8},
  author = {Uszkoreit, Hans and Gabryszak, Aleksandra and Hennig, Leonhard and Steffen, Jörg and Ai, Renlong and Busemann, Stephan and Dehdari, Jon and van Genabith, Josef and Heigold, Georg and Rethmeier, Nils and Rubino, Raphael and Schmeier, Sven and Thomas, Philippe and Wang, He and Xu, Feiyu},
  options = {useprefix=true}
}

@article{petasis_identifying_2016,
  title = {Identifying {{Argument Components}} through {{TextRank}}},
  url = {http://www.aclweb.org/anthology/W/W16/W16-28.pdf#page=106},
  journaltitle = {ACL 2016},
  urldate = {2017-06-20},
  date = {2016},
  pages = {94},
  author = {Petasis, Georgios and Karkaletsis, Vangelis},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HD3Z3VAH/0dd1c8c4a0d8af499fd5e8911170fecb3589.pdf}
}

@article{egan_summarising_2016,
  title = {Summarising the Points Made in Online Political Debates},
  url = {http://www.aclweb.org/anthology/W/W16/W16-28.pdf#page=146},
  journaltitle = {ACL 2016},
  urldate = {2017-06-20},
  date = {2016},
  pages = {134},
  author = {Egan, Charlie and Siddharthan, Advaith and Wyner, Adam},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/N6W4AKPI/874e1757fbd1d0fa01759429d3999ba13202.pdf}
}

@article{yu_learning_2015,
  title = {Learning Composition Models for Phrase Embeddings},
  volume = {3},
  url = {https://transacl.org/ojs/index.php/tacl/article/view/586},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  urldate = {2017-06-20},
  date = {2015},
  pages = {227--242},
  author = {Yu, Mo and Dredze, Mark}
}

@online{_neuer_????,
  title = {Neuer {{Tab}}},
  url = {about:newtab},
  urldate = {2017-06-21},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/QFNINPPT/newtab.html}
}

@inproceedings{habernal_exploiting_2015,
  title = {Exploiting {{Debate Portals}} for {{Semi}}-{{Supervised Argumentation Mining}} in {{User}}-{{Generated Web Discourse}}.},
  url = {http://www.aclweb.org/anthology/D/D15/D15-1255.pdf},
  booktitle = {{{EMNLP}}},
  urldate = {2017-06-21},
  date = {2015},
  pages = {2127--2137},
  author = {Habernal, Ivan and Gurevych, Iryna},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Q48IRSCE/D15-1255.pdf}
}

@article{wang_comparison_2017,
  langid = {english},
  title = {Comparison {{Study}} on {{Critical Components}} in {{Composition Model}} for {{Phrase Representation}}},
  volume = {16},
  issn = {23754699},
  doi = {10.1145/3010088},
  number = {3},
  journaltitle = {ACM Transactions on Asian and Low-Resource Language Information Processing},
  date = {2017-01-20},
  pages = {1-25},
  keywords = {Phrase representation,composition model,max-margin,mean square error,retrofitting,word paraphrasing},
  author = {Wang, Shaonan and Zong, Chengqing},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DG42P9IB/a16-wang.pdf}
}

@article{bowman_fast_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1603.06021},
  primaryClass = {cs},
  title = {A {{Fast Unified Model}} for {{Parsing}} and {{Sentence Understanding}}},
  url = {http://arxiv.org/abs/1603.06021},
  abstract = {Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suffer from two key technical problems that make them slow and unwieldy for large-scale NLP tasks: they usually operate on parsed sentences and they do not directly support batched computation. We address these issues by introducing the Stack-augmented Parser-Interpreter Neural Network (SPINN), which combines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shift-reduce parser. Our model supports batched computation for a speedup of up to 25 times over other tree-structured models, and its integrated parser can operate on unparsed data with little loss in accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models.},
  urldate = {2017-06-22},
  date = {2016-03-18},
  keywords = {Computer Science - Computation and Language},
  author = {Bowman, Samuel R. and Gauthier, Jon and Rastogi, Abhinav and Gupta, Raghav and Manning, Christopher D. and Potts, Christopher}
}

@thesis{fyshe_corpora_2015,
  title = {Corpora and {{Cognition}}: {{The Semantic Composition}} of {{Adjectives}} and {{Nouns}} in the {{Human Brain}}},
  url = {http://www.cs.cmu.edu/~afyshe/thesis/afyshe_thesis.pdf},
  shorttitle = {Corpora and {{Cognition}}},
  institution = {{Air Force Research Laboratory}},
  urldate = {2017-06-22},
  date = {2015},
  author = {Fyshe, Alona},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/W7VBPAMK/afyshe_thesis.pdf}
}

@article{tian_mechanism_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.08407},
  title = {The {{Mechanism}} of {{Additive Composition}}},
  issn = {0885-6125, 1573-0565},
  url = {http://arxiv.org/abs/1511.08407},
  doi = {10.1007/s10994-017-5634-8},
  abstract = {Additive composition (Foltz et al, 1998; Landauer and Dumais, 1997; Mitchell and Lapata, 2010) is a widely used method for computing meanings of phrases, which takes the average of vector representations of the constituent words. In this article, we prove an upper bound for the bias of additive composition, which is the first theoretical analysis on compositional frameworks from a machine learning point of view. The bound is written in terms of collocation strength; we prove that the more exclusively two successive words tend to occur together, the more accurate one can guarantee their additive composition as an approximation to the natural phrase vector. Our proof relies on properties of natural language data that are empirically verified, and can be theoretically derived from an assumption that the data is generated from a Hierarchical Pitman-Yor Process. The theory endorses additive composition as a reasonable operation for calculating meanings of phrases, and suggests ways to improve additive compositionality, including: transforming entries of distributional word vectors by a function that meets a specific condition, constructing a novel type of vector representations to make additive composition sensitive to word order, and utilizing singular value decomposition to train word vectors.},
  journaltitle = {Machine Learning},
  urldate = {2017-06-22},
  date = {2017-04-03},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language},
  author = {Tian, Ran and Okazaki, Naoaki and Inui, Kentaro},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XR86GJ9F/Tian et al_2017_The Mechanism of Additive Composition.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/AU45696E/1511.html}
}

@article{levy_improving_2015,
  title = {Improving Distributional Similarity with Lessons Learned from Word Embeddings},
  volume = {3},
  url = {https://www.transacl.org/ojs/index.php/tacl/article/view/570},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  urldate = {2017-06-22},
  date = {2015},
  pages = {211--225},
  author = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HTIHABKI/Q15-1016.pdf}
}

@article{wieting_paraphrase_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.03487},
  primaryClass = {cs},
  title = {From {{Paraphrase Database}} to {{Compositional Paraphrase Model}} and {{Back}}},
  url = {http://arxiv.org/abs/1506.03487},
  abstract = {The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive semantic resource, consisting of a list of phrase pairs with (heuristic) confidence estimates. However, it is still unclear how it can best be used, due to the heuristic nature of the confidences and its necessarily incomplete coverage. We propose models to leverage the phrase pairs from the PPDB to build parametric paraphrase models that score paraphrase pairs more accurately than the PPDB's internal scores while simultaneously improving its coverage. They allow for learning phrase embeddings as well as improved word embeddings. Moreover, we introduce two new, manually annotated datasets to evaluate short-phrase paraphrasing models. Using our paraphrase model trained using PPDB, we achieve state-of-the-art results on standard word and bigram similarity tasks and beat strong baselines on our new short phrase paraphrase tasks.},
  urldate = {2017-06-22},
  date = {2015-06-10},
  keywords = {Computer Science - Computation and Language},
  author = {Wieting, John and Bansal, Mohit and Gimpel, Kevin and Livescu, Karen and Roth, Dan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/PNNEAEEN/Wieting et al_2015_From Paraphrase Database to Compositional Paraphrase Model and Back.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/H886HS8P/1506.html}
}

@inproceedings{dima_reverse-engineering_2015,
  title = {Reverse-Engineering {{Language}}: {{A Study}} on the {{Semantic Compositionality}} of {{German Compounds}}.},
  url = {http://www.aclweb.org/old_anthology/D/D15/D15-1188.pdf},
  shorttitle = {Reverse-Engineering {{Language}}},
  booktitle = {{{EMNLP}}},
  urldate = {2017-06-22},
  date = {2015},
  pages = {1637--1642},
  author = {Dima, Corina},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/B7A4MNBT/D15-1188.pdf}
}

@article{le_quantifying_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1603.00423},
  primaryClass = {cs},
  title = {Quantifying the Vanishing Gradient and Long Distance Dependency Problem in Recursive Neural Networks and Recursive {{LSTMs}}},
  url = {http://arxiv.org/abs/1603.00423},
  abstract = {Recursive neural networks (RNN) and their recently proposed extension recursive long short term memory networks (RLSTM) are models that compute representations for sentences, by recursively combining word embeddings according to an externally provided parse tree. Both models thus, unlike recurrent networks, explicitly make use of the hierarchical structure of a sentence. In this paper, we demonstrate that RNNs nevertheless suffer from the vanishing gradient and long distance dependency problem, and that RLSTMs greatly improve over RNN's on these problems. We present an artificial learning task that allows us to quantify the severity of these problems for both models. We further show that a ratio of gradients (at the root node and a focal leaf node) is highly indicative of the success of backpropagation at optimizing the relevant weights low in the tree. This paper thus provides an explanation for existing, superior results of RLSTMs on tasks such as sentiment analysis, and suggests that the benefits of including hierarchical structure and of including LSTM-style gating are complementary.},
  urldate = {2017-06-26},
  date = {2016-03-01},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Computation and Language,Computer Science - Artificial Intelligence},
  author = {Le, Phong and Zuidema, Willem}
}

@article{karpathy_visualizing_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.02078},
  primaryClass = {cs},
  title = {Visualizing and {{Understanding Recurrent Networks}}},
  url = {http://arxiv.org/abs/1506.02078},
  abstract = {Recurrent Neural Networks (RNNs), and specifically a variant with Long Short-Term Memory (LSTM), are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data. However, while LSTMs provide exceptional results in practice, the source of their performance and their limitations remain rather poorly understood. Using character-level language models as an interpretable testbed, we aim to bridge this gap by providing an analysis of their representations, predictions and error types. In particular, our experiments reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets. Moreover, our comparative analysis with finite horizon n-gram models traces the source of the LSTM improvements to long-range structural dependencies. Finally, we provide analysis of the remaining errors and suggests areas for further study.},
  urldate = {2017-06-26},
  date = {2015-06-05},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning,Computer Science - Computation and Language},
  author = {Karpathy, Andrej and Johnson, Justin and Fei-Fei, Li},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WBES3AJZ/1506.html}
}

@article{chung_empirical_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.3555},
  primaryClass = {cs},
  title = {Empirical {{Evaluation}} of {{Gated Recurrent Neural Networks}} on {{Sequence Modeling}}},
  url = {http://arxiv.org/abs/1412.3555},
  abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
  urldate = {2017-06-26},
  date = {2014-12-11},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning},
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/E8BIDJNC/Chung et al_2014_Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/H6EBFIMS/1412.html}
}

@article{amigo_comparison_2009,
  title = {A Comparison of Extrinsic Clustering Evaluation Metrics Based on Formal Constraints},
  volume = {12},
  url = {http://link.springer.com/article/10.1007/s10791-008-9066-8},
  number = {4},
  journaltitle = {Information retrieval},
  urldate = {2017-06-26},
  date = {2009},
  pages = {461--486},
  author = {Amigó, Enrique and Gonzalo, Julio and Artiles, Javier and Verdejo, Felisa},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/KV9MQ48K/Documento.pdf}
}

@article{zayats_conversation_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.02080},
  primaryClass = {cs},
  title = {Conversation {{Modeling}} on {{Reddit}} Using a {{Graph}}-{{Structured LSTM}}},
  url = {http://arxiv.org/abs/1704.02080},
  abstract = {This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM which represents both hierarchical and temporal conversation structure. In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features. Analyses show a benefit to the model over the full course of the discussion, improving detection in both early and late stages. Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments.},
  urldate = {2017-06-26},
  date = {2017-04-06},
  keywords = {Computer Science - Computation and Language},
  author = {Zayats, Vicky and Ostendorf, Mari},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/W9HTFA9A/Zayats_Ostendorf_2017_Conversation Modeling on Reddit using a Graph-Structured LSTM.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/H5FJEIB4/1704.html}
}

@article{zhang_characterizing_2017,
  title = {Characterizing {{Online Discussion Using Coarse Discourse Sequences}}},
  url = {http://people.csail.mit.edu/axz/papers/discourse.pdf},
  urldate = {2017-07-03},
  date = {2017},
  author = {Zhang, Amy X. and Culbertson, Bryan and Paritosh, Praveen},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WG4ICXI4/46055.pdf}
}

@article{kokkinos_structural_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1701.01811},
  primaryClass = {cs},
  title = {Structural {{Attention Neural Networks}} for Improved Sentiment Analysis},
  url = {http://arxiv.org/abs/1701.01811},
  abstract = {We introduce a tree-structured attention neural network for sentences and small phrases and apply it to the problem of sentiment classification. Our model expands the current recursive models by incorporating structural information around a node of a syntactic tree using both bottom-up and top-down information propagation. Also, the model utilizes structural attention to identify the most salient representations during the construction of the syntactic tree. To our knowledge, the proposed models achieve state of the art performance on the Stanford Sentiment Treebank dataset.},
  urldate = {2017-07-04},
  date = {2017-01-07},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Computation and Language},
  author = {Kokkinos, Filippos and Potamianos, Alexandros},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/UABN5UCR/Kokkinos_Potamianos_2017_Structural Attention Neural Networks for improved sentiment analysis.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MMWG9HM6/1701.html}
}

@software{alvations_stasis_2017,
  title = {Stasis: {{Semantic Textual Similarity}} in {{Python}}},
  url = {https://github.com/alvations/stasis},
  shorttitle = {Stasis},
  urldate = {2017-07-21},
  date = {2017-07-21T11:02:07Z},
  keywords = {semantic-textual-similarity,semeval,dataset,python},
  author = {{alvations}},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DZSR9NA3/stasis.html},
  origdate = {2015-01-23T10:03:11Z}
}

@software{_dataset-sts_2017,
  title = {Dataset-Sts: {{Semantic Text Similarity Dataset Hub}}},
  url = {https://github.com/brmson/dataset-sts},
  shorttitle = {Dataset-Sts},
  publisher = {{brmson}},
  urldate = {2017-07-21},
  date = {2017-07-21T11:01:14Z},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/C32M57GM/dataset-sts.html},
  origdate = {2016-01-21T03:22:10Z}
}

@article{eger_neural_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.06104},
  primaryClass = {cs},
  title = {Neural {{End}}-to-{{End Learning}} for {{Computational Argumentation Mining}}},
  url = {http://arxiv.org/abs/1704.06104},
  abstract = {We investigate neural techniques for end-to-end computational argumentation mining (AM). We frame AM both as a token-based dependency parsing and as a token-based sequence tagging problem, including a multi-task learning setup. Contrary to models that operate on the argument component level, we find that framing AM as dependency parsing leads to subpar performance results. In contrast, less complex (local) tagging models based on BiLSTMs perform robustly across classification scenarios, being able to catch long-range dependencies inherent to the AM problem. Moreover, we find that jointly learning 'natural' subtasks, in a multi-task learning setup, improves performance.},
  urldate = {2017-07-21},
  date = {2017-04-20},
  keywords = {Computer Science - Computation and Language},
  author = {Eger, Steffen and Daxenberger, Johannes and Gurevych, Iryna},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/B7WPJRWZ/Eger et al_2017_Neural End-to-End Learning for Computational Argumentation Mining.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DEXZNKS4/1704.html}
}

@article{huang_paraphrase_2011,
  title = {Paraphrase Detection Using Recursive Autoencoder},
  url = {http://www-nlp.stanford.edu/courses/cs224n/2011/reports/ehhuang.pdf},
  journaltitle = {Source:[http://nlp. stanford. edu/courses/cs224n/2011/reports/ehhuang. pdf]},
  urldate = {2017-07-26},
  date = {2011},
  author = {Huang, Eric},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Z298FAEW/1c248d67635b71d294eaacbb39a5ffce0359.pdf}
}

@article{wang_sentence_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.07019},
  primaryClass = {cs},
  title = {Sentence {{Similarity Learning}} by {{Lexical Decomposition}} and {{Composition}}},
  url = {http://arxiv.org/abs/1602.07019},
  abstract = {Most conventional sentence similarity methods only focus on similar parts of two input sentences, and simply ignore the dissimilar parts, which usually give us some clues and semantic meanings about the sentences. In this work, we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences. The model represents each word as a vector, and calculates a semantic matching vector for each word based on all words in the other sentence. Then, each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector. After this, a two-channel CNN model is employed to capture features by composing the similar and dissimilar components. Finally, a similarity score is estimated over the composed feature vectors. Experimental results show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.},
  urldate = {2017-07-26},
  date = {2016-02-22},
  keywords = {Computer Science - Computation and Language},
  author = {Wang, Zhiguo and Mi, Haitao and Ittycheriah, Abraham},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GXFDCB5D/Wang et al_2016_Sentence Similarity Learning by Lexical Decomposition and Composition.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/N5J65MIF/1602.html}
}

@inproceedings{mueller_siamese_2016,
  title = {Siamese {{Recurrent Architectures}} for {{Learning Sentence Similarity}}.},
  url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12195/12023},
  booktitle = {{{AAAI}}},
  urldate = {2017-07-26},
  date = {2016},
  pages = {2786--2792},
  keywords = {Manhatten distance},
  author = {Mueller, Jonas and Thyagarajan, Aditya},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/W5P6RNWC/MuellerThyagarajan_AAAI16.pdf}
}

@article{pascanu_difficulty_2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1211.5063},
  primaryClass = {cs},
  title = {On the Difficulty of Training {{Recurrent Neural Networks}}},
  url = {http://arxiv.org/abs/1211.5063},
  abstract = {There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
  urldate = {2017-07-28},
  date = {2012-11-21},
  keywords = {Computer Science - Learning},
  author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua}
}

@article{agirre_sem_2013,
  title = {{{SEM}} 2013 Shared Task: {{Semantic Textual Similarity}}},
  url = {http://www.aclweb.org/website/old_anthology/S/S13/S13-1.pdf#page=58},
  journaltitle = {Atlanta, Georgia, USA},
  urldate = {2017-07-29},
  date = {2013},
  pages = {32},
  author = {Agirre, Eneko and Cer, Daniel and Diab, Mona and Gonzalez-Agirre, Aitor and Guo, Weiwei},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/7P7SG2KE/download\;jsessionid=BA8DE2BF5A8903E33FBA9526D03168D3.pdf}
}

@book{krause_taxicab_1987,
  location = {{New York}},
  title = {Taxicab {{Geometry}}: An Adventure in Non-{{Euclidean}} Geometry},
  isbn = {978-0-486-25202-5},
  shorttitle = {Taxicab {{Geometry}}},
  abstract = {Develops a simple non-Euclidean geometry and explores some of its practical applications through graphs, research problems, and exercises. Includes selected answers},
  pagetotal = {88},
  publisher = {{Dover Publications}},
  date = {1987},
  keywords = {Geometry; Non-Euclidean,Juvenile literature},
  author = {Krause, Eugene F.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HUCCVUJJ/A_Survey_of_Text_Similarity_Approaches.pdf}
}

@online{_survey_????,
  title = {A {{Survey}} of {{Text Similarity Approaches}} - {{A}}\_{{Survey}}\_of\_{{Text}}\_{{Similarity}}\_{{Approaches}}.Pdf},
  url = {http://s3.amazonaws.com/academia.edu.documents/35754965/A_Survey_of_Text_Similarity_Approaches.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1501679464&Signature=a8RMn77ifYkQQ%2BBX8BWfoX%2Fly1c%3D&response-content-disposition=inline%3B%20filename%3DA_Survey_of_Text_Similarity_Approaches.pdf},
  urldate = {2017-08-02}
}

@article{gomaa_survey_2013,
  title = {A Survey of Text Similarity Approaches},
  volume = {68},
  number = {13},
  journaltitle = {International Journal of Computer Applications},
  date = {2013},
  author = {Gomaa, Wael H and Fahmy, Aly A},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/62CSXR2U/A_Survey_of_Text_Similarity_Approaches.pdf}
}

@article{bojanowski_enriching_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1607.04606},
  primaryClass = {cs},
  title = {Enriching {{Word Vectors}} with {{Subword Information}}},
  url = {http://arxiv.org/abs/1607.04606},
  abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character \$n\$-grams. A vector representation is associated to each character \$n\$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
  urldate = {2017-08-04},
  date = {2016-07-15},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language},
  author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DI65RQ58/Bojanowski et al_2016_Enriching Word Vectors with Subword Information.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/65W5QPDC/1607.html}
}

@article{oshea_comparative_2008,
  title = {A Comparative Study of Two Short Text Semantic Similarity Measures},
  url = {http://www.springerlink.com/index/V0867641U342PM28.pdf},
  journaltitle = {Agent and Multi-Agent Systems: Technologies and Applications},
  urldate = {2017-08-09},
  date = {2008},
  pages = {172--181},
  author = {O’Shea, James and Bandar, Zuhair and Crockett, Keeley and McLean, David},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HKTQXJ8Z/f5a434beb4f27a812ba8461e2bd710f4c9c1.pdf}
}

@inproceedings{kenter_short_2015,
  langid = {english},
  title = {Short {{Text Similarity}} with {{Word Embeddings}}},
  isbn = {978-1-4503-3794-6},
  url = {http://dl.acm.org/citation.cfm?doid=2806416.2806475},
  doi = {10.1145/2806416.2806475},
  publisher = {{ACM Press}},
  urldate = {2017-08-09},
  date = {2015},
  pages = {1411-1420},
  author = {Kenter, Tom and de Rijke, Maarten},
  options = {useprefix=true},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3NMSPU7E/kenter-short-2015.pdf}
}

@online{_web-based_????,
  title = {A {{Web}}-Based {{Kernel Function}} for {{Measuring}} the {{Similarity}} of {{Short Text Snippets}}},
  url = {http://www2006.org/programme/files/xhtml/3069/3069-sahami/3069-sahami-xhtml.html},
  urldate = {2017-08-09},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/P6D54QW6/3069-sahami-xhtml.html}
}

@article{quan_short_2010,
  langid = {english},
  title = {Short Text Similarity Based on Probabilistic Topics},
  volume = {25},
  issn = {0219-1377, 0219-3116},
  url = {https://link.springer.com/article/10.1007/s10115-009-0250-y},
  doi = {10.1007/s10115-009-0250-y},
  abstract = {In this paper, we propose a new method for measuring the similarity between two short text snippets by comparing each of them with the probabilistic topics. Specifically, our method starts by firstly finding the distinguishing terms between the two short text snippets and comparing them with a series of probabilistic topics, extracted by Gibbs sampling algorithm. The relationship between the distinguishing terms of the short text snippets can be discovered by examining their probabilities under each topic. The similarity between two short text snippets is calculated based on their common terms and the relationship of their distinguishing terms. Extensive experiments on paraphrasing and question categorization show that the proposed method can calculate the similarity of short text snippets more accurately than other methods including the pure TF-IDF measure.},
  number = {3},
  journaltitle = {Knowledge and Information Systems},
  shortjournal = {Knowl Inf Syst},
  urldate = {2017-08-09},
  date = {2010-12-01},
  pages = {473-491},
  author = {Quan, Xiaojun and Liu, Gang and Lu, Zhi and Ni, Xingliang and Wenyin, Liu},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MAH488M5/10.html}
}

@article{islam_semantic_2008,
  title = {Semantic Text Similarity Using Corpus-Based Word Similarity and String Similarity},
  volume = {2},
  url = {http://dl.acm.org/citation.cfm?id=1376819},
  number = {2},
  journaltitle = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
  urldate = {2017-08-09},
  date = {2008},
  pages = {10},
  author = {Islam, Aminul and Inkpen, Diana},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GR285HG3/913bf05cbde6e24c98d9fe06ebaed7dbd372.pdf}
}

@article{oliva_symss_2011,
  langid = {english},
  title = {{{SyMSS}}: {{A}} Syntax-Based Measure for Short-Text Semantic Similarity},
  volume = {70},
  issn = {0169023X},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0169023X11000036},
  doi = {10.1016/j.datak.2011.01.002},
  shorttitle = {{{SyMSS}}},
  number = {4},
  journaltitle = {Data \& Knowledge Engineering},
  urldate = {2017-08-09},
  date = {2011-04},
  pages = {390-405},
  author = {Oliva, Jesús and Serrano, José Ignacio and del Castillo, María Dolores and Iglesias, Ángel},
  options = {useprefix=true},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DSMMI3B2/1-s2.0-S0169023X11000036-main.pdf}
}

@inproceedings{annesi_semantic_2014,
  location = {{New York, NY, USA}},
  title = {Semantic {{Compositionality}} in {{Tree Kernels}}},
  isbn = {978-1-4503-2598-1},
  url = {http://doi.acm.org/10.1145/2661829.2661955},
  doi = {10.1145/2661829.2661955},
  abstract = {Kernel-based learning has been largely applied to semantic textual inference tasks. In particular, Tree Kernels (TKs) are crucial in the modeling of syntactic similarity between linguistic instances in Question Answering or Information Extraction tasks. At the same time, lexical semantic information has been studied through the adoption of the so-called Distributional Semantics (DS) paradigm, where lexical vectors are acquired automatically from large corpora. Notice how methods to account for compositional linguistic structures (e.g. grammatically typed bi-grams or complex verb or noun phrases) have been proposed recently by defining algebras on lexical vectors. The result is an extended paradigm called Distributional Compositional Semantics (DCS). Although lexical extensions have been already proposed to generalize TKs towards semantic phenomena (e.g. the predicate argument structures as for role labeling), currently studied TKs do not account for compositionality, in general. In this paper, a novel kernel called Compositionally Smoothed Partial Tree Kernel is proposed to integrate DCS operators into the tree kernel evaluation, by acting both over lexical leaves and non-terminal, i.e. complex compositional, nodes. The empirical results obtained on a Question Classification and Paraphrase Identification tasks show that state-of-the-art performances can be achieved, without resorting to manual feature engineering, thus suggesting that a large set of Web and text mining tasks can be handled successfully by the kernel proposed here.},
  booktitle = {Proceedings of the 23rd {{ACM International Conference}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  series = {CIKM '14},
  publisher = {{ACM}},
  urldate = {2017-08-10},
  date = {2014},
  pages = {1029--1038},
  keywords = {natural language processing,compositional distributional semantics,kernel machines,tree kernel},
  author = {Annesi, Paolo and Croce, Danilo and Basili, Roberto},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/QUCWK9XU/Annesi et al_2014_Semantic Compositionality in Tree Kernels.pdf}
}

@article{pagliardini_unsupervised_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.02507},
  primaryClass = {cs},
  title = {Unsupervised {{Learning}} of {{Sentence Embeddings}} Using {{Compositional}} N-{{Gram Features}}},
  url = {http://arxiv.org/abs/1703.02507},
  abstract = {The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.},
  urldate = {2017-08-14},
  date = {2017-03-07},
  keywords = {Computer Science - Computation and Language,Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,I.2.7},
  author = {Pagliardini, Matteo and Gupta, Prakhar and Jaggi, Martin},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/5BXXW5DS/Pagliardini et al_2017_Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GZH4CZHM/Pagliardini et al_2017_Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/6WIQFWSP/1703.html;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MK6T5NXC/1703.html}
}

@inproceedings{marelli_semeval-2014_2014,
  title = {{{SemEval}}-2014 {{Task}} 1: {{Evaluation}} of {{Compositional Distributional Semantic Models}} on {{Full Sentences}} through {{Semantic Relatedness}} and {{Textual Entailment}}.},
  url = {https://www.aclweb.org/anthology/S/S14/S14-2.pdf#page=21},
  shorttitle = {{{SemEval}}-2014 {{Task}} 1},
  booktitle = {{{SemEval}}@ {{COLING}}},
  urldate = {2017-08-14},
  date = {2014},
  pages = {1--8},
  author = {Marelli, Marco and Bentivogli, Luisa and Baroni, Marco and Bernardi, Raffaella and Menini, Stefano and Zamparelli, Roberto},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Q6ESFF8N/56898a9e7f401a2affe776b5297bd4e25025.pdf}
}

@article{vaswani_attention_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.03762},
  primaryClass = {cs},
  title = {Attention {{Is All You Need}}},
  url = {http://arxiv.org/abs/1706.03762},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  urldate = {2017-08-17},
  date = {2017-06-12},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FWRXHV8W/1706.html}
}

@article{bentivogli_sick_2016,
  langid = {english},
  title = {{{SICK}} through the {{SemEval}} Glasses. {{Lesson}} Learned from the Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment},
  volume = {50},
  issn = {1574-020X, 1574-0218},
  url = {http://link.springer.com/10.1007/s10579-015-9332-5},
  doi = {10.1007/s10579-015-9332-5},
  number = {1},
  journaltitle = {Language Resources and Evaluation},
  urldate = {2017-08-23},
  date = {2016-03},
  pages = {95-124},
  author = {Bentivogli, Luisa and Bernardi, Raffaella and Marelli, Marco and Menini, Stefano and Baroni, Marco and Zamparelli, Roberto},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/BJFQNKB9/SICK-Through-the-SemEval-Glasses-Lesson-learned-from-the-evaluation-of-compositional-distributional-semantic-models-on-full-sentences-through-semantic-relatedness-and-textual-entailment.pdf}
}

@incollection{dagan_pascal_2006,
  title = {The {{PASCAL}} Recognising Textual Entailment Challenge},
  url = {ftp://nozdr.ru/biblio/kolxo3/Cs/CsLn/Machine%20Learning%20Challenges,%201%20conf.,%20MLCW%202005(LNCS3944,%20Springer,%202006)(ISBN%203540334270)(473s).pdf#page=188},
  booktitle = {Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment},
  publisher = {{Springer}},
  date = {2006},
  pages = {177--190},
  author = {Dagan, Ido and Glickman, Oren and Magnini, Bernardo}
}

@online{_coi32103.dvi_????,
  title = {Coi32103.Dvi - Coli.2006.32.1.13.Pdf},
  url = {http://delivery.acm.org/10.1145/1170000/1168108/coli.2006.32.1.13.pdf?ip=134.96.191.252&id=1168108&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&CFID=976201936&CFTOKEN=49675072&__acm__=1503579624_f65c7d77466d3489c90247a4b42b811c},
  urldate = {2017-08-24}
}

@article{sahlgren_distributional_2008,
  title = {The Distributional Hypothesis},
  volume = {20},
  url = {http://www.diva-portal.org/smash/get/diva2:1035870/FULLTEXT01.pdf},
  journaltitle = {Italian Journal of Disability Studies},
  urldate = {2017-08-24},
  date = {2008},
  pages = {33--53},
  author = {Sahlgren, Magnus}
}

@article{budanitsky_evaluating_2006,
  title = {Evaluating Wordnet-Based Measures of Lexical Semantic Relatedness},
  volume = {32},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/coli.2006.32.1.13},
  number = {1},
  journaltitle = {Computational Linguistics},
  urldate = {2017-08-24},
  date = {2006},
  pages = {13--47},
  author = {Budanitsky, Alexander and Hirst, Graeme},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/FTDUAXBX/coli.2006.32.1.13.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/IKF3J7NP/coli.2006.32.1.pdf}
}

@article{sparck_jones_statistical_1972,
  title = {A Statistical Interpretation of Term Specificity and Its Application in Retrieval},
  volume = {28},
  url = {http://www.emeraldinsight.com/doi/abs/10.1108/eb026526},
  number = {1},
  journaltitle = {Journal of documentation},
  urldate = {2017-09-04},
  date = {1972},
  pages = {11--21},
  author = {Sparck Jones, Karen}
}

@inproceedings{das_gaussian_2015,
  title = {Gaussian {{LDA}} for {{Topic Models}} with {{Word Embeddings}}.},
  url = {http://www.aclweb.org/old_anthology/P/P15/P15-1077.pdf},
  booktitle = {{{ACL}} (1)},
  urldate = {2017-09-05},
  date = {2015},
  pages = {795--804},
  author = {Das, Rajarshi and Zaheer, Manzil and Dyer, Chris}
}

@article{harris_distributional_1954,
  langid = {english},
  title = {Distributional {{Structure}}},
  volume = {10},
  issn = {0043-7956, 2373-5112},
  url = {http://www.tandfonline.com/doi/full/10.1080/00437956.1954.11659520},
  doi = {10.1080/00437956.1954.11659520},
  number = {2-3},
  journaltitle = {\emph{WORD}},
  urldate = {2017-09-05},
  date = {1954-08},
  pages = {146-162},
  author = {Harris, Zellig S.}
}

@inproceedings{levy_neural_2014,
  title = {Neural Word Embedding as Implicit Matrix Factorization},
  url = {http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization},
  booktitle = {Advances in Neural Information Processing Systems},
  urldate = {2017-09-05},
  date = {2014},
  pages = {2177--2185},
  author = {Levy, Omer and Goldberg, Yoav}
}

@article{deerwester_indexing_1990,
  title = {Indexing by Latent Semantic Analysis},
  volume = {41},
  number = {6},
  journaltitle = {Journal of the American society for information science},
  date = {1990},
  pages = {391},
  author = {Deerwester, Scott and Dumais, Susan T. and Furnas, George W. and Landauer, Thomas K. and Harshman, Richard}
}

@incollection{jurafsky_vector_????,
  title = {Vector {{Semantics}}},
  url = {https://web.stanford.edu/~jurafsky/slp3/15.pdf},
  booktitle = {Speech and {{Language Processing}}},
  author = {Jurafsky, Daniel and Martin, James H.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/9CHA8IWQ/15.pdf}
}

@book{index_global_2013,
  title = {Global Mobile Data Traffic Forecast Update, 2012-2017},
  date = {2013},
  author = {Index, Cisco Visual Networking},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MFNGAUI6/ed3book.pdf}
}

@article{lee_generalizing_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1509.08985},
  primaryClass = {cs, stat},
  title = {Generalizing {{Pooling Functions}} in {{Convolutional Neural Networks}}: {{Mixed}}, {{Gated}}, and {{Tree}}},
  url = {http://arxiv.org/abs/1509.08985},
  shorttitle = {Generalizing {{Pooling Functions}} in {{Convolutional Neural Networks}}},
  abstract = {We seek to improve deep neural networks by generalizing the pooling operations that play a central role in current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets; they are also easy to implement, and can be applied within various deep neural network architectures. These benefits come with only a light increase in computational overhead during training and a very modest increase in the number of model parameters.},
  urldate = {2017-09-08},
  date = {2015-09-29},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning,Statistics - Machine Learning},
  author = {Lee, Chen-Yu and Gallagher, Patrick W. and Tu, Zhuowen},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/EA9HXN5G/1509.html}
}

@book{jurafsky_speech_2014,
  title = {Speech and Language Processing},
  volume = {3},
  url = {http://www.cs.colorado.edu/~martin/SLP/Updates/1.pdf},
  publisher = {{Pearson London}},
  urldate = {2017-09-09},
  date = {2014},
  author = {Jurafsky, Dan and Martin, James H.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/KE9RALC4/0131873210.pdf}
}

@article{epelbaum_deep_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1709.01412},
  primaryClass = {cs, stat},
  title = {Deep Learning: {{Technical}} Introduction},
  url = {http://arxiv.org/abs/1709.01412},
  shorttitle = {Deep Learning},
  abstract = {This note presents in a technical though hopefully pedagogical way the three most common forms of neural network architectures: Feedforward, Convolutional and Recurrent. For each network, their fundamental building blocks are detailed. The forward pass and the update rules for the backpropagation algorithm are then derived in full.},
  urldate = {2017-09-10},
  date = {2017-09-05},
  keywords = {Computer Science - Learning,Statistics - Machine Learning},
  author = {Epelbaum, Thomas},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HWF7LREM/1709.html}
}

@article{polyak_methods_1964,
  title = {Some Methods of Speeding up the Convergence of Iteration Methods},
  volume = {4},
  issn = {0041-5553},
  url = {http://www.sciencedirect.com/science/article/pii/0041555364901375},
  doi = {10.1016/0041-5553(64)90137-5},
  abstract = {For the solution of the functional equation P (x) = 0 (1) (where P is an operator, usually linear, from B into B, and B is a Banach space) iteration methods are generally used. These consist of the construction of a series x0, …, xn, …, which converges to the solution (see, for example [1]). Continuous analogues of these methods are also known, in which a trajectory x(t), 0 ⩽ t ⩽ ∞ is constructed, which satisfies the ordinary differential equation in B and is such that x(t) approaches the solution of (1) as t → ∞ (see [2]). We shall call the method a k-step method if for the construction of each successive iteration xn+1 we use k previous iterations xn, …, xn−k+1. The same term will also be used for continuous methods if x(t) satisfies a differential equation of the k-th order or k-th degree. Iteration methods which are more widely used are one-step (e.g. methods of successive approximations). They are generally simple from the calculation point of view but often converge very slowly. This is confirmed both by the evaluation of the speed of convergence and by calculation in practice (for more details see below). Therefore the question of the rate of convergence is most important. Some multistep methods, which we shall consider further, which are only slightly more complicated than the corresponding one-step methods, make it possible to speed up the convergence substantially. Note that all the methods mentioned below are applicable also to the problem of minimizing the differentiable functional (x) in Hilbert space, so long as this problem reduces to the solution of the equation grad (x) = 0.},
  number = {5},
  journaltitle = {USSR Computational Mathematics and Mathematical Physics},
  shortjournal = {USSR Computational Mathematics and Mathematical Physics},
  urldate = {2017-09-12},
  date = {1964-01-01},
  pages = {1-17},
  author = {Polyak, B. T.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JYBLCN8L/0041555364901375.html}
}

@article{zeiler_adadelta_2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1212.5701},
  primaryClass = {cs},
  title = {{{ADADELTA}}: {{An Adaptive Learning Rate Method}}},
  url = {http://arxiv.org/abs/1212.5701},
  shorttitle = {{{ADADELTA}}},
  abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
  urldate = {2017-09-12},
  date = {2012-12-22},
  keywords = {Computer Science - Learning},
  author = {Zeiler, Matthew D.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/GWU8MZWQ/1212.html;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/JND8VANP/1212.html}
}

@article{rumelhart_learning_1988,
  title = {Learning Representations by Back-Propagating Errors},
  volume = {5},
  number = {3},
  journaltitle = {Cognitive modeling},
  date = {1988},
  pages = {1},
  author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and {others}}
}

@article{radford_unsupervised_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.06434},
  primaryClass = {cs},
  title = {Unsupervised {{Representation Learning}} with {{Deep Convolutional Generative Adversarial Networks}}},
  url = {http://arxiv.org/abs/1511.06434},
  abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
  urldate = {2017-09-21},
  date = {2015-11-19},
  keywords = {Computer Science - Learning,Computer Science - Computer Vision and Pattern Recognition},
  author = {Radford, Alec and Metz, Luke and Chintala, Soumith}
}

@article{jozefowicz_exploring_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.02410},
  primaryClass = {cs},
  title = {Exploring the {{Limits}} of {{Language Modeling}}},
  url = {http://arxiv.org/abs/1602.02410},
  abstract = {In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.},
  urldate = {2017-09-21},
  date = {2016-02-07},
  keywords = {Computer Science - Computation and Language},
  author = {Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui}
}

@article{tzeng_adversarial_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1702.05464},
  primaryClass = {cs},
  title = {Adversarial {{Discriminative Domain Adaptation}}},
  url = {http://arxiv.org/abs/1702.05464},
  abstract = {Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They also can improve recognition despite the presence of domain shift or dataset bias: several adversarial approaches to unsupervised domain adaptation have recently been introduced, which reduce the difference between the training and test domain distributions and thus improve generalization performance. Prior generative approaches show compelling visualizations, but are not optimal on discriminative tasks and can be limited to smaller shifts. Prior discriminative approaches could handle larger domain shifts, but imposed tied weights on the model and did not exploit a GAN-based loss. We first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and we use this generalized view to better relate the prior approaches. We propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard cross-domain digit classification tasks and a new more difficult cross-modality object classification task.},
  urldate = {2017-09-21},
  date = {2017-02-17},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Tzeng, Eric and Hoffman, Judy and Saenko, Kate and Darrell, Trevor}
}

@article{ganin_unsupervised_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.7495},
  primaryClass = {cs, stat},
  title = {Unsupervised {{Domain Adaptation}} by {{Backpropagation}}},
  url = {http://arxiv.org/abs/1409.7495},
  abstract = {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of "deep" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation. Overall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.},
  urldate = {2017-09-22},
  date = {2014-09-26},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning,Statistics - Machine Learning},
  author = {Ganin, Yaroslav and Lempitsky, Victor},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/K3QHS7SW/Ganin und Lempitsky - 2014 - Unsupervised Domain Adaptation by Backpropagation.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/IKNNNBYF/1409.html}
}

@article{pan_survey_2010,
  title = {A {{Survey}} on {{Transfer Learning}}},
  volume = {22},
  issn = {1041-4347},
  url = {https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf},
  doi = {10.1109/TKDE.2009.191},
  abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
  number = {10},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  date = {2010-10},
  pages = {1345-1359},
  keywords = {data mining,machine learning,Data mining,data mining.,inductive transfer learning,knowledge engineering,Knowledge engineering,knowledge transfer,Knowledge transfer,Labeling,learning by example,Learning systems,Machine learning,Machine learning algorithms,optimisation,Space technology,survey,Testing,Training data,transductive transfer learning,Transfer learning,unsupervised learning,unsupervised transfer learning},
  author = {Pan, S. J. and Yang, Q.}
}

@inproceedings{bengio_deep_2012,
  location = {{Bellevue, Washington, USA}},
  title = {Deep {{Learning}} of {{Representations}} for {{Unsupervised}} and {{Transfer Learning}}},
  volume = {27},
  url = {http://proceedings.mlr.press/v27/bengio12a/bengio12a.pdf},
  abstract = {Deep learning algorithms seek to exploit the unknown structure in the input distribution in order to discover good representations, often at multiple levels, with higher-level learned features defined in terms of lower-level features. The objective is to make these higher-level representations more abstract, with their individual features more invariant to most of the variations that are typically present in the training distribution, while collectively preserving as much as possible of the information in the input. Ideally, we would like these representations to disentangle the unknown factors of variation that underlie the training distribution. Such unsupervised learning of representations can be exploited usefully under the hypothesis that the input distribution \$P(x)\$ is structurally related to some task of interest, say predicting \$P(y|x)\$. This paper focuses on the context of the Unsupervised and Transfer Learning Challenge, on why unsupervised pre-training of representations can be useful, and how it can be exploited in the transfer learning scenario, where we care about predictions on examples that are not from the same distribution as the training distribution.},
  booktitle = {Proceedings of {{ICML Workshop}} on {{Unsupervised}} and {{Transfer Learning}}},
  series = {Proceedings of Machine Learning Research},
  publisher = {{PMLR}},
  date = {2012-07-02},
  pages = {17--36},
  author = {Bengio, Yoshua},
  editor = {Guyon, Isabelle and Dror, Gideon and Lemaire, Vincent and Taylor, Graham and Silver, Daniel}
}

@article{chen_marginalized_2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1206.4683},
  primaryClass = {cs},
  title = {Marginalized {{Denoising Autoencoders}} for {{Domain Adaptation}}},
  url = {http://arxiv.org/abs/1206.4683},
  abstract = {Stacked denoising autoencoders (SDAs) have been successfully used to learn new representations for domain adaptation. Recently, they have attained record accuracy on standard benchmark tasks of sentiment analysis across different text domains. SDAs learn robust data representations by reconstruction, recovering original features from data that are artificially corrupted with noise. In this paper, we propose marginalized SDA (mSDA) that addresses two crucial limitations of SDAs: high computational cost and lack of scalability to high-dimensional features. In contrast to SDAs, our approach of mSDA marginalizes noise and thus does not require stochastic gradient descent or other optimization algorithms to learn parameters ? in fact, they are computed in closed-form. Consequently, mSDA, which can be implemented in only 20 lines of MATLAB\^\{TM\}, significantly speeds up SDAs by two orders of magnitude. Furthermore, the representations learnt by mSDA are as effective as the traditional SDAs, attaining almost identical accuracies in benchmark tasks.},
  urldate = {2017-09-25},
  date = {2012-06-18},
  keywords = {Computer Science - Learning},
  author = {Chen, Minmin and Xu, Zhixiang and Weinberger, Kilian and Sha, Fei},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XG9BGPVW/Chen et al. - 2012 - Marginalized Denoising Autoencoders for Domain Ada.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/H6ZZR23W/1206.html}
}

@inproceedings{glorot_domain_2011,
  title = {Domain Adaptation for Large-Scale Sentiment Classification: {{A}} Deep Learning Approach},
  url = {http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Glorot_342.pdf},
  shorttitle = {Domain Adaptation for Large-Scale Sentiment Classification},
  booktitle = {Proceedings of the 28th International Conference on Machine Learning ({{ICML}}-11)},
  urldate = {2017-09-25},
  date = {2011},
  pages = {513--520},
  author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua}
}

@book{lund_semantic_1995,
  title = {Semantic and Associative Priming in High-Dimensional Semantic Space},
  pagetotal = {660},
  date = {1995-01-01},
  keywords = {HAL},
  author = {Lund, Kevin and Burgess, Curt and Atchley, Ruth}
}

@article{lund_producing_1996,
  title = {Producing High-Dimensional Semantic Spaces from Lexical Co-Occurrence},
  volume = {28},
  url = {http://link.springer.com/article/10.3758/BF03204766},
  number = {2},
  journaltitle = {Behavior Research Methods, Instruments, \& Computers},
  urldate = {2017-09-25},
  date = {1996},
  pages = {203--208},
  keywords = {HAL},
  author = {Lund, Kevin and Burgess, Curt}
}

@article{cer_semeval-2017_2017,
  title = {{{SemEval}}-2017 {{Task}} 1: {{Semantic Textual Similarity}}-{{Multilingual}} and {{Cross}}-Lingual {{Focused Evaluation}}},
  url = {https://arxiv.org/abs/1708.00055},
  shorttitle = {{{SemEval}}-2017 {{Task}} 1},
  journaltitle = {arXiv preprint arXiv:1708.00055},
  urldate = {2017-09-26},
  date = {2017},
  author = {Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia}
}

@inproceedings{prechelt_early_1998,
  location = {{London, UK, UK}},
  title = {Early {{Stopping}}-{{But When}}?},
  isbn = {3-540-65311-2},
  url = {http://dl.acm.org/citation.cfm?id=645754.668392},
  booktitle = {Neural {{Networks}}: {{Tricks}} of the {{Trade}}, {{This Book}} Is an {{Outgrowth}} of a 1996 {{NIPS Workshop}}},
  publisher = {{Springer-Verlag}},
  date = {1998},
  pages = {55--69},
  author = {Prechelt, Lutz}
}

@article{kiros_skip-thought_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.06726},
  primaryClass = {cs},
  title = {Skip-{{Thought Vectors}}},
  url = {https://arxiv.org/pdf/1506.06726.pdf},
  abstract = {We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.},
  urldate = {2017-09-28},
  date = {2015-06-22},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language},
  author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan and Zemel, Richard S. and Torralba, Antonio and Urtasun, Raquel and Fidler, Sanja}
}

@inproceedings{shazeer_sparse_2015,
  title = {Sparse Non-Negative Matrix Language Modeling for Skip-Grams},
  url = {https://lirias.kuleuven.be/bitstream/123456789/511499/1/3976_postprint.pdf},
  booktitle = {Proceedings {{Interspeech}} 2015},
  urldate = {2017-10-02},
  date = {2015},
  pages = {1428--1432},
  author = {Shazeer, Noam and Pelemans, Joris and Chelba, Ciprian}
}

@article{tan_scalable_2012,
  title = {A Scalable Distributed Syntactic, Semantic, and Lexical Language Model},
  volume = {38},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/COLI_a_00107},
  number = {3},
  journaltitle = {Computational Linguistics},
  urldate = {2017-10-02},
  date = {2012},
  pages = {631--671},
  author = {Tan, Ming and Zhou, Wenli and Zheng, Lei and Wang, Shaojun}
}

@inproceedings{socher_recursive_2013,
  title = {Recursive Deep Models for Semantic Compositionality over a Sentiment Treebank},
  url = {http://www.aclweb.org/anthology/D13-1170},
  booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
  urldate = {2017-10-02},
  date = {2013},
  pages = {1631--1642},
  author = {Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher}
}

@article{kalchbrenner_convolutional_2014,
  title = {A Convolutional Neural Network for Modelling Sentences},
  url = {https://arxiv.org/abs/1404.2188},
  journaltitle = {arXiv preprint arXiv:1404.2188},
  urldate = {2017-10-02},
  date = {2014},
  author = {Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil}
}

@article{cho_properties_2014,
  title = {On the Properties of Neural Machine Translation: {{Encoder}}-Decoder Approaches},
  url = {https://arxiv.org/abs/1409.1259},
  shorttitle = {On the Properties of Neural Machine Translation},
  journaltitle = {arXiv preprint arXiv:1409.1259},
  urldate = {2017-10-02},
  date = {2014},
  keywords = {gru},
  author = {Cho, Kyunghyun and Van Merriënboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3VZCUVFA/389906563156504e16afe7d440adbaf4da86.pdf}
}

@inproceedings{zhao_self-adaptive_2015-1,
  title = {Self-{{Adaptive Hierarchical Sentence Model}}.},
  url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/download/10828/11307},
  booktitle = {{{IJCAI}}},
  urldate = {2017-10-02},
  date = {2015},
  pages = {4069--4076},
  author = {Zhao, Han and Lu, Zhengdong and Poupart, Pascal}
}

@article{grefenstette_multi-step_2013,
  title = {Multi-Step Regression Learning for Compositional Distributional Semantics},
  url = {https://arxiv.org/abs/1301.6939},
  journaltitle = {arXiv preprint arXiv:1301.6939},
  urldate = {2017-10-02},
  date = {2013},
  author = {Grefenstette, Edward and Dinu, Georgiana and Zhang, Yao-Zhong and Sadrzadeh, Mehrnoosh and Baroni, Marco}
}

@inproceedings{medic_does_2017,
  title = {Does {{Free Word Order Hurt}}? {{Assessing}} the {{Practical Lexical Function Model}} for {{Croatian}}},
  url = {http://www.aclweb.org/anthology/S17-1014},
  booktitle = {*{{SEM}}},
  date = {2017},
  author = {Medic, Zoran and Snajder, Jan and Padó, Sebastian}
}

@online{_d10-1115.pdf_????,
  title = {D10-1115.Pdf},
  url = {http://www.aclweb.org/anthology/D10-1115},
  urldate = {2017-10-02},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/9HIWVNI3/D10-1115.pdf}
}

@inproceedings{baroni_nouns_2010,
  title = {Nouns Are Vectors, Adjectives Are Matrices: {{Representing}} Adjective-Noun Constructions in Semantic Space},
  url = {http://dl.acm.org/citation.cfm?id=1870773},
  shorttitle = {Nouns Are Vectors, Adjectives Are Matrices},
  booktitle = {Proceedings of the 2010 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-02},
  date = {2010},
  pages = {1183--1193},
  author = {Baroni, Marco and Zamparelli, Roberto}
}

@inproceedings{guevara_regression_2010,
  title = {A Regression Model of Adjective-Noun Compositionality in Distributional Semantics},
  url = {http://dl.acm.org/citation.cfm?id=1870521},
  booktitle = {Proceedings of the 2010 {{Workshop}} on {{GEometrical Models}} of {{Natural Language Semantics}}},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-02},
  date = {2010},
  pages = {33--37},
  author = {Guevara, Emiliano}
}

@article{mitchell_composition_2010,
  title = {Composition in Distributional Models of Semantics},
  volume = {34},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1551-6709.2010.01106.x/full},
  number = {8},
  journaltitle = {Cognitive science},
  urldate = {2017-10-02},
  date = {2010},
  pages = {1388--1429},
  author = {Mitchell, Jeff and Lapata, Mirella}
}

@inproceedings{le_distributed_2014,
  title = {Distributed Representations of Sentences and Documents},
  url = {http://www.jmlr.org/proceedings/papers/v32/le14.pdf},
  booktitle = {Proceedings of the 31st {{International Conference}} on {{Machine Learning}} ({{ICML}}-14)},
  urldate = {2017-10-02},
  date = {2014},
  pages = {1188--1196},
  author = {Le, Quoc and Mikolov, Tomas}
}

@inproceedings{vincent_extracting_2008,
  title = {Extracting and Composing Robust Features with Denoising Autoencoders},
  url = {http://dl.acm.org/citation.cfm?id=1390294},
  booktitle = {Proceedings of the 25th International Conference on {{Machine}} Learning},
  publisher = {{ACM}},
  urldate = {2017-10-02},
  date = {2008},
  pages = {1096--1103},
  author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine}
}

@article{wager_dropout_2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1307.1493},
  primaryClass = {cs, stat},
  title = {Dropout {{Training}} as {{Adaptive Regularization}}},
  url = {http://arxiv.org/abs/1307.1493},
  abstract = {Dropout and other feature noising schemes control overfitting by artificially corrupting the training data. For generalized linear models, dropout performs a form of adaptive regularization. Using this viewpoint, we show that the dropout regularizer is first-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix. We also establish a connection to AdaGrad, an online learning algorithm, and find that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems. By casting dropout as regularization, we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer. We apply this idea to document classification tasks, and show that it consistently boosts the performance of dropout training, improving on state-of-the-art results on the IMDB reviews dataset.},
  urldate = {2017-10-02},
  date = {2013-07-04},
  keywords = {Computer Science - Learning,Statistics - Machine Learning,Statistics - Methodology},
  author = {Wager, Stefan and Wang, Sida and Liang, Percy}
}

@article{socher_grounded_2014,
  title = {Grounded Compositional Semantics for Finding and Describing Images with Sentences},
  volume = {2},
  url = {https://www.transacl.org/ojs/index.php/tacl/article/view/325},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  urldate = {2017-10-02},
  date = {2014},
  pages = {207--218},
  author = {Socher, Richard and Karpathy, Andrej and Le, Quoc V. and Manning, Christopher D. and Ng, Andrew Y.}
}

@inproceedings{dai_semi-supervised_2015,
  title = {Semi-Supervised Sequence Learning},
  url = {http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  urldate = {2017-10-02},
  date = {2015},
  pages = {3079--3087},
  author = {Dai, Andrew M. and Le, Quoc V.}
}

@inproceedings{baroni_dont_2014,
  title = {Don't Count, Predict! {{A}} Systematic Comparison of Context-Counting vs. Context-Predicting Semantic Vectors.},
  url = {http://anthology.aclweb.org/P/P14/P14-1023.pdf},
  booktitle = {{{ACL}} (1)},
  urldate = {2017-10-02},
  date = {2014},
  pages = {238--247},
  author = {Baroni, Marco and Dinu, Georgiana and Kruszewski, Germán}
}

@inproceedings{ai_analysis_2016,
  langid = {english},
  title = {Analysis of the {{Paragraph Vector Model}} for {{Information Retrieval}}},
  isbn = {978-1-4503-4497-5},
  url = {http://dl.acm.org/citation.cfm?doid=2970398.2970409},
  doi = {10.1145/2970398.2970409},
  publisher = {{ACM Press}},
  urldate = {2017-10-02},
  date = {2016},
  pages = {133-142},
  author = {Ai, Qingyao and Yang, Liu and Guo, Jiafeng and Croft, W. Bruce}
}

@article{cohan_scientific_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.03449},
  title = {Scientific Document Summarization via Citation Contextualization and Scientific Discourse},
  issn = {1432-5012, 1432-1300},
  url = {http://arxiv.org/abs/1706.03449},
  doi = {10.1007/s00799-017-0216-8},
  abstract = {The rapid growth of scientific literature has made it difficult for the researchers to quickly learn about the developments in their respective fields. Scientific document summarization addresses this challenge by providing summaries of the important contributions of scientific papers. We present a framework for scientific summarization which takes advantage of the citations and the scientific discourse structure. Citation texts often lack the evidence and context to support the content of the cited paper and are even sometimes inaccurate. We first address the problem of inaccuracy of the citation texts by finding the relevant context from the cited paper. We propose three approaches for contextualizing citations which are based on query reformulation, word embeddings, and supervised learning. We then train a model to identify the discourse facets for each citation. We finally propose a method for summarizing scientific papers by leveraging the faceted citations and their corresponding contexts. We evaluate our proposed method on two scientific summarization datasets in the biomedical and computational linguistics domains. Extensive evaluation results show that our methods can improve over the state of the art by large margins.},
  journaltitle = {International Journal on Digital Libraries},
  urldate = {2017-10-02},
  date = {2017-05-09},
  keywords = {Computer Science - Computation and Language,Computer Science - Digital Libraries},
  author = {Cohan, Arman and Goharian, Nazli},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/22CVGRL4/Cohan und Goharian - 2017 - Scientific document summarization via citation con.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZH8W68ZB/1706.html}
}

@article{liu_automatic_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.10152},
  primaryClass = {cs},
  title = {Automatic {{Argumentative}}-{{Zoning Using Word2vec}}},
  url = {http://arxiv.org/abs/1703.10152},
  abstract = {In comparison with document summarization on the articles from social media and newswire, argumentative zoning (AZ) is an important task in scientific paper analysis. Traditional methodology to carry on this task relies on feature engineering from different levels. In this paper, three models of generating sentence vectors for the task of sentence classification were explored and compared. The proposed approach builds sentence representations using learned embeddings based on neural network. The learned word embeddings formed a feature space, to which the examined sentence is mapped to. Those features are input into the classifiers for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on the Argumentative-Zoning (AZ) annotated articles. The results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance. In comparison with the hand-crafted features, the word2vec method won for most of the categories. However, the hand-crafted features showed their strength on classifying some of the categories.},
  urldate = {2017-10-02},
  date = {2017-03-29},
  keywords = {Computer Science - Computation and Language},
  author = {Liu, Haixia}
}

@inproceedings{zanzotto_estimating_2010,
  title = {Estimating Linear Models for Compositional Distributional Semantics},
  url = {http://dl.acm.org/citation.cfm?id=1873923},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-02},
  date = {2010},
  pages = {1263--1271},
  author = {Zanzotto, Fabio Massimo and Korkontzelos, Ioannis and Fallucchi, Francesca and Manandhar, Suresh}
}

@inproceedings{mikolov_distributed_2013,
  title = {Distributed Representations of Words and Phrases and Their Compositionality},
  url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality},
  booktitle = {Advances in Neural Information Processing Systems},
  urldate = {2017-10-02},
  date = {2013},
  pages = {3111--3119},
  keywords = {word2vec},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S. and Dean, Jeff},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/658UCXJ2/MikolovSutskeverChenCorradoDean2013.pdf}
}

@inproceedings{maas_learning_2011,
  title = {Learning Word Vectors for Sentiment Analysis},
  url = {http://dl.acm.org/citation.cfm?id=2002491},
  booktitle = {Proceedings of the 49th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}-{{Volume}} 1},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-02},
  date = {2011},
  pages = {142--150},
  author = {Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher}
}

@inproceedings{larochelle_neural_2012,
  title = {A Neural Autoregressive Topic Model},
  url = {http://papers.nips.cc/paper/4613-a-neural-autoregressive-topic-model},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  urldate = {2017-10-02},
  date = {2012},
  pages = {2708--2716},
  author = {Larochelle, Hugo and Lauly, Stanislas}
}

@article{srivastava_modeling_2013,
  title = {Modeling Documents with Deep Boltzmann Machines},
  url = {https://arxiv.org/abs/1309.6865},
  journaltitle = {arXiv preprint arXiv:1309.6865},
  urldate = {2017-10-02},
  date = {2013},
  author = {Srivastava, Nitish and Salakhutdinov, Ruslan R. and Hinton, Geoffrey E.}
}

@article{lau_empirical_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1607.05368},
  primaryClass = {cs},
  title = {An {{Empirical Evaluation}} of Doc2vec with {{Practical Insights}} into {{Document Embedding Generation}}},
  url = {http://arxiv.org/abs/1607.05368},
  abstract = {Recently, Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al., 2013a) to learn document-level embeddings. Despite promising results in the original paper, others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models.},
  urldate = {2017-10-02},
  date = {2016-07-18},
  keywords = {Computer Science - Computation and Language},
  author = {Lau, Jey Han and Baldwin, Timothy}
}

@article{wieting_towards_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.08198},
  primaryClass = {cs},
  title = {Towards {{Universal Paraphrastic Sentence Embeddings}}},
  url = {https://arxiv.org/pdf/1511.08198.pdf},
  abstract = {We consider the problem of learning general-purpose, paraphrastic sentence embeddings based on supervision from the Paraphrase Database (Ganitkevitch et al., 2013). We compare six compositional architectures, evaluating them on annotated textual similarity datasets drawn both from the same distribution as the training data and from a wide range of other domains. We find that the most complex architectures, such as long short-term memory (LSTM) recurrent neural networks, perform best on the in-domain data. However, in out-of-domain scenarios, simple architectures such as word averaging vastly outperform LSTMs. Our simplest averaging model is even competitive with systems tuned for the particular tasks while also being extremely efficient and easy to use. In order to better understand how these architectures compare, we conduct further experiments on three supervised NLP tasks: sentence similarity, entailment, and sentiment classification. We again find that the word averaging models perform well for sentence similarity and entailment, outperforming LSTMs. However, on sentiment classification, we find that the LSTM performs very strongly-even recording new state-of-the-art performance on the Stanford Sentiment Treebank. We then demonstrate how to combine our pretrained sentence embeddings with these supervised tasks, using them both as a prior and as a black box feature extractor. This leads to performance rivaling the state of the art on the SICK similarity and entailment tasks. We release all of our resources to the research community with the hope that they can serve as the new baseline for further work on universal sentence embeddings.},
  urldate = {2017-10-02},
  date = {2015-11-25},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language},
  author = {Wieting, John and Bansal, Mohit and Gimpel, Kevin and Livescu, Karen}
}

@inproceedings{garay_bitcoin_2015,
  title = {The {{Bitcoin Backbone Protocol}}: {{Analysis}} and {{Applications}}.},
  url = {https://eprint.iacr.org/2014/765.pdf},
  booktitle = {{{EUROCRYPT}} (2)},
  date = {2015},
  pages = {281--310},
  author = {Garay, Juan A and Kiayias, Aggelos and Leonardos, Nikos}
}

@inproceedings{mcadams_ontology_????,
  title = {An {{Ontology}} for {{Smart Contracts}}},
  url = {https://files.zotero.net/19470512428/Darryl%20McAdams%20-%20An%20Ontology%20for%20Smart%20Contracts.pdf},
  author = {McAdams, Darryl}
}

@inproceedings{turian_word_2010,
  title = {Word Representations: A Simple and General Method for Semi-Supervised Learning},
  url = {http://dl.acm.org/citation.cfm?id=1858721},
  shorttitle = {Word Representations},
  booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-04},
  date = {2010},
  pages = {384--394},
  author = {Turian, Joseph and Ratinov, Lev and Bengio, Yoshua}
}

@inproceedings{iyyer_deep_2015,
  title = {Deep Unordered Composition Rivals Syntactic Methods for Text Classification},
  volume = {1},
  url = {http://www.aclweb.org/anthology/P15-1162},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  urldate = {2017-10-04},
  date = {2015},
  pages = {1681--1691},
  author = {Iyyer, Mohit and Manjunatha, Varun and Boyd-Graber, Jordan and Daumé III, Hal}
}

@inproceedings{blacoe_comparison_2012,
  title = {A Comparison of Vector-Based Representations for Semantic Composition},
  url = {http://dl.acm.org/citation.cfm?id=2391011},
  booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-04},
  date = {2012},
  pages = {546--556},
  author = {Blacoe, William and Lapata, Mirella}
}

@article{baroni_frege_2014,
  langid = {english},
  title = {Frege in {{Space}}: {{A Program}} of {{Compositional Distributional Semantics}}},
  volume = {9},
  issn = {1945-3604},
  url = {http://csli-lilt.stanford.edu/ojs/index.php/LiLT/article/download/6/5},
  shorttitle = {Frege in {{Space}}},
  number = {0},
  journaltitle = {LiLT (Linguistic Issues in Language Technology)},
  urldate = {2017-10-04},
  date = {2014},
  keywords = {compositional semantics,distributional semantics,semantic compositionality},
  author = {Baroni, Marco and Bernardi, Raffaela and Zamparelli, Roberto}
}

@inproceedings{paperno_practical_2014,
  title = {A Practical and Linguistically-Motivated Approach to Compositional Distributional Semantics},
  volume = {1},
  url = {https://aclanthology.info/pdf/P/P14/P14-1009.pdf},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  urldate = {2017-10-04},
  date = {2014},
  pages = {90--99},
  author = {Paperno, Denis and Baroni, Marco and {others}}
}

@inproceedings{polajnar_exploration_2015,
  title = {An Exploration of Discourse-Based Sentence Spaces for Compositional Distributional Semantics},
  url = {http://www.anthology.aclweb.org/W/W15/W15-27.pdf#page=13},
  booktitle = {Workshop on {{Linking Models}} of {{Lexical}}, {{Sentential}} and {{Discourse}}-Level {{Semantics}} ({{LSDSem}})},
  urldate = {2017-10-04},
  date = {2015},
  pages = {1},
  author = {Polajnar, Tamara and Rimell, Laura and Clark, Stephen}
}

@inproceedings{socher_dynamic_2011,
  title = {Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection},
  url = {http://papers.nips.cc/paper/4204-dynamic-pooling-and-unfolding-recursive-autoencoders-for-paraphrase-detection.pdf},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  urldate = {2017-10-04},
  date = {2011},
  pages = {801--809},
  author = {Socher, Richard and Huang, Eric H. and Pennin, Jeffrey and Manning, Christopher D. and Ng, Andrew Y.}
}

@inproceedings{socher_semantic_2012,
  title = {Semantic Compositionality through Recursive Matrix-Vector Spaces},
  url = {http://dl.acm.org/citation.cfm?id=2391084},
  booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-04},
  date = {2012},
  pages = {1201--1211},
  author = {Socher, Richard and Huval, Brody and Manning, Christopher D. and Ng, Andrew Y.}
}

@inproceedings{irsoy_deep_2014,
  title = {Deep Recursive Neural Networks for Compositionality in Language},
  url = {http://papers.nips.cc/paper/5551-deep-recursive-neural-networks-for-compositionality-in-language},
  booktitle = {Advances in Neural Information Processing Systems},
  urldate = {2017-10-04},
  date = {2014},
  pages = {2096--2104},
  author = {Irsoy, Ozan and Cardie, Claire}
}

@article{zhao_self-adaptive_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1504.05070},
  primaryClass = {cs},
  title = {Self-{{Adaptive Hierarchical Sentence Model}}},
  url = {http://arxiv.org/abs/1504.05070},
  abstract = {The ability to accurately model a sentence at varying stages (e.g., word-phrase-sentence) plays a central role in natural language processing. As an effort towards this goal we propose a self-adaptive hierarchical sentence model (AdaSent). AdaSent effectively forms a hierarchy of representations from words to phrases and then to sentences through recursive gated local composition of adjacent segments. We design a competitive mechanism (through gating networks) to allow the representations of the same sentence to be engaged in a particular learning task (e.g., classification), therefore effectively mitigating the gradient vanishing problem persistent in other recursive models. Both qualitative and quantitative analysis shows that AdaSent can automatically form and select the representations suitable for the task at hand during training, yielding superior classification performance over competitor models on 5 benchmark data sets.},
  urldate = {2017-10-04},
  date = {2015-04-20},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning,Computer Science - Computation and Language},
  author = {Zhao, Han and Lu, Zhengdong and Poupart, Pascal},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/QJI3GDYW/1504.html}
}

@inproceedings{chen_sentence_2015,
  title = {Sentence {{Modeling}} with {{Gated Recursive Neural Network}}.},
  url = {https://www.aclweb.org/anthology/D/D15/D15-1092.pdf},
  booktitle = {{{EMNLP}}},
  urldate = {2017-10-04},
  date = {2015},
  pages = {793--798},
  author = {Chen, Xinchi and Qiu, Xipeng and Zhu, Chenxi and Wu, Shiyu and Huang, Xuanjing}
}

@article{kim_convolutional_2014,
  title = {Convolutional Neural Networks for Sentence Classification},
  url = {https://arxiv.org/abs/1408.5882},
  journaltitle = {arXiv preprint arXiv:1408.5882},
  urldate = {2017-10-04},
  date = {2014},
  author = {Kim, Yoon},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/RQF9X9CQ/D14-1181.pdf}
}

@inproceedings{hu_convolutional_2014,
  title = {Convolutional Neural Network Architectures for Matching Natural Language Sentences},
  url = {http://papers.nips.cc/paper/5550-convolutional-neural-network-architectures-for-matching-natural-language-sentences},
  booktitle = {Advances in Neural Information Processing Systems},
  urldate = {2017-10-04},
  date = {2014},
  pages = {2042--2050},
  author = {Hu, Baotian and Lu, Zhengdong and Li, Hang and Chen, Qingcai}
}

@inproceedings{yin_convolutional_2015,
  title = {Convolutional Neural Network for Paraphrase Identification},
  url = {https://aclanthology.info/pdf/N/N15/N15-1091.pdf},
  booktitle = {Proceedings of the 2015 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  urldate = {2017-10-04},
  date = {2015},
  pages = {901--911},
  author = {Yin, Wenpeng and Schütze, Hinrich}
}

@inproceedings{he_multi-perspective_2015,
  title = {Multi-{{Perspective Sentence Similarity Modeling}} with {{Convolutional Neural Networks}}.},
  booktitle = {{{EMNLP}}},
  date = {2015},
  pages = {1576--1586},
  author = {He, Hua and Gimpel, Kevin and Lin, Jimmy J.}
}

@article{ling_finding_2015,
  title = {Finding Function in Form: {{Compositional}} Character Models for Open Vocabulary Word Representation},
  url = {https://arxiv.org/abs/1508.02096},
  shorttitle = {Finding Function in Form},
  journaltitle = {arXiv preprint arXiv:1508.02096},
  urldate = {2017-10-04},
  date = {2015},
  author = {Ling, Wang and Luís, Tiago and Marujo, Luís and Astudillo, Ramón Fernandez and Amir, Silvio and Dyer, Chris and Black, Alan W. and Trancoso, Isabel}
}

@inproceedings{liu_multi-timescale_2015,
  title = {Multi-{{Timescale Long Short}}-{{Term Memory Neural Network}} for {{Modelling Sentences}} and {{Documents}}.},
  url = {https://www.aclweb.org/anthology/D/D15/D15-1280.pdf},
  booktitle = {{{EMNLP}}},
  urldate = {2017-10-04},
  date = {2015},
  pages = {2326--2335},
  author = {Liu, Pengfei and Qiu, Xipeng and Chen, Xinchi and Wu, Shiyu and Huang, Xuanjing}
}

@article{li_hierarchical_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.01057},
  primaryClass = {cs},
  title = {A {{Hierarchical Neural Autoencoder}} for {{Paragraphs}} and {{Documents}}},
  url = {http://arxiv.org/abs/1506.01057},
  abstract = {Natural language generation of coherent long texts like paragraphs or longer documents is a challenging problem for recurrent networks models. In this paper, we explore an important step toward this generation task: training an LSTM (Long-short term memory) auto-encoder to preserve and reconstruct multi-sentence paragraphs. We introduce an LSTM model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words, then decodes this embedding to reconstruct the original paragraph. We evaluate the reconstructed paragraph using standard metrics like ROUGE and Entity Grid, showing that neural models are able to encode texts in a way that preserve syntactic, semantic, and discourse coherence. While only a first step toward generating coherent text units from neural models, our work has the potential to significantly impact natural language generation and summarization .},
  urldate = {2017-10-04},
  date = {2015-06-02},
  keywords = {Computer Science - Computation and Language},
  author = {Li, Jiwei and Luong, Minh-Thang and Jurafsky, Dan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/ZP5U6PFN/1506.html}
}

@inproceedings{yih_learning_2011,
  title = {Learning Discriminative Projections for Text Similarity Measures},
  url = {http://anthology.aclweb.org/W/W11/W11-03.pdf#page=261},
  booktitle = {Proceedings of the {{Fifteenth Conference}} on {{Computational Natural Language Learning}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2011},
  pages = {247--256},
  author = {Yih, Wen-tau and Toutanova, Kristina and Platt, John C and Meek, Christopher}
}

@inproceedings{huang_learning_2013,
  title = {Learning Deep Structured Semantic Models for Web Search Using Clickthrough Data},
  url = {https://pdfs.semanticscholar.org/5b95/34442f91a87022427b74bca9fd95dd045383.pdf},
  booktitle = {Proceedings of the 22nd {{ACM}} International Conference on {{Conference}} on Information \& Knowledge Management},
  publisher = {{ACM}},
  urldate = {2017-10-10},
  date = {2013},
  pages = {2333--2338},
  author = {Huang, Po-Sen and He, Xiaodong and Gao, Jianfeng and Deng, Li and Acero, Alex and Heck, Larry}
}

@article{firth_synopsis_1957,
  title = {A Synopsis of Linguistic Theory, 1930-1955},
  url = {http://annabellelukin.edublogs.org/files/2013/08/Firth-JR-1962-A-Synopsis-of-Linguistic-Theory-wfihi5.pdf},
  journaltitle = {Studies in linguistic analysis},
  date = {1957},
  author = {Firth, John R}
}

@article{hermann_multilingual_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1404.4641},
  primaryClass = {cs},
  title = {Multilingual {{Models}} for {{Compositional Distributed Semantics}}},
  url = {https://arxiv.org/pdf/1404.4641.pdf},
  abstract = {We present a novel technique for learning semantic representations, which extends the distributional hypothesis to multilingual data and joint-space embeddings. Our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences, while maintaining sufficient distance between those of dissimilar sentences. The models do not rely on word alignments or any syntactic information and are successfully applied to a number of diverse languages. We extend our approach to learn semantic representations at the document level, too. We evaluate these models on two cross-lingual document classification tasks, outperforming the prior state of the art. Through qualitative analysis and the study of pivoting effects we demonstrate that our representations are semantically plausible and can capture semantic relationships across languages without parallel data.},
  urldate = {2017-10-10},
  date = {2014-04-17},
  keywords = {Computer Science - Computation and Language},
  author = {Hermann, Karl Moritz and Blunsom, Phil}
}

@inproceedings{faruqui_improving_2014,
  title = {Improving Vector Space Word Representations Using Multilingual Correlation},
  url = {http://anthology.aclweb.org/E/E14/E14-1049.pdf},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2017-10-10},
  date = {2014},
  author = {Faruqui, Manaal and Dyer, Chris}
}

@article{bordes_open_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1404.4326},
  primaryClass = {cs},
  title = {Open {{Question Answering}} with {{Weakly Supervised Embedding Models}}},
  url = {http://arxiv.org/abs/1404.4326},
  abstract = {Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data.},
  urldate = {2017-10-10},
  date = {2014-04-16},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language},
  author = {Bordes, Antoine and Weston, Jason and Usunier, Nicolas}
}

@inproceedings{lu_deep_2015,
  title = {Deep {{Multilingual Correlation}} for {{Improved Word Embeddings}}.},
  url = {http://ttic.uchicago.edu/~kgimpel/papers/lu+etal.naacl15.pdf},
  booktitle = {{{HLT}}-{{NAACL}}},
  urldate = {2017-10-10},
  date = {2015},
  pages = {250--256},
  author = {Lu, Ang and Wang, Weiran and Bansal, Mohit and Gimpel, Kevin and Livescu, Karen}
}

@article{conneau_supervised_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.02364},
  primaryClass = {cs},
  title = {Supervised {{Learning}} of {{Universal Sentence Representations}} from {{Natural Language Inference Data}}},
  url = {http://arxiv.org/abs/1705.02364},
  abstract = {Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.},
  urldate = {2017-11-19},
  date = {2017-05-05},
  keywords = {Computer Science - Computation and Language},
  author = {Conneau, Alexis and Kiela, Douwe and Schwenk, Holger and Barrault, Loic and Bordes, Antoine},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/SJCKX29C/1705.html}
}

@article{arora_simple_2016,
  title = {A Simple but Tough-to-Beat Baseline for Sentence Embeddings},
  url = {https://openreview.net/pdf?id=SyK00v5xx},
  date = {2016},
  author = {Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu}
}

@inproceedings{bergstra_algorithms_2011,
  title = {Algorithms for Hyper-Parameter Optimization},
  url = {https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date = {2011},
  pages = {2546--2554},
  author = {Bergstra, James S. and Bardenet, Rémi and Bengio, Yoshua and Kégl, Balázs}
}

@article{kingma_adam_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.6980},
  primaryClass = {cs},
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  url = {http://arxiv.org/abs/1412.6980},
  shorttitle = {Adam},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  urldate = {2017-11-21},
  date = {2014-12-22},
  keywords = {Computer Science - Learning},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/SJTUA7JI/1412.6980v8.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/6LF78RDE/1412.html}
}

@article{abadi_tensorflow_2016-1,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.08695},
  primaryClass = {cs},
  title = {{{TensorFlow}}: {{A}} System for Large-Scale Machine Learning},
  url = {http://arxiv.org/abs/1605.08695},
  shorttitle = {{{TensorFlow}}},
  abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
  urldate = {2017-11-21},
  date = {2016-05-27},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed; Parallel; and Cluster Computing},
  author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/23CQEQM7/1605.html}
}

@inproceedings{choi_it_2015,
  title = {It {{Depends}}: {{Dependency Parser Comparison Using A Web}}-Based {{Evaluation Tool}}.},
  url = {http://www.aclweb.org/anthology/P15-1038},
  shorttitle = {It {{Depends}}},
  booktitle = {{{ACL}} (1)},
  date = {2015},
  pages = {387--396},
  author = {Choi, Jinho D. and Tetreault, Joel R. and Stent, Amanda}
}

@article{robins_catastrophic_1995,
  title = {Catastrophic Forgetting, Rehearsal and Pseudorehearsal},
  volume = {7},
  number = {2},
  journaltitle = {Connection Science},
  date = {1995},
  pages = {123--146},
  author = {Robins, Anthony}
}

@inproceedings{pavlick_ppdb_2015,
  location = {{Beijing, China}},
  title = {{{PPDB}} 2.0: {{Better}} Paraphrase Ranking, Fine-Grained Entailment Relations, Word Embeddings, and Style Classification},
  url = {http://www.aclweb.org/anthology/P15-2070},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 2: {{Short Papers}})},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-07},
  pages = {425--430},
  author = {Pavlick, Ellie and Rastogi, Pushpendre and Ganitkevitch, Juri and Van Durme, Benjamin and Callison-Burch, Chris}
}

@article{bowman_large_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1508.05326},
  primaryClass = {cs},
  title = {A Large Annotated Corpus for Learning Natural Language Inference},
  url = {http://arxiv.org/abs/1508.05326},
  abstract = {Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.},
  urldate = {2017-11-23},
  date = {2015-08-21},
  keywords = {Computer Science - Computation and Language},
  author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher and Manning, Christopher D.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/35YAFGFS/1508.html}
}

@article{hodosh_framing_2013,
  title = {Framing Image Description as a Ranking Task: {{Data}}, Models and Evaluation Metrics},
  volume = {47},
  shorttitle = {Framing Image Description as a Ranking Task},
  journaltitle = {Journal of Artificial Intelligence Research},
  date = {2013},
  pages = {853--899},
  author = {Hodosh, Micah and Young, Peter and Hockenmaier, Julia}
}

@inproceedings{agirre_semeval-2012_2012,
  title = {Semeval-2012 Task 6: {{A}} Pilot on Semantic Textual Similarity},
  shorttitle = {Semeval-2012 Task 6},
  booktitle = {Proceedings of the {{First Joint Conference}} on {{Lexical}} and {{Computational Semantics}}-{{Volume}} 1: {{Proceedings}} of the Main Conference and the Shared Task, and {{Volume}} 2: {{Proceedings}} of the {{Sixth International Workshop}} on {{Semantic Evaluation}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2012},
  pages = {385--393},
  author = {Agirre, Eneko and Diab, Mona and Cer, Daniel and Gonzalez-Agirre, Aitor},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/QFUHVE7W/e8d2da34e543d07e1df1e18e42e70a926c08.pdf}
}

@article{resnik_semantic_1999,
  title = {Semantic Similarity in a Taxonomy: {{An}} Information-Based Measure and Its Application to Problems of Ambiguity in Natural Language},
  volume = {11},
  url = {https://www.jair.org/media/514/live-514-1722-jair.pdf},
  shorttitle = {Semantic Similarity in a Taxonomy},
  journaltitle = {J. Artif. Intell. Res.(JAIR)},
  date = {1999},
  pages = {95--130},
  author = {Resnik, Philip}
}

@inproceedings{gracia_web-based_2008,
  title = {Web-{{Based Measure}} of {{Semantic Relatedness}}.},
  url = {http://oa.upm.es/6549/1/Web-based_Measure.pdf},
  booktitle = {{{WISE}}},
  publisher = {{Springer}},
  date = {2008},
  pages = {136--150},
  author = {Gracia, Jorge and Mena, Eduardo}
}

@inproceedings{pham_sentence_2013,
  title = {Sentence Paraphrase Detection: {{When}} Determiners and Word Order Make the Difference},
  url = {http://clic.cimec.unitn.it/marco/publications/pham-etal-tfds2013.pdf},
  shorttitle = {Sentence Paraphrase Detection},
  booktitle = {Proceedings of the {{Towards}} a {{Formal Distributional Semantics Workshop}} at {{IWCS}} 2013},
  date = {2013},
  pages = {21--29},
  author = {Pham, Nghia and Bernardi, Raffaella and Zhang, Yao Zhong and Baroni, Marco}
}

@incollection{britain_notes_1895,
  title = {Notes on {{Regression}} and {{Inheritance}} in the {{Case}} of {{Two Parents}}},
  number = {Bd. 58},
  booktitle = {Proceedings of the {{Royal Society}} of {{London}}},
  publisher = {{Taylor \& Francis}},
  date = {1895},
  pages = {240-242},
  author = {Britain), Royal Society (Great}
}

@article{pearson_note_1895,
  title = {Note on {{Regression}} and {{Inheritance}} in the {{Case}} of {{Two Parents}}},
  volume = {58},
  issn = {0370-1662},
  url = {http://rspl.royalsocietypublishing.org/cgi/doi/10.1098/rspl.1895.0041},
  doi = {10.1098/rspl.1895.0041},
  issue = {-1},
  journaltitle = {Proceedings of the Royal Society of London (1854-1905)},
  urldate = {2017-11-27},
  date = {1895-01-01},
  pages = {240-242},
  author = {Pearson, Karl}
}

@article{spearman_proof_1904,
  eprinttype = {jstor},
  eprint = {1412159},
  title = {The {{Proof}} and {{Measurement}} of {{Association}} between {{Two Things}}},
  volume = {15},
  issn = {00029556},
  doi = {10.2307/1412159},
  number = {1},
  journaltitle = {The American Journal of Psychology},
  date = {1904},
  pages = {72-101},
  author = {Spearman, C.}
}

@online{_survey_????-1,
  title = {A Survey on Tag Recommendation Methods - {{Belém}} - 2016 - {{Journal}} of the {{Association}} for {{Information Science}} and {{Technology}} - {{Wiley Online Library}}},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/asi.23736/abstract?systemMessage=Wiley+Online+Library+usage+report+download+page+will+be+unavailable+on+Friday+24th+November+2017+at+21%3A00+EST+%2F+02.00+GMT+%2F+10%3A00+SGT+%28Saturday+25th+Nov+for+SGT+},
  urldate = {2017-11-27}
}

@article{hopfield_neural_1982,
  langid = {english},
  title = {Neural Networks and Physical Systems with Emergent Collective Computational Abilities.},
  volume = {79},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.79.8.2554},
  doi = {10.1073/pnas.79.8.2554},
  number = {8},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2017-11-27},
  date = {1982-04-01},
  pages = {2554-2558},
  author = {Hopfield, J. J.}
}

@article{zhang_feedforward_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.08301},
  primaryClass = {cs},
  title = {Feedforward {{Sequential Memory Networks}}: {{A New Structure}} to {{Learn Long}}-Term {{Dependency}}},
  url = {http://arxiv.org/abs/1512.08301},
  shorttitle = {Feedforward {{Sequential Memory Networks}}},
  abstract = {In this paper, we propose a novel neural network structure, namely $\backslash$emph\{feedforward sequential memory networks (FSMN)\}, to model long-term dependency in time series without using recurrent feedback. The proposed FSMN is a standard fully-connected feedforward neural network equipped with some learnable memory blocks in its hidden layers. The memory blocks use a tapped-delay line structure to encode the long context information into a fixed-size representation as short-term memory mechanism. We have evaluated the proposed FSMNs in several standard benchmark tasks, including speech recognition and language modelling. Experimental results have shown FSMNs significantly outperform the conventional recurrent neural networks (RNN), including LSTMs, in modeling sequential signals like speech or language. Moreover, FSMNs can be learned much more reliably and faster than RNNs or LSTMs due to the inherent non-recurrent model structure.},
  urldate = {2017-11-27},
  date = {2015-12-27},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  author = {Zhang, Shiliang and Liu, Cong and Jiang, Hui and Wei, Si and Dai, Lirong and Hu, Yu},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/3ZTH2SDZ/Zhang et al. - 2015 - Feedforward Sequential Memory Networks A New Stru.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/4CGQCQYR/1512.html}
}

@article{rosenblatt_perceptron_1958,
  langid = {english},
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  volume = {65},
  issn = {1939-1471, 0033-295X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
  doi = {10.1037/h0042519},
  shorttitle = {The Perceptron},
  number = {6},
  journaltitle = {Psychological Review},
  urldate = {2017-11-27},
  date = {1958},
  pages = {386-408},
  author = {Rosenblatt, F.}
}

@incollection{hosseini_persian_2013,
  title = {Persian Vowel Recognition Using the Combination of Haar Wavelet and Neural Network},
  booktitle = {Innovations in {{Intelligent Machines}}-3},
  publisher = {{Springer}},
  date = {2013},
  pages = {53--68},
  author = {Hosseini, Mohammad Mehdi and Gharahbagh, Abdorreza Alavi},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/MZW7RDA3/0471349119.pdf}
}

@collection{sandberg_nonlinear_2001,
  location = {{New York}},
  title = {Nonlinear Dynamical Systems: Feedforward Neural Network Perspectives},
  isbn = {978-0-471-34911-2},
  shorttitle = {Nonlinear Dynamical Systems},
  pagetotal = {298},
  series = {Adaptive and learning systems for signal processing, communications, and control},
  publisher = {{Wiley}},
  date = {2001},
  keywords = {Dynamics,Neural networks (Computer science)},
  editor = {Sandberg, I. W.}
}

@incollection{sandberg_feedforward_2001,
  langid = {english},
  location = {{New York, NY}},
  title = {Feedforward {{Neural Networks}}: {{An Introduction}}},
  isbn = {978-0-471-34911-2},
  url = {http://media.wiley.com/product_data/excerpt/19/04713491/0471349119.pdf},
  booktitle = {Nonlinear Dynamical Systems: Feedforward Neural Network Perspectives},
  publisher = {{Wiley}},
  date = {2001},
  author = {Haykin, Simon},
  editor = {Sandberg, Irwin W.},
  note = {OCLC: 247412991}
}

@article{hornik_multilayer_1989,
  langid = {english},
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  volume = {2},
  issn = {08936080},
  url = {http://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
  doi = {10.1016/0893-6080(89)90020-8},
  number = {5},
  journaltitle = {Neural Networks},
  urldate = {2017-11-27},
  date = {1989-01},
  pages = {359-366},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert}
}

@book{rumelhart_parallel_1986,
  location = {{Cambridge, Mass}},
  title = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition},
  isbn = {978-0-262-18120-4},
  shorttitle = {Parallel Distributed Processing},
  pagetotal = {2},
  series = {Computational models of cognition and perception},
  publisher = {{MIT Press}},
  date = {1986},
  keywords = {Cognition,Human information processing},
  author = {Rumelhart, David E. and McClelland, James L.},
  editora = {University of California, San Diego},
  editoratype = {collaborator}
}

@book{mohri_foundations_2012,
  langid = {english},
  location = {{Cambridge, Mass. London}},
  title = {Foundations of Machine Learning},
  isbn = {978-0-262-01825-8},
  pagetotal = {412},
  series = {Adaptive computation and machine learning},
  publisher = {{The MIT Press}},
  date = {2012},
  author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  note = {OCLC: 812407408}
}

@article{nickel_holographic_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1510.04935},
  primaryClass = {cs, stat},
  title = {Holographic {{Embeddings}} of {{Knowledge Graphs}}},
  url = {http://arxiv.org/abs/1510.04935},
  abstract = {Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. In extensive experiments we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction in knowledge graphs and relational learning benchmark datasets.},
  urldate = {2017-11-29},
  date = {2015-10-16},
  keywords = {Computer Science - Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence,I.2.4,I.2.6},
  author = {Nickel, Maximilian and Rosasco, Lorenzo and Poggio, Tomaso},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/45TEPW4J/1510.html}
}

@article{church_word_1990,
  title = {Word Association Norms, Mutual Information, and Lexicography},
  volume = {16},
  number = {1},
  journaltitle = {Computational linguistics},
  date = {1990},
  pages = {22--29},
  keywords = {PMI},
  author = {Church, Kenneth Ward and Hanks, Patrick}
}

@article{turney_frequency_2010,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1003.1141},
  primaryClass = {cs},
  title = {From {{Frequency}} to {{Meaning}}: {{Vector Space Models}} of {{Semantics}}},
  url = {http://arxiv.org/abs/1003.1141},
  doi = {10.1613/jair.2934},
  shorttitle = {From {{Frequency}} to {{Meaning}}},
  abstract = {Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.},
  urldate = {2017-12-02},
  date = {2010-03-04},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language,Computer Science - Information Retrieval,PPMI,SVM},
  author = {Turney, Peter D. and Pantel, Patrick},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/XY4WW45S/1003.html}
}

@inproceedings{niwa_co-occurrence_1994,
  title = {Co-Occurrence Vectors from Corpora vs. Distance Vectors from Dictionaries},
  booktitle = {Proceedings of the 15th Conference on {{Computational}} Linguistics-{{Volume}} 1},
  publisher = {{Association for Computational Linguistics}},
  date = {1994},
  pages = {304--309},
  keywords = {PMI,PPMI,SVM},
  author = {Niwa, Yoshiki and Nitta, Yoshihiko}
}

@article{saatchi_bayesian_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.09558},
  primaryClass = {cs, stat},
  title = {Bayesian {{GAN}}},
  url = {http://arxiv.org/abs/1705.09558},
  abstract = {Generative adversarial networks (GANs) can implicitly learn rich distributions over images, audio, and data which are hard to model with an explicit likelihood. We present a practical Bayesian formulation for unsupervised and semi-supervised learning with GANs. Within this framework, we use stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of the generator and discriminator networks. The resulting approach is straightforward and obtains good performance without any standard interventions such as feature matching, or mini-batch discrimination. By exploring an expressive posterior over the parameters of the generator, the Bayesian GAN avoids mode-collapse, produces interpretable and diverse candidate samples, and provides state-of-the-art quantitative results for semi-supervised learning on benchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN, Wasserstein GANs, and DCGAN ensembles.},
  urldate = {2017-12-03},
  date = {2017-05-26},
  keywords = {Computer Science - Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  author = {Saatchi, Yunus and Wilson, Andrew Gordon},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/N28K4UVS/1705.html}
}

@article{karaletsos_adversarial_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.05048},
  primaryClass = {cs, stat},
  title = {Adversarial {{Message Passing For Graphical Models}}},
  url = {http://arxiv.org/abs/1612.05048},
  abstract = {Bayesian inference on structured models typically relies on the ability to infer posterior distributions of underlying hidden variables. However, inference in implicit models or complex posterior distributions is hard. A popular tool for learning implicit models are generative adversarial networks (GANs) which learn parameters of generators by fooling discriminators. Typically, GANs are considered to be models themselves and are not understood in the context of inference. Current techniques rely on inefficient global discrimination of joint distributions to perform learning, or only consider discriminating a single output variable. We overcome these limitations by treating GANs as a basis for likelihood-free inference in generative models and generalize them to Bayesian posterior inference over factor graphs. We propose local learning rules based on message passing minimizing a global divergence criterion involving cooperating local adversaries used to sidestep explicit likelihood evaluations. This allows us to compose models and yields a unified inference and learning framework for adversarial learning. Our framework treats model specification and inference separately and facilitates richly structured models within the family of Directed Acyclic Graphs, including components such as intractable likelihoods, non-differentiable models, simulators and generally cumbersome models. A key result of our treatment is the insight that Bayesian inference on structured models can be performed only with sampling and discrimination when using nonparametric variational families, without access to explicit distributions. As a side-result, we discuss the link to likelihood maximization. These approaches hold promise to be useful in the toolbox of probabilistic modelers and enrich the gamut of current probabilistic programming applications.},
  urldate = {2017-12-03},
  date = {2016-12-15},
  keywords = {Statistics - Machine Learning,Computer Science - Artificial Intelligence},
  author = {Karaletsos, Theofanis},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/F2MIBGJZ/1612.html}
}

@article{sunitha_survey_????,
  title = {A {{Survey}} of {{Extractive Summarization Techniques}}},
  author = {Sunitha, C. and Archana, A. B. and Deepak, K. N.}
}

@inproceedings{wang_error_2016,
  title = {Error {{Link Detection}} and {{Correction}} in {{Wikipedia}}},
  booktitle = {{{CIKM}}},
  date = {2016},
  keywords = {wikipedia},
  author = {Wang, Chengyu and Zhang, Rong and He, Xiaofeng and Zhou, Aoying}
}

@article{melo_detection_2017,
  title = {Detection of {{Relation Assertion Errors}} in {{Knowledge Graphs}}},
  date = {2017},
  author = {Melo, André and Paulheim, Heiko}
}

@article{heist_language-agnostic_????,
  title = {Language-Agnostic {{Relation Extraction}} from {{Wikipedia Abstracts}} for {{Knowledge Graph Extension}}},
  keywords = {wikipedia},
  author = {Heist, Nicolas and Paulheim, Heiko}
}

@article{parikh_decomposable_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1606.01933},
  primaryClass = {cs},
  title = {A {{Decomposable Attention Model}} for {{Natural Language Inference}}},
  url = {http://arxiv.org/abs/1606.01933},
  abstract = {We propose a simple neural architecture for natural language inference. Our approach uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable. On the Stanford Natural Language Inference (SNLI) dataset, we obtain state-of-the-art results with almost an order of magnitude fewer parameters than previous work and without relying on any word-order information. Adding intra-sentence attention that takes a minimum amount of order into account yields further improvements.},
  urldate = {2017-12-10},
  date = {2016-06-06},
  keywords = {Computer Science - Computation and Language},
  author = {Parikh, Ankur P. and Täckström, Oscar and Das, Dipanjan and Uszkoreit, Jakob}
}

@article{chen_enhanced_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.06038},
  primaryClass = {cs},
  title = {Enhanced {{LSTM}} for {{Natural Language Inference}}},
  url = {http://arxiv.org/abs/1609.06038},
  abstract = {Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is very challenging. With the availability of large annotated data (Bowman et al., 2015), it has recently become feasible to train neural network based inference models, which have shown to be very effective. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.6\% on the Stanford Natural Language Inference Dataset. Unlike the previous top models that use very complicated network architectures, we first demonstrate that carefully designing sequential inference models based on chain LSTMs can outperform all previous models. Based on this, we further show that by explicitly considering recursive architectures in both local inference modeling and inference composition, we achieve additional improvement. Particularly, incorporating syntactic parsing information contributes to our best result---it further improves the performance even when added to the already very strong model.},
  urldate = {2017-12-10},
  date = {2016-09-20},
  keywords = {Computer Science - Computation and Language},
  author = {Chen, Qian and Zhu, Xiaodan and Ling, Zhenhua and Wei, Si and Jiang, Hui and Inkpen, Diana},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/4GS3IQWB/1609.html}
}

@book{tesniere_elements_1976,
  location = {{Paris}},
  title = {Éléments de Syntaxe Structurale},
  edition = {2e éd. revue et corrigée},
  isbn = {978-2-252-01861-3},
  pagetotal = {674},
  publisher = {{Klincksieck}},
  date = {1976},
  keywords = {Syntax,Grammar; Comparative and general,Structural linguistics},
  author = {Tesnière, Lucien}
}

@incollection{jurafsky_dependency_2014,
  title = {Dependency {{Parsing}}},
  booktitle = {Speech and Language Processing},
  publisher = {{Pearson London}},
  date = {2014},
  author = {Jurafsky, Dan and Martin, James H.}
}

@inproceedings{nivre_universal_2016,
  title = {Universal {{Dependencies}} v1: {{A Multilingual Treebank Collection}}.},
  shorttitle = {Universal {{Dependencies}} V1},
  booktitle = {{{LREC}}},
  date = {2016},
  author = {Nivre, Joakim and de Marneffe, Marie-Catherine and Ginter, Filip and Goldberg, Yoav and Hajic, Jan and Manning, Christopher D. and McDonald, Ryan T. and Petrov, Slav and Pyysalo, Sampo and Silveira, Natalia},
  options = {useprefix=true}
}

@incollection{janssen_montague_2017,
  title = {Montague {{Semantics}}},
  edition = {Spring 2017},
  url = {https://plato.stanford.edu/archives/spr2017/entries/montague-semantics/},
  abstract = {Montague semantics is a theory of natural language semantics and ofits relation with syntax. It was originally developed by the logicianRichard Montague (1930–1971) and subsequently modified andextended by linguists, philosophers, and logicians. The most importantfeatures of the theory are its use of model theoretic semantics whichis nowadays commonly used for the semantics of logical languages andits adherence to the principle of compositionality—that is, themeaning of the whole is a function of the meanings of its parts andtheir mode of syntactic combination. This entry presents the originsof Montague Semantics, summarizes important aspects of the classicaltheory, and sketches more recent developments. We conclude with asmall example, which illustrates some modern features.},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  urldate = {2018-01-19},
  date = {2017},
  keywords = {compositionality,discourse representation theory,Frege; Gottlob,generalized quantifiers,identity: transworld,impossible worlds,intensional transitive verbs,intentionality,logic: intensional,logical form,mass expressions: logic of,possible worlds,presupposition,propositional attitude reports,propositions: structured,questions,reference,rigid designators,semantics: dynamic,type theory},
  author = {Janssen, Theo M. V.},
  editor = {Zalta, Edward N.}
}

@incollection{montague_proper_1973,
  title = {The Proper Treatment of Quantification in Ordinary {{English}}},
  booktitle = {Philosophy, Language, and Artificial Intelligence},
  publisher = {{Springer}},
  date = {1973},
  pages = {141-162},
  author = {Montague, Richard}
}

@inproceedings{zhao_ecnu_2014,
  title = {{{ECNU}}: {{One Stone Two Birds}}: {{Ensemble}} of {{Heterogenous Measures}} for {{Semantic Relatedness}} and {{Textual Entailment}}.},
  shorttitle = {{{ECNU}}},
  booktitle = {{{SemEval}}@ {{COLING}}},
  date = {2014},
  pages = {271--277},
  author = {Zhao, Jiang and Zhu, Tiantian and Lan, Man}
}

@article{cortes_support-vector_1995,
  title = {Support-Vector Networks},
  volume = {20},
  number = {3},
  journaltitle = {Machine learning},
  date = {1995},
  pages = {273--297},
  author = {Cortes, Corinna and Vapnik, Vladimir}
}

@article{opitz_popular_1999,
  title = {Popular Ensemble Methods: {{An}} Empirical Study},
  volume = {11},
  shorttitle = {Popular Ensemble Methods},
  journaltitle = {J. Artif. Intell. Res.(JAIR)},
  date = {1999},
  pages = {169--198},
  author = {Opitz, David W. and Maclin, Richard}
}

@article{breiman_random_2001,
  title = {Random {{Forests}}},
  volume = {45},
  url = {https://doi.org/10.1023/A:1010933404324},
  doi = {10.1023/A:1010933404324},
  number = {1},
  journaltitle = {Machine Learning},
  date = {2001},
  pages = {5-32},
  author = {Breiman, Leo},
  biburl = {http://dblp.org/rec/bib/journals/ml/Breiman01},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{bjerva_meaning_2014,
  title = {The {{Meaning Factory}}: {{Formal Semantics}} for {{Recognizing Textual Entailment}} and {{Determining Semantic Similarity}}.},
  url = {http://www.aclweb.org/anthology/S14-2114},
  shorttitle = {The {{Meaning Factory}}},
  booktitle = {{{SemEval}}@ {{COLING}}},
  date = {2014},
  pages = {642--646},
  author = {Bjerva, Johannes and Bos, Johan and Van der Goot, Rob and Nissim, Malvina}
}

@inproceedings{lai_illinois-lh_2014,
  title = {Illinois-{{LH}}: {{A Denotational}} and {{Distributional Approach}} to {{Semantics}}.},
  shorttitle = {Illinois-{{LH}}},
  booktitle = {{{SemEval}}@ {{COLING}}},
  date = {2014},
  pages = {329--334},
  author = {Lai, Alice and Hockenmaier, Julia}
}

@article{matsugu_subject_2003,
  langid = {english},
  title = {Subject Independent Facial Expression Recognition with Robust Face Detection Using a Convolutional Neural Network},
  volume = {16},
  issn = {08936080},
  url = {http://www.iro.umontreal.ca/~pift6080/H09/documents/papers/sparse/matsugo_etal_face_expression_conv_nnet.pdf},
  doi = {10.1016/S0893-6080(03)00115-1},
  number = {5-6},
  journaltitle = {Neural Networks},
  urldate = {2018-01-22},
  date = {2003-06},
  pages = {555-559},
  author = {Matsugu, Masakazu and Mori, Katsuhiko and Mitari, Yusuke and Kaneda, Yuji}
}

@inproceedings{lecun_convolutional_1995,
  title = {Convolutional {{Networks}} for {{Images Speech}} and {{Time Series}}},
  url = {http://yann.lecun.com/exdb/publis/pdf/lecun-bengio-95a.pdf},
  date = {1995},
  author = {LeCun, Yann and Bengio, Yoshua}
}

@inproceedings{bromley_signature_1994,
  title = {Signature Verification Using a" Siamese" Time Delay Neural Network},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date = {1994},
  pages = {737--744},
  author = {Bromley, Jane and Guyon, Isabelle and LeCun, Yann and Säckinger, Eduard and Shah, Roopak}
}

@inproceedings{goller_learning_1996,
  title = {Learning Task-Dependent Distributed Representations by Backpropagation through Structure},
  volume = {1},
  isbn = {978-0-7803-3210-2},
  url = {http://ieeexplore.ieee.org/document/548916/},
  doi = {10.1109/ICNN.1996.548916},
  publisher = {{IEEE}},
  urldate = {2018-01-22},
  date = {1996},
  pages = {347-352},
  author = {Goller, C. and Kuchler, A.}
}

@article{bengio_neural_2003,
  title = {A Neural Probabilistic Language Model},
  volume = {3},
  issue = {Feb},
  journaltitle = {Journal of machine learning research},
  date = {2003},
  pages = {1137--1155},
  author = {Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and Jauvin, Christian}
}

@article{hermann_not_2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1306.2158},
  primaryClass = {cs},
  title = {"{{Not}} Not Bad" Is Not "Bad": {{A}} Distributional Account of Negation},
  url = {http://arxiv.org/abs/1306.2158},
  shorttitle = {"{{Not}} Not Bad" Is Not "Bad"},
  abstract = {With the increasing empirical success of distributional models of compositional semantics, it is timely to consider the types of textual logic that such models are capable of capturing. In this paper, we address shortcomings in the ability of current models to capture logical operations such as negation. As a solution we propose a tripartite formulation for a continuous vector space representation of semantics and subsequently use this representation to develop a formal compositional notion of negation within such models.},
  urldate = {2018-01-22},
  date = {2013-06-10},
  keywords = {Computer Science - Computation and Language,I.2.7,68T50},
  author = {Hermann, Karl Moritz and Grefenstette, Edward and Blunsom, Phil}
}

@article{turney_domain_2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1309.4035},
  primaryClass = {cs},
  title = {Domain and {{Function}}: {{A Dual}}-{{Space Model}} of {{Semantic Relations}} and {{Compositions}}},
  url = {http://arxiv.org/abs/1309.4035},
  doi = {10.1613/jair.3640},
  shorttitle = {Domain and {{Function}}},
  abstract = {Given appropriate representations of the semantic relations between carpenter and wood and between mason and stone (for example, vectors in a vector space model), a suitable algorithm should be able to recognize that these relations are highly similar (carpenter is to wood as mason is to stone; the relations are analogous). Likewise, with representations of dog, house, and kennel, an algorithm should be able to recognize that the semantic composition of dog and house, dog house, is highly similar to kennel (dog house and kennel are synonymous). It seems that these two tasks, recognizing relations and compositions, are closely connected. However, up to now, the best models for relations are significantly different from the best models for compositions. In this paper, we introduce a dual-space model that unifies these two tasks. This model matches the performance of the best previous models for relations and compositions. The dual-space model consists of a space for measuring domain similarity and a space for measuring function similarity. Carpenter and wood share the same domain, the domain of carpentry. Mason and stone share the same domain, the domain of masonry. Carpenter and mason share the same function, the function of artisans. Wood and stone share the same function, the function of materials. In the composition dog house, kennel has some domain overlap with both dog and house (the domains of pets and buildings). The function of kennel is similar to the function of house (the function of shelters). By combining domain and function similarities in various ways, we can model relations, compositions, and other aspects of semantics.},
  urldate = {2018-01-22},
  date = {2013-09-16},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language,Computer Science - Artificial Intelligence,I.2.7,I.2.6,H.3.1},
  author = {Turney, Peter D.}
}

@article{clark_type-driven_2013,
  title = {Type-Driven Syntax and Semantics for Composing Meaning Vectors},
  journaltitle = {Quantum Physics and Linguistics: A Compositional, Diagrammatic Discourse},
  date = {2013},
  pages = {359--377},
  author = {Clark, Stephen}
}

@inproceedings{cho_learning_2014,
  title = {Learning {{Phrase Representations}} Using {{RNN Encoder}}-{{Decoder}} for {{Statistical Machine Translation}}},
  url = {http://aclweb.org/anthology/D/D14/D14-1179.pdf},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}, {{EMNLP}} 2014, {{October}} 25-29, 2014, {{Doha}}, {{Qatar}}, {{A}} Meeting of {{SIGDAT}}, a {{Special Interest Group}} of the {{ACL}}},
  date = {2014},
  pages = {1724-1734},
  keywords = {RNN,encoder-decoder},
  author = {Cho, Kyunghyun and van Merrienboer, Bart and Gülçehre, ¸Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  options = {useprefix=true},
  crossref = {DBLP:conf/emnlp/2014},
  biburl = {http://dblp.org/rec/bib/conf/emnlp/ChoMGBBSB14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{hellmann_integrating_2013,
  title = {Integrating {{NLP}} Using Linked Data},
  url = {http://svn.aksw.org/papers/2013/ISWC_NIF/public.pdf},
  booktitle = {International Semantic Web Conference},
  publisher = {{Springer}},
  date = {2013},
  pages = {98--113},
  author = {Hellmann, Sebastian and Lehmann, Jens and Auer, Sören and Brümmer, Martin}
}

@article{bahdanau_neural_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.0473},
  primaryClass = {cs, stat},
  title = {Neural {{Machine Translation}} by {{Jointly Learning}} to {{Align}} and {{Translate}}},
  url = {http://arxiv.org/abs/1409.0473},
  abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  urldate = {2018-01-28},
  date = {2014-09-01},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning,Statistics - Machine Learning,Computer Science - Computation and Language,Neural Networks - Attention,Machine Translation,Neural Networks - RNN},
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua}
}

@article{cheng_long_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1601.06733},
  primaryClass = {cs},
  title = {Long {{Short}}-{{Term Memory}}-{{Networks}} for {{Machine Reading}}},
  url = {http://arxiv.org/abs/1601.06733},
  abstract = {In this paper we address the question of how to render sequence-level networks better at handling structured input. We propose a machine reading simulator which processes text incrementally from left to right and performs shallow reasoning with memory and attention. The reader extends the Long Short-Term Memory architecture with a memory network in place of a single memory cell. This enables adaptive memory usage during recurrence with neural attention, offering a way to weakly induce relations among tokens. The system is initially designed to process a single sequence but we also demonstrate how to integrate it with an encoder-decoder architecture. Experiments on language modeling, sentiment analysis, and natural language inference show that our model matches or outperforms the state of the art.},
  urldate = {2018-01-28},
  date = {2016-01-25},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Computation and Language},
  author = {Cheng, Jianpeng and Dong, Li and Lapata, Mirella}
}

@article{graves_speech_2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1303.5778},
  primaryClass = {cs},
  title = {Speech {{Recognition}} with {{Deep Recurrent Neural Networks}}},
  url = {http://arxiv.org/abs/1303.5778},
  abstract = {Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates $\backslash$emph\{deep recurrent neural networks\}, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7\% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.},
  urldate = {2018-01-28},
  date = {2013-03-22},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Computation and Language,Neural Networks - Bi-LSTM},
  author = {Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey}
}

@book{levin_english_1993,
  location = {{Chicago}},
  title = {English Verb Classes and Alternations: A Preliminary Investigation},
  isbn = {978-0-226-47532-5 978-0-226-47533-2},
  shorttitle = {English Verb Classes and Alternations},
  pagetotal = {348},
  publisher = {{University of Chicago Press}},
  date = {1993},
  keywords = {English language,Verb},
  author = {Levin, Beth}
}

@article{buysse2012dative,
  title = {The Dative Alternation: {{A}} Corpus-Based Study of Spoken {{British English}}},
  journaltitle = {Unpublished Master Thesis, Universiteit Gent},
  date = {2012},
  author = {Buysse, Manon}
}

@article{de_cuypere_dative_2013,
  langid = {english},
  title = {Dative Alternation in {{Indian English}}: {{A}} Corpus-Based Analysis},
  volume = {32},
  issn = {1467-971X},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/weng.12017/abstract},
  doi = {10.1111/weng.12017},
  shorttitle = {Dative Alternation in {{Indian English}}},
  abstract = {The dative alternation refers to the alternation between two constructions that denote some type of transfer: the double object construction (I give my sister a book) vs. the to-dative construction (I give a book to my sister). We examined the motivations behind the dative alternation in Indian English. A corpus study was performed based on a sample of N = 943 sentences that were drawn from the Kolhapur corpus. Using a mixed-effects logistic regression analysis, we evaluated the effect of 14 predictors that are known to influence the dative alternation in other macro-regional varieties of English. Three predictors were found to be significant: the sentence verb (modeled as a random intercept), the pronominality of the Recipient and the difference in length between the Recipient and the Theme. Our results further corroborate earlier findings that the to-dative construction is more frequently used in Indian English than in other varieties. We argue that the latter tendency may be associated with a transfer from Hindi.},
  number = {2},
  journaltitle = {World Englishes},
  shortjournal = {World Englishes},
  urldate = {2018-02-12},
  date = {2013-06-01},
  pages = {169-184},
  author = {De Cuypere, Ludovic and Verbeke, Saartje}
}

@article{kendall_dative_2011,
  title = {The Dative Alternation in {{African American English}}: {{Researching}} Syntactic Variation and Change across Sociolinguistic Datasets},
  volume = {7},
  issn = {1613-7027, 1613-7035},
  doi = {10.1515/cllt.2011.011},
  shorttitle = {The Dative Alternation in {{African American English}}},
  number = {2},
  journaltitle = {Corpus Linguistics and Linguistic Theory},
  date = {2011-01},
  author = {Kendall, Tyler and Bresnan, Joan and van Herk, Gerard},
  options = {useprefix=true}
}

@book{bresnan_interfaculty_2005-1,
  title = {‡{{Interfaculty Research Unit}} for {{Language}} and {{Speech}} ({{IWTS}})},
  abstract = {Theoretical linguists have traditionally relied on linguistic intuitions such as gram-maticality judgments for their data. But the massive growth of computer-readable texts and recordings, the availability of cheaper, more powerful computers and soft-ware, and the development of new probabilistic models for language have now made the spontaneous use of language in natural settings a rich and easily accessible alter-native source of data. Surprisingly, many linguists believe that such ‘usage data ’ are irrelevant to the theory of grammar. Four problems are repeatedly brought up in the critiques of usage data— 1. correlated factors seeming to support reductive theories, 2. pooled data invalidating grammatical inference, 3. syntactic choices reducing to lexical biases, and 4. cross-corpus differences undermining corpus studies. Presenting a case study of work on the English dative alternation, we show first,},
  date = {2005},
  author = {Bresnan, Joan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/5BBLI7EP/Bresnan - 2005 - ‡Interfaculty Research Unit for Language and Speec.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WPZMA7VD/summary.html}
}

@inproceedings{bresnan_is_2006,
  title = {Is Syntactic Knowledge Probabilistic? Experiments with the English Dative Alternation},
  shorttitle = {Is Syntactic Knowledge Probabilistic?},
  abstract = {Theoretical linguistics traditionally relies on linguistic intuitions such as grammaticality judgments for data. But the massive growth of language technologies has made the spontaneous use of language in natural settings a rich and easily accessible alternative source of data. Moreover, studies of usage as well as intuitive judgments have shown that linguistic intuitions of grammaticality are deeply flawed, because (1) they seriously underestimate the space of grammatical possibility by ignoring the effects of multiple conflicting formal, semantic, and contextual constraints, and (2) they may reflect probability instead of grammaticality. Both of these points are richly exemplified by studies of the English dative alternation (Green 1971; Gries},
  booktitle = {Linguistics in Search of Its Evidential Base, {{Studies}} in {{Generative Grammar}}. {{Mouton}} de {{Gruyter}}},
  date = {2006},
  author = {Bresnan, Joan}
}

@article{bresnan2007predicting,
  title = {Predicting the Dative Alternation},
  journaltitle = {Cognitive foundations of interpretation},
  date = {2007},
  pages = {69-94},
  author = {Bresnan, Joan and Cueni, Anna and Nikitina, Tatiana and Baayen, R Harald and {others}},
  publisher = {{Citeseer}}
}

@book{bresnan_gradience_2003,
  title = {On the {{Gradience}} of the {{Dative Alternation}}},
  abstract = {The present study addresses the gradience of the dative alternation. It  is shown that central evidential paradigms that have been used to support  semantic explanations for the choice of dative constructions are  not well founded empirically. Some widely repeated reports of intuitive  contrasts in grammaticality appear to rest instead on judgments  of pragmatic probabilities. An informational theory of the dative alternation  is supported by the results of a corpus study on the distribution  of person across dative NP and PP recipients in spoken English, and a  formal model of the theory is given within the framework of stochastic  Optimality Theory.},
  date = {2003},
  author = {Bresnan, Joan and Nikitina, Tatiana}
}

@inproceedings{lapata_acquiring_1999,
  title = {Acquiring Lexical Generalizations from Corpora: {{A}} Case Study for Diathesis Alternations},
  shorttitle = {Acquiring Lexical Generalizations from Corpora},
  booktitle = {Proceedings of the 37th Annual Meeting of the {{Association}} for {{Computational Linguistics}} on {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  date = {1999},
  pages = {397--404},
  author = {Lapata, Maria}
}

@article{article,
  title = {A {{Corpus}}-{{Based Investigation}} of {{Dative Alternation}} in {{Use}} of the {{Verbs}} '{{Give}}' and '{{Send}}': {{A Sample}} of {{Corpus}} of {{Contemporary American English}} ({{COCA}})},
  volume = {11},
  date = {2017-09},
  pages = {205-221},
  author = {Yildiz, Mustafa},
  booktitle = {Linguistics Journal}
}

@article{weingarten_primed_2016,
  langid = {english},
  title = {From Primed Concepts to Action: {{A}} Meta-Analysis of the Behavioral Effects of Incidentally Presented Words},
  volume = {142},
  issn = {1939-1455},
  doi = {10.1037/bul0000030},
  shorttitle = {From Primed Concepts to Action},
  abstract = {A meta-analysis assessed the behavioral impact of and psychological processes associated with presenting words connected to an action or a goal representation. The average and distribution of 352 effect sizes (analyzed using fixed-effects and random-effects models) was obtained from 133 studies (84 reports) in which word primes were incidentally presented to participants, with a nonopposite control group, before measuring a behavioral dependent variable. Findings revealed a small behavioral priming effect (dFE = 0.332, dRE = 0.352), which was robust across methodological procedures and only minimally biased by the publication of positive (vs. negative) results. Theory testing analyses indicated that more valued behavior or goal concepts (e.g., associated with important outcomes or values) were associated with stronger priming effects than were less valued behaviors. Furthermore, there was some evidence of persistence of goal effects over time. These results support the notion that goal activation contributes over and above perception-behavior in explaining priming effects. In summary, theorizing about the role of value and satisfaction in goal activation pointed to stronger effects of a behavior or goal concept on overt action. There was no evidence that expectancy (ease of achieving the goal) moderated priming effects. (PsycINFO Database Record},
  number = {5},
  journaltitle = {Psychological Bulletin},
  shortjournal = {Psychol Bull},
  date = {2016-05},
  pages = {472-497},
  keywords = {Behavior,Humans,Achievement,Repetition Priming,Word Association Tests},
  author = {Weingarten, Evan and Chen, Qijia and McAdams, Maxwell and Yi, Jessica and Hepler, Justin and Albarracín, Dolores},
  eprinttype = {pmid},
  eprint = {26689090},
  pmcid = {PMC5783538}
}

@article{naili_comparative_2017,
  langid = {english},
  title = {Comparative Study of Word Embedding Methods in Topic Segmentation},
  volume = {112},
  issn = {18770509},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050917313480},
  doi = {10.1016/j.procs.2017.08.009},
  journaltitle = {Procedia Computer Science},
  urldate = {2018-02-12},
  date = {2017},
  pages = {340-349},
  author = {Naili, Marwa and Chaibi, Anja Habacha and Ben Ghezala, Henda Hajjami}
}

@online{_overview_2016,
  langid = {american},
  title = {An Overview of Word Embeddings and Their Connection to Distributional Semantic Models},
  url = {http://blog.aylien.com/overview-word-embeddings-history-word2vec-cbow-glove/},
  abstract = {FacebookTwitterLinkedInUnsupervisedly learned word embeddings have seen tremendous success in numerous NLP tasks in recent years. So much so that in many NLP architectures, they are close to fully replacing more traditional distributional representations such as LSA features and Brown clusters. You just have to look at last year’s EMNLP and ACL conferences, both of which had a very strong focus on word embeddings, and a recent post in Communications of the ACM in which word embeddings is hailed as the catalyst for NLP’s breakout. But are they worthy of theSEE DETAILS},
  journaltitle = {AYLIEN},
  urldate = {2018-02-12},
  date = {2016-10-13T18:45:27+00:00},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/HN9ULAHX/overview-word-embeddings-history-word2vec-cbow-glove.html}
}

@article{salton_vector_1975,
  title = {A {{Vector Space Model}} for {{Automatic Indexing}}},
  volume = {18},
  abstract = {In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model.},
  journaltitle = {Commun. ACM},
  date = {1975},
  pages = {613-620},
  keywords = {VSM},
  author = {Salton, Gerard and Wong, A. and Yang, Chung-Shu}
}

@book{manning_introduction_2008,
  location = {{New York}},
  title = {Introduction to Information Retrieval},
  isbn = {978-0-521-86571-5},
  pagetotal = {482},
  publisher = {{Cambridge University Press}},
  date = {2008},
  keywords = {Semantic Web,Document clustering,Information retrieval,Text processing (Computer science)},
  author = {Manning, Christopher D. and Raghavan, Prabhakar and Schütze, Hinrich},
  note = {OCLC: ocn190786122}
}

@article{wu_googles_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.08144},
  primaryClass = {cs},
  title = {Google's {{Neural Machine Translation System}}: {{Bridging}} the {{Gap}} between {{Human}} and {{Machine Translation}}},
  url = {http://arxiv.org/abs/1609.08144},
  shorttitle = {Google's {{Neural Machine Translation System}}},
  abstract = {Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units ("wordpieces") for both input and output. This method provides a good balance between the flexibility of "character"-delimited models and the efficiency of "word"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60\% compared to Google's phrase-based production system.},
  urldate = {2018-02-13},
  date = {2016-09-26},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language,Computer Science - Artificial Intelligence},
  author = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V. and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and Klingner, Jeff and Shah, Apurva and Johnson, Melvin and Liu, Xiaobing and Kaiser, Łukasz and Gouws, Stephan and Kato, Yoshikiyo and Kudo, Taku and Kazawa, Hideto and Stevens, Keith and Kurian, George and Patil, Nishant and Wang, Wei and Young, Cliff and Smith, Jason and Riesa, Jason and Rudnick, Alex and Vinyals, Oriol and Corrado, Greg and Hughes, Macduff and Dean, Jeffrey},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/UQBXEF6V/Wu et al. - 2016 - Google's Neural Machine Translation System Bridgi.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WN4PHXSG/1609.html}
}

@inproceedings{sahami_bayesian_1998,
  title = {A {{Bayesian}} Approach to Filtering Junk E-Mail},
  volume = {62},
  booktitle = {Learning for {{Text Categorization}}: {{Papers}} from the 1998 Workshop},
  date = {1998},
  pages = {98--105},
  author = {Sahami, Mehran and Dumais, Susan and Heckerman, David and Horvitz, Eric}
}

@inproceedings{clark_compositional_2008,
  title = {A Compositional Distributional Model of Meaning},
  booktitle = {Proceedings of the {{Second Quantum Interaction Symposium}} ({{QI}}-2008)},
  publisher = {{Oxford}},
  date = {2008},
  pages = {133--140},
  keywords = {CDSM},
  author = {Clark, Stephen and Coecke, Bob and Sadrzadeh, Mehrnoosh}
}

@article{kartsaklis_compositional_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.00138},
  primaryClass = {quant-ph},
  title = {Compositional {{Distributional Semantics}} with {{Compact Closed Categories}} and {{Frobenius Algebras}}},
  url = {http://arxiv.org/abs/1505.00138},
  abstract = {This thesis contributes to ongoing research related to the categorical compositional model for natural language of Coecke, Sadrzadeh and Clark in three ways: Firstly, I propose a concrete instantiation of the abstract framework based on Frobenius algebras (joint work with Sadrzadeh). The theory improves shortcomings of previous proposals, extends the coverage of the language, and is supported by experimental work that improves existing results. The proposed framework describes a new class of compositional models that find intuitive interpretations for a number of linguistic phenomena. Secondly, I propose and evaluate in practice a new compositional methodology which explicitly deals with the different levels of lexical ambiguity (joint work with Pulman). A concrete algorithm is presented, based on the separation of vector disambiguation from composition in an explicit prior step. Extensive experimental work shows that the proposed methodology indeed results in more accurate composite representations for the framework of Coecke et al. in particular and every other class of compositional models in general. As a last contribution, I formalize the explicit treatment of lexical ambiguity in the context of the categorical framework by resorting to categorical quantum mechanics (joint work with Coecke). In the proposed extension, the concept of a distributional vector is replaced with that of a density matrix, which compactly represents a probability distribution over the potential different meanings of the specific word. Composition takes the form of quantum measurements, leading to interesting analogies between quantum physics and linguistics.},
  urldate = {2018-02-13},
  date = {2015-05-01},
  keywords = {Computer Science - Computation and Language,Computer Science - Artificial Intelligence,Mathematics - Category Theory,Mathematics - Quantum Algebra,Quantum Physics,CDSM},
  author = {Kartsaklis, Dimitri}
}

@article{edelstein_factorized_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.07756},
  primaryClass = {cs},
  title = {A {{Factorized Model}} for {{Transitive Verbs}} in {{Compositional Distributional Semantics}}},
  url = {http://arxiv.org/abs/1609.07756},
  abstract = {We present a factorized compositional distributional semantics model for the representation of transitive verb constructions. Our model first produces (subject, verb) and (verb, object) vector representations based on the similarity of the nouns in the construction to each of the nouns in the vocabulary and the tendency of these nouns to take the subject and object roles of the verb. These vectors are then combined into a final (subject,verb,object) representation through simple vector operations. On two established tasks for the transitive verb construction our model outperforms recent previous work.},
  urldate = {2018-02-13},
  date = {2016-09-25},
  keywords = {Computer Science - Computation and Language,I.2.7,linguistics},
  author = {Edelstein, Lilach and Reichart, Roi}
}

@inproceedings{grefenstette_experimental_2011,
  title = {Experimental Support for a Categorical Compositional Distributional Model of Meaning},
  booktitle = {Proceedings of the {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2011},
  pages = {1394--1404},
  keywords = {CDSM},
  author = {Grefenstette, Edward and Sadrzadeh, Mehrnoosh}
}

@article{coecke_mathematical_2010,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1003.4394},
  primaryClass = {cs, math},
  title = {Mathematical {{Foundations}} for a {{Compositional Distributional Model}} of {{Meaning}}},
  url = {http://arxiv.org/abs/1003.4394},
  abstract = {We propose a mathematical framework for a unification of the distributional theory of meaning in terms of vector space models, and a compositional theory for grammatical types, for which we rely on the algebra of Pregroups, introduced by Lambek. This mathematical framework enables us to compute the meaning of a well-typed sentence from the meanings of its constituents. Concretely, the type reductions of Pregroups are `lifted' to morphisms in a category, a procedure that transforms meanings of constituents into a meaning of the (well-typed) whole. Importantly, meanings of whole sentences live in a single space, independent of the grammatical structure of the sentence. Hence the inner-product can be used to compare meanings of arbitrary sentences, as it is for comparing the meanings of words in the distributional model. The mathematical structure we employ admits a purely diagrammatic calculus which exposes how the information flows between the words in a sentence in order to make up the meaning of the whole sentence. A variation of our `categorical model' which involves constraining the scalars of the vector spaces to the semiring of Booleans results in a Montague-style Boolean-valued semantics.},
  urldate = {2018-02-13},
  date = {2010-03-23},
  keywords = {Computer Science - Computation and Language,Mathematics - Category Theory,CDSM,Computer Science - Logic in Computer Science},
  author = {Coecke, Bob and Sadrzadeh, Mehrnoosh and Clark, Stephen},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WB9XGYJU/Coecke et al. - 2010 - Mathematical Foundations for a Compositional Distr.pdf;/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/UIBNNDHY/1003.html}
}

@article{simonyan_very_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.1556},
  primaryClass = {cs},
  title = {Very {{Deep Convolutional Networks}} for {{Large}}-{{Scale Image Recognition}}},
  url = {http://arxiv.org/abs/1409.1556},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  urldate = {2018-02-14},
  date = {2014-09-04},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Simonyan, Karen and Zisserman, Andrew}
}

@article{sermanet_overfeat_2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1312.6229},
  primaryClass = {cs},
  title = {{{OverFeat}}: {{Integrated Recognition}}, {{Localization}} and {{Detection}} Using {{Convolutional Networks}}},
  url = {http://arxiv.org/abs/1312.6229},
  shorttitle = {{{OverFeat}}},
  abstract = {We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.},
  urldate = {2018-02-14},
  date = {2013-12-21},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and LeCun, Yann}
}

@article{peters_deep_2018,
  title = {Deep Contextualized Word Representations},
  url = {https://openreview.net/forum?id=SJTCsqMUf},
  abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across...},
  urldate = {2018-02-14},
  date = {2018-02-03},
  author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke}
}

@book{lehmann_theory_1998,
  langid = {english},
  location = {{New York}},
  title = {Theory of {{Point Estimation}}},
  edition = {2},
  isbn = {978-0-387-98502-2},
  url = {//www.springer.com/de/book/9780387985022},
  series = {Springer Texts in Statistics},
  publisher = {{Springer-Verlag}},
  urldate = {2018-02-14},
  date = {1998},
  author = {Lehmann, Erich L. and Casella, George},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/WM5KTE3E/9780387985022.html}
}

@article{piantadosi_zipfs_2014,
  title = {Zipf’s Word Frequency Law in Natural Language: {{A}} Critical Review and Future Directions},
  volume = {21},
  issn = {1069-9384},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4176592/},
  doi = {10.3758/s13423-014-0585-6},
  shorttitle = {Zipf’s Word Frequency Law in Natural Language},
  abstract = {The frequency distribution of words has been a key object of study in statistical linguistics for the past 70 years. This distribution approximately follows a simple mathematical form known as Zipf ’ s law. This article first shows that human language has a highly complex, reliable structure in the frequency distribution over and above this classic law, although prior data visualization methods have obscured this fact. A number of empirical phenomena related to word frequencies are then reviewed. These facts are chosen to be informative about the mechanisms giving rise to Zipf’s law and are then used to evaluate many of the theoretical explanations of Zipf’s law in language. No prior account straightforwardly explains all the basic facts or is supported with independent evaluation of its underlying assumptions. To make progress at understanding why language obeys Zipf’s law, studies must seek evidence beyond the law itself, testing assumptions and evaluating novel predictions with new, independent data.},
  number = {5},
  journaltitle = {Psychonomic bulletin \& review},
  shortjournal = {Psychon Bull Rev},
  urldate = {2018-02-14},
  date = {2014-10},
  pages = {1112-1130},
  keywords = {Zipf},
  author = {Piantadosi, Steven T.},
  eprinttype = {pmid},
  eprint = {24664880},
  pmcid = {PMC4176592}
}

@book{zipf_psychobiology_1935,
  location = {{Cambridge, Mass.}},
  title = {The {{Psychobiology}} of {{Language}}: {{An Introduction}} to {{Dynamic Philology}}},
  publisher = {{M.I.T. Press}},
  date = {1935},
  author = {Zipf, George}
}

@article{stewart_early_1993,
  title = {On the {{Early History}} of the {{Singular Value Decomposition}}},
  volume = {35},
  issn = {0036-1445},
  url = {http://epubs.siam.org/doi/abs/10.1137/1035134},
  doi = {10.1137/1035134},
  abstract = {This paper surveys the contributions of five mathematicians—Eugenio Beltrami (1835–1899), Camille Jordan (1838–1921), James Joseph Sylvester (1814–1897), Erhard Schmidt (1876–1959), and Hermann Weyl (1885–1955)—who were responsible for establishing the existence of the singular value decomposition and developing its theory.},
  number = {4},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  urldate = {2018-02-14},
  date = {1993-12-01},
  pages = {551-566},
  keywords = {SVD},
  author = {Stewart, G.}
}

@article{beltrami_sulle_1873,
  title = {Sulle Funzioni Bilineari},
  number = {11},
  series = {Giornale di Matematiche ad Uso degli Studenti Delle Universita},
  date = {1873},
  pages = {98-106},
  keywords = {SVD},
  author = {Beltrami, Edward}
}

@article{hofmann_unsupervised_2001,
  title = {Unsupervised Learning by Probabilistic Latent Semantic Analysis},
  volume = {42},
  number = {1-2},
  journaltitle = {Machine learning},
  date = {2001},
  pages = {177--196},
  keywords = {LSA,LSI,frobenius norm},
  author = {Hofmann, Thomas}
}

@article{evert_distributional_2010,
  title = {Distributional Semantic Models},
  journaltitle = {NAACL HLT 2010 Tutorial Abstracts},
  date = {2010},
  pages = {15--18},
  keywords = {DSM},
  author = {Evert, Stefan}
}

@article{schutze_automatic_1998,
  title = {Automatic {{Word Sense Discrimination}}},
  volume = {24},
  issn = {0891-2017},
  url = {http://dl.acm.org/citation.cfm?id=972719.972724},
  abstract = {This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words.},
  number = {1},
  journaltitle = {Comput. Linguist.},
  urldate = {2018-02-14},
  date = {1998-03},
  pages = {97--123},
  keywords = {DSM},
  author = {Schütze, Hinrich}
}

@article{landauer_solution_1997,
  title = {A Solution to {{Plato}}'s Problem: The {{Latent Semantic Analysis}} Theory of Acquisition, Induction and Representation of Knowledge},
  shorttitle = {A Solution to {{Plato}}'s Problem},
  abstract = {How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched. Prologue "How much do we know at any time? Much more, or so I believe, than we know we know!"--Agatha Christie, The Moving Finger A typical American seventh grader knows the meaning of 10-15 words today that she did not know yesterday. She must},
  journaltitle = {Psychological Review},
  date = {1997},
  pages = {211--240},
  keywords = {DSM},
  author = {Landauer, Thomas K. and Dumais, Susan T.}
}

@inproceedings{sales_compositional-distributional_2016,
  title = {A Compositional-Distributional Semantic Model for Searching Complex Entity Categories},
  booktitle = {Proceedings of the {{Fifth Joint Conference}} on {{Lexical}} and {{Computational Semantics}}},
  date = {2016},
  pages = {199--208},
  keywords = {CDSM},
  author = {Sales, Juliano Efson and Freitas, André and Davis, Brian and Handschuh, Siegfried}
}

@article{academie_macon_annales_1851,
  langid = {french},
  title = {Annales de Mâcon.},
  issn = {0980-6032},
  journaltitle = {Annales de Mâcon.},
  date = {1851},
  author = {{Académie (Mâcon)}},
  note = {OCLC: 183317608}
}

@inproceedings{ferrone_compositional_2014,
  title = {Compositional Distributional Semantics Models in Chunk-Based Smoothed Tree Kernels},
  booktitle = {Proceedings of the {{Third Joint Conference}} on {{Lexical}} and {{Computational Semantics}} (* {{SEM}} 2014)},
  date = {2014},
  pages = {93--98},
  author = {Ferrone, Lorenzo and Zanzotto, Fabio Massimo}
}

@inproceedings{bordes_translating_2013,
  title = {Translating Embeddings for Modeling Multi-Relational Data},
  booktitle = {Advances in Neural Information Processing Systems},
  date = {2013},
  pages = {2787--2795},
  keywords = {TransE},
  author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana}
}

@article{amir_modelling_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1607.00976},
  primaryClass = {cs},
  title = {Modelling {{Context}} with {{User Embeddings}} for {{Sarcasm Detection}} in {{Social Media}}},
  url = {http://arxiv.org/abs/1607.00976},
  abstract = {We introduce a deep neural network for automated sarcasm detection. Recent work has emphasized the need for models to capitalize on contextual features, beyond lexical and syntactic cues present in utterances. For example, different speakers will tend to employ sarcasm regarding different subjects and, thus, sarcasm detection models ought to encode such speaker information. Current methods have achieved this by way of laborious feature engineering. By contrast, we propose to automatically learn and then exploit user embeddings, to be used in concert with lexical signals to recognize sarcasm. Our approach does not require elaborate feature engineering (and concomitant data scraping); fitting user embeddings requires only the text from their previous posts. The experimental results show that our model outperforms a state-of-the-art approach leveraging an extensive set of carefully crafted features.},
  urldate = {2018-03-08},
  date = {2016-07-04},
  keywords = {Computer Science - Computation and Language,Computer Science - Artificial Intelligence},
  author = {Amir, Silvio and Wallace, Byron C. and Lyu, Hao and Silva, Paula Carvalho Mário J.}
}

@article{lecun_deep_2015,
  langid = {english},
  title = {Deep Learning},
  volume = {521},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature14539},
  doi = {10.1038/nature14539},
  number = {7553},
  journaltitle = {Nature},
  urldate = {2018-03-09},
  date = {2015-05},
  pages = {436-444},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey}
}

@article{andreas_neural_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.02799},
  primaryClass = {cs},
  title = {Neural {{Module Networks}}},
  url = {http://arxiv.org/abs/1511.02799},
  abstract = {Visual question answering is fundamentally compositional in nature---a question like "where is the dog?" shares substructure with questions like "what color is the dog?" and "where is the cat?" This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning *neural module networks*, which compose collections of jointly-trained neural "modules" into deep networks for question answering. Our approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our approach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.},
  urldate = {2018-03-13},
  date = {2015-11-09},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Learning,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan}
}

@article{hudson_compositional_2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.03067},
  primaryClass = {cs},
  title = {Compositional {{Attention Networks}} for {{Machine Reasoning}}},
  url = {http://arxiv.org/abs/1803.03067},
  abstract = {We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. Drawing inspiration from first principles of computer organization, MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9\% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.},
  urldate = {2018-03-13},
  date = {2018-03-08},
  keywords = {Computer Science - Artificial Intelligence},
  author = {Hudson, Drew A. and Manning, Christopher D.}
}

@article{johnson_inferring_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.03633},
  primaryClass = {cs},
  title = {Inferring and {{Executing Programs}} for {{Visual Reasoning}}},
  url = {http://arxiv.org/abs/1705.03633},
  abstract = {Existing methods for visual reasoning attempt to directly map inputs to outputs using black-box architectures without explicitly modeling the underlying reasoning processes. As a result, these black-box models often learn to exploit biases in the data rather than learning to perform visual reasoning. Inspired by module networks, this paper proposes a model for visual reasoning that consists of a program generator that constructs an explicit representation of the reasoning process to be performed, and an execution engine that executes the resulting program to produce an answer. Both the program generator and the execution engine are implemented by neural networks, and are trained using a combination of backpropagation and REINFORCE. Using the CLEVR benchmark for visual reasoning, we show that our model significantly outperforms strong baselines and generalizes better in a variety of settings.},
  urldate = {2018-03-13},
  date = {2017-05-10},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  author = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Hoffman, Judy and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
  options = {useprefix=true}
}

@inproceedings{silveira_gold_2014,
  title = {A {{Gold Standard Dependency Corpus}} for {{English}}.},
  booktitle = {{{LREC}}},
  date = {2014},
  pages = {2897--2904},
  author = {Silveira, Natalia and Dozat, Timothy and De Marneffe, Marie-Catherine and Bowman, Samuel R. and Connor, Miriam and Bauer, John and Manning, Christopher D.}
}

@article{marcus_ontonotes_,
  title = {{{OntoNotes}}: {{A Large Training Corpus}} for {{Enhanced Processing}}},
  author = {Marcus, Ralph Weischedel Eduard Hovy Mitchell and Palmer, Martha and Ramshaw, Robert Belvin Sameer Pradhan Lance and Xue, Nianwen}
}

@article{weischedel_ontonotes_2011,
  title = {{{OntoNotes}}: {{A Large Training Corpus}} for {{Enhanced Processing}}},
  date = {2011-01},
  author = {Weischedel, Ralph and Hovy, Eduard and Marcus, Mitchell and Palmer, Martha and Belvin, Robert and Pradhan, Sameer and Ramshaw, Lance and Xue, Nianwen}
}

@inproceedings{honnibal_improved_2015,
  location = {{Lisbon, Portugal}},
  title = {An {{Improved Non}}-Monotonic {{Transition System}} for {{Dependency Parsing}}},
  url = {https://aclweb.org/anthology/D/D15/D15-1162},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  date = {2015-09},
  pages = {1373-1378},
  author = {Honnibal, Matthew and Johnson, Mark}
}

@inproceedings{joulin_bag_2017,
  langid = {english},
  title = {Bag of {{Tricks}} for {{Efficient Text Classification}}},
  url = {http://aclweb.org/anthology/E17-2068},
  doi = {10.18653/v1/E17-2068},
  abstract = {This paper explores a simple and efﬁcient baseline for text classiﬁcation. Our experiments show that our fast text classiﬁer fastText is often on par with deep learning classiﬁers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU, and classify half a million sentences among 312K classes in less than a minute.},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2018-05-16},
  date = {2017},
  pages = {427-431},
  author = {Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas}
}

@inproceedings{yang_hierarchical_2016,
  langid = {english},
  title = {Hierarchical {{Attention Networks}} for {{Document Classification}}},
  url = {http://aclweb.org/anthology/N16-1174},
  doi = {10.18653/v1/N16-1174},
  abstract = {We propose a hierarchical attention network for document classiﬁcation. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classiﬁcation tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences.},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2018-05-18},
  date = {2016},
  pages = {1480-1489},
  author = {Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard}
}

@article{xu_show_2015,
  langid = {english},
  title = {Show, {{Attend}} and {{Tell}}: {{Neural Image CaptionGeneration}} with {{Visual Attention}}},
  abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to ﬁx its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-theart performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO.},
  date = {2015},
  pages = {10},
  author = {Xu, Kelvin and Lei, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard S and Bengio, Yoshua}
}

@misc{binder_comparison_2018,
  title = {Comparison of Two Semantic Aware Composition Models for Word Embeddings and Its Relation to Dependency Type Information},
  date = {2018},
  author = {Binder, Arne}
}

@article{dojchinovski_dbpedia_2018,
  langid = {english},
  title = {{{DBpedia NIF}}: {{Open}}, {{Large}}-{{Scale}} and {{Multilingual Knowledge Extraction Corpus}}},
  abstract = {In the past decade, the DBpedia community has put signiﬁcant amount of eﬀort on developing technical infrastructure and methods for eﬃcient extraction of structured information from Wikipedia. These eﬀorts have been primarily focused on harvesting, reﬁnement and publishing semi-structured information found in Wikipedia articles, such as information from infoboxes, categorization information, images, wikilinks and citations. Nevertheless, still vast amount of valuable information is contained in the unstructured Wikipedia article texts. In this paper, we present DBpedia NIF - a large-scale and multilingual knowledge extraction corpus. The aim of the dataset is two-fold: to dramatically broaden and deepen the amount of structured information in DBpedia, and to provide large-scale and multilingual language resource for development of various NLP and IR task. The dataset provides the content of all articles for 128 Wikipedia languages. We describe the dataset creation process and the NLP Interchange Format (NIF) used to model the content, links and the structure the information of the Wikipedia articles. The dataset has been further enriched with about 25\% more links and selected partitions published as Linked Data. Finally, we describe the maintenance and sustainability plans, and selected use cases of the dataset from the TextExt knowledge extraction challenge.},
  date = {2018},
  pages = {15},
  author = {Dojchinovski, Milan and Hernandez, Julio and Ackermann, Markus},
  note = {https://2018.eswc-conferences.org/wp-content/uploads/2018/02/ESWC2018\_paper\_136.pdf}
}

@article{greff_lstm_2017,
  langid = {english},
  title = {{{LSTM}}: {{A Search Space Odyssey}}},
  volume = {28},
  issn = {2162-237X, 2162-2388},
  url = {http://ieeexplore.ieee.org/document/7508408/},
  doi = {10.1109/TNNLS.2016.2582924},
  shorttitle = {{{LSTM}}},
  abstract = {Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the ﬁrst large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful fANOVA framework. In total, we summarize the results of 5400 experimental runs (≈ 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture signiﬁcantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efﬁcient adjustment.},
  number = {10},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  urldate = {2018-05-18},
  date = {2017-10},
  pages = {2222-2232},
  author = {Greff, Klaus and Srivastava, Rupesh K. and Koutnik, Jan and Steunebrink, Bas R. and Schmidhuber, Jurgen}
}

@article{xiong_microsoft_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1708.06073},
  primaryClass = {cs},
  title = {The {{Microsoft}} 2017 {{Conversational Speech Recognition System}}},
  url = {http://arxiv.org/abs/1708.06073},
  abstract = {We describe the 2017 version of Microsoft's conversational speech recognition system, in which we update our 2016 system with recent developments in neural-network-based acoustic and language modeling to further advance the state of the art on the Switchboard speech recognition task. The system adds a CNN-BLSTM acoustic model to the set of model architectures we combined previously, and includes character-based and dialog session aware LSTM language models in rescoring. For system combination we adopt a two-stage approach, whereby subsets of acoustic models are first combined at the senone/frame level, followed by a word-level voting via confusion networks. We also added a confusion network rescoring step after system combination. The resulting system yields a 5.1$\backslash$\% word error rate on the 2000 Switchboard evaluation set.},
  urldate = {2018-05-18},
  date = {2017-08-20},
  keywords = {Computer Science - Computation and Language},
  author = {Xiong, W. and Wu, L. and Alleva, F. and Droppo, J. and Huang, X. and Stolcke, A.}
}

@article{vinyals_show_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.4555},
  primaryClass = {cs},
  title = {Show and {{Tell}}: {{A Neural Image Caption Generator}}},
  url = {http://arxiv.org/abs/1411.4555},
  shorttitle = {Show and {{Tell}}},
  abstract = {Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.},
  urldate = {2018-05-18},
  date = {2014-11-17},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru}
}

@article{socher_parsing_2011,
  langid = {english},
  title = {Parsing {{Natural Scenes}} and {{Natural Language}} with {{Recursive Neural Networks}}},
  date = {2011},
  pages = {8},
  author = {Socher, Richard and Lin, Cliff Chiung-Yu and Ng, Andrew Y and Manning, Christopher D}
}

@article{dierk_smart_1971,
  title = {The {{SMART}} Retrieval System: {{Experiments}} in Automatic Document Processing},
  volume = {PC-15},
  issn = {0361-1434},
  doi = {10.1109/TPC.1972.6591971},
  shorttitle = {The {{SMART}} Retrieval System},
  abstract = {If one were to construct a dictionary today for use in an information storage and retrieval system, it would seem almost appropriate to link the name Gerard Salton with the SMART system, for the two, in a way, are synonyms. Thus, to read of another publication by Salton about the SMART system is not a surprise: the new book continues the account of the SMART system begun earlier [1].},
  number = {1},
  journaltitle = {IEEE Transactions on Professional Communication},
  date = {1971},
  pages = {17-17},
  author = {Dierk, S. F.}
}

@article{rapp_word_2003,
  langid = {english},
  title = {Word Sense Discovery Based on Sense Descriptor Dissimilarity},
  abstract = {In machine translation, information on word ambiguities is usually provided by the lexicographers who construct the lexicon. In this paper we propose an automatic method for word sense induction, i.e. for the discovery of a set of sense descriptors to a given ambiguous word. The approach is based on the statistics of the distributional similarity between the words in a corpus. Our algorithm works as follows: The 20 strongest first-order associations to the ambiguous word are considered as sense descriptor candidates. All pairs of these candidates are ranked according to the following two criteria: First, the two words in a pair should be as dissimilar as possible. Second, although being dissimilar their co-occurrence vectors should add up to the co-occurrence vector of the ambiguous word scaled by two. Both conditions together have the effect that preference is given to pairs whose co-occurring words are complementary. For best results, our implementation uses singular value decomposition, entropy-based weights, and second-order similarity metrics.},
  date = {2003},
  pages = {8},
  author = {Rapp, Reinhard}
}

@article{turney_similarity_2006,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {cs/0608100},
  title = {Similarity of {{Semantic Relations}}},
  url = {http://arxiv.org/abs/cs/0608100},
  abstract = {There are at least two kinds of similarity. Relational similarity is correspondence between relations, in contrast with attributional similarity, which is correspondence between attributes. When two words have a high degree of attributional similarity, we call them synonyms. When two pairs of words have a high degree of relational similarity, we say that their relations are analogous. For example, the word pair mason:stone is analogous to the pair carpenter:wood. This paper introduces Latent Relational Analysis (LRA), a method for measuring relational similarity. LRA has potential applications in many areas, including information extraction, word sense disambiguation, and information retrieval. Recently the Vector Space Model (VSM) of information retrieval has been adapted to measuring relational similarity, achieving a score of 47\% on a collection of 374 college-level multiple-choice word analogy questions. In the VSM approach, the relation between a pair of words is characterized by a vector of frequencies of predefined patterns in a large corpus. LRA extends the VSM approach in three ways: (1) the patterns are derived automatically from the corpus, (2) the Singular Value Decomposition (SVD) is used to smooth the frequency data, and (3) automatically generated synonyms are used to explore variations of the word pairs. LRA achieves 56\% on the 374 analogy questions, statistically equivalent to the average human score of 57\%. On the related problem of classifying semantic relations, LRA achieves similar gains over the VSM.},
  urldate = {2018-05-22},
  date = {2006-08-25},
  keywords = {Computer Science - Learning,Computer Science - Computation and Language,Computer Science - Information Retrieval,I.2.7,I.2.6,H.3.1},
  author = {Turney, Peter D.}
}

@inproceedings{erk_structured_2008,
  langid = {english},
  title = {A Structured Vector Space Model for Word Meaning in Context},
  url = {http://portal.acm.org/citation.cfm?doid=1613715.1613831},
  doi = {10.3115/1613715.1613831},
  abstract = {We address the task of computing vector space representations for the meaning of word occurrences, which can vary widely according to context. This task is a crucial step towards a robust, vector-based compositional account of sentence meaning. We argue that existing models for this task do not take syntactic structure sufﬁciently into account. We present a novel structured vector space model that addresses these issues by incorporating the selectional preferences for words’ argument positions. This makes it possible to integrate syntax into the computation of word meaning in context. In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases.},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2018-05-22},
  date = {2008},
  pages = {897},
  author = {Erk, Katrin and Padó, Sebastian}
}

@inproceedings{mcdonald_testing_2001,
  title = {Testing the Distributional Hypothesis: {{The}} Influence of Context on Judgements of Semantic Similarity},
  shorttitle = {Testing the Distributional Hypothesis},
  abstract = {Distributional information has recently been implicated as playing an important role in several aspects of language ability. Learning the meaning of a word is thought to be dependent, at least in part, on exposure to the word in its linguistic contexts of use. In two experiments, we manipulated subjects ’ contextual experience with marginally familiar and nonce words. Results showed that similarity judgements involving these words were affected by the distributional properties of the contexts in which they were read. The accrual of contextual experience was simulated in a semantic space model, by successively adding larger amounts of experience in the form of item-in-context exemplars sampled from the British National Corpus. The experiments and the simulation},
  booktitle = {In {{Proceedings}} of the 23rd {{Annual Conference}} of the {{Cognitive Science Society}}},
  date = {2001},
  pages = {611--6},
  author = {Mcdonald, Scott and Ramscar, Michael}
}

@article{bosc_dart_2016,
  langid = {english},
  title = {{{DART}}: A {{Dataset}} of {{Arguments}} and Their {{Relations}} on {{Twitter}}},
  abstract = {The problem of understanding the stream of messages exchanged on social media such as Facebook and Twitter is becoming a major challenge for automated systems. The tremendous amount of data exchanged on these platforms as well as the speciﬁc form of language adopted by social media users constitute a new challenging context for existing argument mining techniques. In this paper, we describe a resource of natural language arguments called DART (Dataset of Arguments and their Relations on Twitter) where the complete argument mining pipeline over Twitter messages is considered: (i) we identify which tweets can be considered as arguments and which cannot, and (ii) we identify what is the relation, i.e., support or attack, linking such tweets to each other.},
  date = {2016},
  pages = {6},
  author = {Bosc, Tom and Cabrio, Elena and Villata, Serena}
}

@article{lewis_rcv1_,
  langid = {english},
  title = {{{RCV1}}: {{A New Benchmark Collection}} for {{Text Categorization Research}}},
  abstract = {Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection’s properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.},
  pages = {37},
  keywords = {reuters},
  author = {Lewis, David D and Yang, Yiming and Rose, Tony G and Li, Fan}
}

@article{huang_recommending_2011,
  langid = {english},
  title = {Recommending {{MeSH}} Terms for Annotating Biomedical Articles},
  volume = {18},
  issn = {1067-5027, 1527-974X},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2010-000055},
  doi = {10.1136/amiajnl-2010-000055},
  abstract = {Background Due to the high cost of manual curation of key aspects from the scientiﬁc literature, automated methods for assisting this process are greatly desired. Here, we report a novel approach to facilitate MeSH indexing, a challenging task of assigning MeSH terms to MEDLINE citations for their archiving and retrieval.
Methods Unlike previous methods for automatic MeSH term assignment, we reformulate the indexing task as a ranking problem such that relevant MeSH headings are ranked higher than those irrelevant ones. Speciﬁcally, for each document we retrieve 20 neighbor documents, obtain a list of MeSH main headings from neighbors, and rank the MeSH main headings using ListNetea learningto-rank algorithm. We trained our algorithm on 200 documents and tested on a previously used benchmark set of 200 documents and a larger dataset of 1000 documents.
Results Tested on the benchmark dataset, our method achieved a precision of 0.390, recall of 0.712, and mean average precision (MAP) of 0.626. In comparison to the state of the art, we observe statistically signiﬁcant improvements as large as 39\% in MAP (p-value $<$0.001). Similar signiﬁcant improvements were also obtained on the larger document set.
Conclusion Experimental results show that our approach makes the most accurate MeSH predictions to date, which suggests its great potential in making a practical impact on MeSH indexing. Furthermore, as discussed the proposed learning framework is robust and can be adapted to many other similar tasks beyond MeSH indexing in the biomedical domain. All data sets are available at: http://www.ncbi.nlm.nih.gov/ CBBresearch/Lu/indexing.},
  number = {5},
  journaltitle = {Journal of the American Medical Informatics Association},
  urldate = {2018-05-23},
  date = {2011-09},
  pages = {660-667},
  author = {Huang, Minlie and Névéol, Aurélie and Lu, Zhiyong}
}

@article{mao_mesh_2017,
  langid = {english},
  title = {{{MeSH Now}}: Automatic {{MeSH}} Indexing at {{PubMed}} Scale via Learning to Rank},
  volume = {8},
  issn = {2041-1480},
  url = {http://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-017-0123-3},
  doi = {10.1186/s13326-017-0123-3},
  shorttitle = {{{MeSH Now}}},
  abstract = {Background: MeSH indexing is the task of assigning relevant MeSH terms based on a manual reading of scholarly publications by human indexers. The task is highly important for improving literature retrieval and many other scientific investigations in biomedical research. Unfortunately, given its manual nature, the process of MeSH indexing is both time-consuming (new articles are not immediately indexed until 2 or 3 months later) and costly (approximately ten dollars per article). In response, automatic indexing by computers has been previously proposed and attempted but remains challenging. In order to advance the state of the art in automatic MeSH indexing, a community-wide shared task called BioASQ was recently organized.
Methods: We propose MeSH Now, an integrated approach that first uses multiple strategies to generate a combined list of candidate MeSH terms for a target article. Through a novel learning-to-rank framework, MeSH Now then ranks the list of candidate terms based on their relevance to the target article. Finally, MeSH Now selects the highest-ranked MeSH terms via a post-processing module.
Results: We assessed MeSH Now on two separate benchmarking datasets using traditional precision, recall and F1score metrics. In both evaluations, MeSH Now consistently achieved over 0.60 in F-score, ranging from 0.610 to 0. 612. Furthermore, additional experiments show that MeSH Now can be optimized by parallel computing in order to process MEDLINE documents on a large scale.
Conclusions: We conclude that MeSH Now is a robust approach with state-of-the-art performance for automatic MeSH indexing and that MeSH Now is capable of processing PubMed scale documents within a reasonable time frame. Availability: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/MeSHNow/.},
  number = {1},
  journaltitle = {Journal of Biomedical Semantics},
  urldate = {2018-05-23},
  date = {2017-12},
  author = {Mao, Yuqing and Lu, Zhiyong}
}

@article{perdomo-ortiz_opportunities_2018,
  langid = {english},
  title = {Opportunities and Challenges for Quantum-Assisted Machine Learning in near-Term Quantum Computers},
  date = {2018},
  pages = {13},
  author = {Perdomo-Ortiz, Alejandro and Benedetti, Marcello and Realpe-Gomez, John and Biswas, Rupak}
}

@article{bushman_transforming_2015,
  title = {Transforming the {{Medical Subject Headings}} into {{Linked Data}}: {{Creating}} the {{Authorized Version}} of {{MeSH}} in {{RDF}}},
  volume = {15},
  issn = {1938-6389},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4749162/},
  doi = {10.1080/19386389.2015.1099967},
  shorttitle = {Transforming the {{Medical Subject Headings}} into {{Linked Data}}},
  abstract = {In February 2014 the National Library of Medicine formed the Linked Data Infrastructure Working Group to investigate the potential for publishing linked data, determine best practices for publishing linked data, and prioritize linked data projects, beginning with transforming the Medical Subject Headings as a linked data pilot. This article will review the pilot project to convert the Medical Subject Headings from XML to RDF. It will discuss the collaborative process, the technical and organizational issues tackled, and the future of linked data at the library.},
  number = {3-4},
  journaltitle = {Journal of library metadata},
  shortjournal = {J Libr Metadata},
  urldate = {2018-05-27},
  date = {2015},
  pages = {157-176},
  author = {Bushman, Barbara and Anderson, David and Fu, Gang},
  eprinttype = {pmid},
  eprint = {26877832},
  pmcid = {PMC4749162}
}

@article{anguita_ncbi2rdf_2013,
  langid = {english},
  title = {{{NCBI2RDF}}: Enabling Full {{RDF}}-Based Access to {{NCBI}} Databases},
  volume = {2013},
  issn = {2314-6141},
  doi = {10.1155/2013/983805},
  shorttitle = {{{NCBI2RDF}}},
  abstract = {RDF has become the standard technology for enabling interoperability among heterogeneous biomedical databases. The NCBI provides access to a large set of life sciences databases through a common interface called Entrez. However, the latter does not provide RDF-based access to such databases, and, therefore, they cannot be integrated with other RDF-compliant databases and accessed via SPARQL query interfaces. This paper presents the NCBI2RDF system, aimed at providing RDF-based access to the complete NCBI data repository. This API creates a virtual endpoint for servicing SPARQL queries over different NCBI repositories and presenting to users the query results in SPARQL results format, thus enabling this data to be integrated and/or stored with other RDF-compliant repositories. SPARQL queries are dynamically resolved, decomposed, and forwarded to the NCBI-provided E-utilities programmatic interface to access the NCBI data. Furthermore, we show how our approach increases the expressiveness of the native NCBI querying system, allowing several databases to be accessed simultaneously. This feature significantly boosts productivity when working with complex queries and saves time and effort to biomedical researchers. Our approach has been validated with a large number of SPARQL queries, thus proving its reliability and enhanced capabilities in biomedical environments.},
  journaltitle = {BioMed Research International},
  shortjournal = {Biomed Res Int},
  date = {2013},
  pages = {983805},
  keywords = {Access to Information,Databases; Genetic,Search Engine,Software},
  author = {Anguita, Alberto and García-Remesal, Miguel and de la Iglesia, Diana and Maojo, Victor},
  options = {useprefix=true},
  eprinttype = {pmid},
  eprint = {23984425},
  pmcid = {PMC3745940}
}

@article{fried_improving_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1707.03058},
  primaryClass = {cs},
  title = {Improving {{Neural Parsing}} by {{Disentangling Model Combination}} and {{Reranking Effects}}},
  url = {http://arxiv.org/abs/1707.03058},
  abstract = {Recent work has proposed several generative neural models for constituency parsing that achieve state-of-the-art results. Since direct search in these generative models is difficult, they have primarily been used to rescore candidate outputs from base parsers in which decoding is more straightforward. We first present an algorithm for direct search in these generative models. We then demonstrate that the rescoring results are at least partly due to implicit model combination rather than reranking effects. Finally, we show that explicit model combination can improve performance even further, resulting in new state-of-the-art numbers on the PTB of 94.25 F1 when training only on gold data and 94.66 F1 when using external data.},
  urldate = {2018-06-02},
  date = {2017-07-10},
  keywords = {Computer Science - Computation and Language},
  author = {Fried, Daniel and Stern, Mitchell and Klein, Dan}
}

@article{linzen_assessing_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1611.01368},
  primaryClass = {cs},
  title = {Assessing the {{Ability}} of {{LSTMs}} to {{Learn Syntax}}-{{Sensitive Dependencies}}},
  url = {http://arxiv.org/abs/1611.01368},
  abstract = {The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture's grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1\% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.},
  urldate = {2018-06-02},
  date = {2016-11-04},
  keywords = {Computer Science - Computation and Language},
  author = {Linzen, Tal and Dupoux, Emmanuel and Goldberg, Yoav}
}

@article{sundermeyer_lstm_2012,
  langid = {english},
  title = {{{LSTM Neural Networks}} for {{Language Modeling}}},
  abstract = {Neural networks have become increasingly popular for the task of language modeling. Whereas feed-forward networks only exploit a ﬁxed context length to predict the next word of a sequence, conceptually, standard recurrent neural networks can take into account all of the predecessor words. On the other hand, it is well known that recurrent networks are difﬁcult to train and therefore are unlikely to show the full potential of recurrent models.},
  date = {2012},
  pages = {4},
  author = {Sundermeyer, Martin and Schluter, Ralf and Ney, Hermann}
}

@article{dyer_recurrent_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.07776},
  primaryClass = {cs},
  title = {Recurrent {{Neural Network Grammars}}},
  url = {http://arxiv.org/abs/1602.07776},
  abstract = {We introduce recurrent neural network grammars, probabilistic models of sentences with explicit phrase structure. We explain efficient inference procedures that allow application to both parsing and language modeling. Experiments show that they provide better parsing in English than any single previously published supervised generative model and better language modeling than state-of-the-art sequential RNNs in English and Chinese.},
  urldate = {2018-06-02},
  date = {2016-02-24},
  keywords = {Computer Science - Computation and Language,Computer Science - Neural and Evolutionary Computing},
  author = {Dyer, Chris and Kuncoro, Adhiguna and Ballesteros, Miguel and Smith, Noah A.}
}

@article{dyer_transition-based_2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.08075},
  primaryClass = {cs},
  title = {Transition-{{Based Dependency Parsing}} with {{Stack Long Short}}-{{Term Memory}}},
  url = {http://arxiv.org/abs/1505.08075},
  abstract = {We propose a technique for learning representations of parser states in transition-based dependency parsers. Our primary innovation is a new control structure for sequence-to-sequence neural networks---the stack LSTM. Like the conventional stack data structures used in transition-based parsing, elements can be pushed to or popped from the top of the stack in constant time, but, in addition, an LSTM maintains a continuous space embedding of the stack contents. This lets us formulate an efficient parsing model that captures three facets of a parser's state: (i) unbounded look-ahead into the buffer of incoming words, (ii) the complete history of actions taken by the parser, and (iii) the complete contents of the stack of partially built tree fragments, including their internal structures. Standard backpropagation techniques are used for training and yield state-of-the-art parsing performance.},
  urldate = {2018-06-02},
  date = {2015-05-29},
  keywords = {Computer Science - Computation and Language,Computer Science - Learning,Computer Science - Neural and Evolutionary Computing},
  author = {Dyer, Chris and Ballesteros, Miguel and Ling, Wang and Matthews, Austin and Smith, Noah A.},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/I5INLP9X/1505.html}
}

@article{baltescu_pragmatic_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.7119},
  primaryClass = {cs},
  title = {Pragmatic {{Neural Language Modelling}} in {{Machine Translation}}},
  url = {http://arxiv.org/abs/1412.7119},
  abstract = {This paper presents an in-depth investigation on integrating neural language models in translation systems. Scaling neural language models is a difficult task, but crucial for real-world applications. This paper evaluates the impact on end-to-end MT quality of both new and existing scaling techniques. We show when explicitly normalising neural models is necessary and what optimisation tricks one should use in such scenarios. We also focus on scalable training algorithms and investigate noise contrastive estimation and diagonal contexts as sources for further speed improvements. We explore the trade-offs between neural models and back-off n-gram models and find that neural models make strong candidates for natural language applications in memory constrained environments, yet still lag behind traditional models in raw translation quality. We conclude with a set of recommendations one should follow to build a scalable neural language model for MT.},
  urldate = {2018-06-02},
  date = {2014-12-22},
  keywords = {Computer Science - Computation and Language},
  author = {Baltescu, Paul and Blunsom, Phil},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/Z8THR89E/1412.html}
}

@article{glorot_understanding_2010,
  langid = {english},
  title = {Understanding the Difﬁculty of Training Deep Feedforward Neural Networks},
  url = {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
  abstract = {Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We ﬁrst observe the inﬂuence of the non-linear activations functions. We ﬁnd that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we ﬁnd that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We ﬁnd that a new non-linearity that saturates less can often be beneﬁcial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difﬁcult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
  date = {2010},
  pages = {8},
  author = {Glorot, Xavier and Bengio, Yoshua}
}

@article{lipton_thresholding_nodate,
  langid = {english},
  title = {Thresholding {{Classiﬁers}} to {{Maximize F1 Score}}},
  url = {https://arxiv.org/pdf/1402.1892.pdf},
  abstract = {This paper provides new insight into maximizing F1 scores in the context of binary classiﬁcation and also in the context of multilabel classiﬁcation. The harmonic mean of precision and recall, F1 score is widely used to measure the success of a binary classiﬁer when one class is rare. Micro average, macro average, and per instance average F1 scores are used in multilabel classiﬁcation. For any classiﬁer that produces a real-valued output, we derive the relationship between the best achievable F1 score and the decision-making threshold that achieves this optimum. As a special case, if the classiﬁer outputs are well-calibrated conditional probabilities, then the optimal threshold is half the optimal F1 score. As another special case, if the classiﬁer is completely uninformative, then the optimal behavior is to classify all examples as positive. Since the actual prevalence of positive examples typically is low, this behavior can be considered undesirable. As a case study, we discuss the results, which can be surprising, of applying this procedure when predicting 26,853 labels for Medline documents.},
  pages = {16},
  author = {Lipton, Zachary C and Elkan, Charles and Naryanaswamy, Balakrishnan},
  file = {/home/arne/.zotero/zotero/m3xsompx.default/zotero/storage/DQKHZEWP/Lipton et al. - Thresholding Classiﬁers to Maximize F1 Score.pdf}
}


